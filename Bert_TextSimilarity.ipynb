{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_TextSimilarity",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMJQzvWd03rrNJOzrHb6Qa8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "366c740b19874f039955eee0352e74d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_17c092ece6ab410d8b761834d1a03ef0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d6d544f332a34f8a8f7edf3450a6524d",
              "IPY_MODEL_f05e58955a3f43a59b1ceae008c84bed"
            ]
          }
        },
        "17c092ece6ab410d8b761834d1a03ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6d544f332a34f8a8f7edf3450a6524d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7b4b262a3c8040d995f454e2c0d387fd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c4d03b3b07d4e35bc47f6ba99b3d524"
          }
        },
        "f05e58955a3f43a59b1ceae008c84bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_14713082f861489aa658a32598f164d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.27kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68f3b1056dbb49f8b305310ec766965c"
          }
        },
        "7b4b262a3c8040d995f454e2c0d387fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c4d03b3b07d4e35bc47f6ba99b3d524": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14713082f861489aa658a32598f164d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68f3b1056dbb49f8b305310ec766965c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6ffa6c35ef14279b846545320fda2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_716df54703244ca588006bd631dd0a38",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d1092c27518e4e50a3e67e304a3cfc7a",
              "IPY_MODEL_e1405d1ce5c7435487625f57b0ac30c9"
            ]
          }
        },
        "716df54703244ca588006bd631dd0a38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1092c27518e4e50a3e67e304a3cfc7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_84cfa8a013314aa8bb4e8954697d33f1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_559e19352cbe421382290aac82257154"
          }
        },
        "e1405d1ce5c7435487625f57b0ac30c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_027d388861a8483c89aba2e3a5d3686d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 63.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2abdc20a224a45858e0a0132a1ebe4c0"
          }
        },
        "84cfa8a013314aa8bb4e8954697d33f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "559e19352cbe421382290aac82257154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "027d388861a8483c89aba2e3a5d3686d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2abdc20a224a45858e0a0132a1ebe4c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/glingden/Natural-Language-Processing-NLP/blob/master/Bert_TextSimilarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_guI_jjrpWt",
        "colab_type": "text"
      },
      "source": [
        "# BERT Semantic Text Similarity\n",
        "\n",
        "In this notebook, the BERT (bert-base-uncased) model is used for finding  semantic text similarity between the pair of sentences.  The [STS_B benchmark](https://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark) dataset is used for this work. This dataset consists of separate training, validation and test data. The work in this notebook contains two parts:\n",
        "1. Sentence level embedding extraction from pre-trained the bert model and apply cosine similarity between the pair sentence (No fine-tunned/trained, but only using sentence vector representation from the pretrained model)\n",
        "\n",
        "2. Fine-tune: The STS_B Train Dataset is used for fine tunning. And the fine-tunned model is used to  validate the validaiton dataset and predict the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGfcD5iLrtAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import necessary libraries\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9FEdKjUp9Xv",
        "colab_type": "text"
      },
      "source": [
        "GPU from Google Colab is used in this work. So, check if GPU is avaiable, and if not rasie error. We have to identify and specify GPU as device in order to use it. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWARCoGcpiy3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb1640dd-0c5c-4bc1-844e-7873a1520aaa"
      },
      "source": [
        "#check GPU is available or not \n",
        "if torch.cuda.is_available():\n",
        "\n",
        "  device = torch.device(\"cuda\")\n",
        "  print('Found GPU :', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('Not found, use CPU instead')\n",
        "    device = torch.device(\"cpu\")\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU : Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk2eRMkcHA6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN-iiHv5J5rF",
        "colab_type": "text"
      },
      "source": [
        "# **Load Dataset** <br> \n",
        "\n",
        "Dataset is stored at  Google drive. So, I have to mount the google drive to access them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fyQjjuUaV91",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6595d3c0-93f0-4890-fa37-490767df9a91"
      },
      "source": [
        "#mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOC8EINhKX0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load dataset\n",
        "dataset_types = [ \"sts-train.csv\", \"sts-dev.csv\", \"sts-test.csv\",] # 3 datasets\n",
        "col_names = [\"genre\", \"file\", \"years\", \"_\", \"score(0-5)\", \"sentence_1\", \"sentence_2\"] #columns names\n",
        "\n",
        "#collect as a list of pandas dataframes\n",
        "df_list = []\n",
        "for dataset in dataset_types:\n",
        "  df = pd.read_csv(\"/content/drive/My Drive/Google_Colab/stsbenchmark_dataset/\"+ dataset, \n",
        "                 delimiter=',' , \n",
        "                 header= None,\n",
        "                 names= col_names\n",
        "                )\n",
        "  \n",
        "\n",
        "  df_list.append(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAB1ImAYLalv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#separate dataset (train, dev and test)\n",
        "df_train = df_list[0]\n",
        "df_dev = df_list[1]\n",
        "df_test = df_list[2]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_YrEnaHOrGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "05568ca3-c507-4471-a395-cde94c69520c"
      },
      "source": [
        "#show random 5 rows in each dataset (train, dev and test)\n",
        "print(\"Show train_data shape: {}\".format(df_train.shape))\n",
        "print(\"Show dev_data shape: {}\".format(df_dev.shape))\n",
        "print(\"Show test_data shape: {}\".format(df_test.shape))\n",
        "print(\"Show Random 5 rows:\")\n",
        "df_train.sample(5)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Show train_data shape: (5749, 7)\n",
            "Show dev_data shape: (1500, 7)\n",
            "Show test_data shape: (1379, 7)\n",
            "Show Random 5 rows:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>file</th>\n",
              "      <th>years</th>\n",
              "      <th>_</th>\n",
              "      <th>score(0-5)</th>\n",
              "      <th>sentence_1</th>\n",
              "      <th>sentence_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3128</th>\n",
              "      <td>main-news</td>\n",
              "      <td>MSRpar</td>\n",
              "      <td>2012train</td>\n",
              "      <td>266</td>\n",
              "      <td>4.0</td>\n",
              "      <td>In an E-mail statement to the Knoxville News S...</td>\n",
              "      <td>I am not giving any consideration to resignati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1125</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>images</td>\n",
              "      <td>2014</td>\n",
              "      <td>177</td>\n",
              "      <td>2.2</td>\n",
              "      <td>A person riding a dirt bike in the outdoors.</td>\n",
              "      <td>A person jumping a motorbike in the air.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1484</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>images</td>\n",
              "      <td>2014</td>\n",
              "      <td>726</td>\n",
              "      <td>1.8</td>\n",
              "      <td>A close-up of a sheep in the grass.</td>\n",
              "      <td>A close-up of a lamb with its ear tagged, stan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2097</th>\n",
              "      <td>main-forum</td>\n",
              "      <td>deft-forum</td>\n",
              "      <td>2014</td>\n",
              "      <td>97</td>\n",
              "      <td>3.4</td>\n",
              "      <td>I have  years of \"Neener Neener\" rights Usuall...</td>\n",
              "      <td>I have  years of \"Neener Neener\" rights they a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4358</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2014</td>\n",
              "      <td>14</td>\n",
              "      <td>3.8</td>\n",
              "      <td>Five killed in Belgian coach crash</td>\n",
              "      <td>Teenagers among 5 dead in Belgian bus crash</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              genre  ...                                         sentence_2\n",
              "3128      main-news  ...  I am not giving any consideration to resignati...\n",
              "1125  main-captions  ...           A person jumping a motorbike in the air.\n",
              "1484  main-captions  ...  A close-up of a lamb with its ear tagged, stan...\n",
              "2097     main-forum  ...  I have  years of \"Neener Neener\" rights they a...\n",
              "4358      main-news  ...        Teenagers among 5 dead in Belgian bus crash\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiwBL8bglyEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsWuhhJA0gal",
        "colab_type": "text"
      },
      "source": [
        "# **Text Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdTCfSMTzmed",
        "colab_type": "text"
      },
      "source": [
        "Prepare text data according to BERT format. We have to tokenize the text sequences/sentences as per the BERT requirements before feeding them into Model. For this, we will use BertTokenizer from hugging face."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYQGuLbxehNW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "80025828-02b7-4c6c-d1f5-13d9871f3921"
      },
      "source": [
        "#tranformer library from Hugging face\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.0rc4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcFhA_hLzRpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import libraries from hugging face\n",
        "from transformers import BertTokenizer, BertModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrmmEhqczsn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initiate tokenizer \n",
        "tokenizer= BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-nLTbRvew5W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5e893f9b-bc42-4c76-ee91-1070774fa565"
      },
      "source": [
        "#check transformer\n",
        "!python -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('just normal'))\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-06-30 09:26:38.841473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "[{'label': 'POSITIVE', 'score': 0.9987471699714661}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QkjjHeK2zzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecc7bd0f-37b9-453a-867d-bad0c3c98c44"
      },
      "source": [
        "tokenizer.convert_ids_to_tokens(tokenizer.encode(df_train.sentence_1[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]', 'a', 'plane', 'is', 'taking', 'off', '.', '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po958dsD3h1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94b9bfd2-e568-4569-e3fd-9c596344bbfc"
      },
      "source": [
        "df_train.sentence_1[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A plane is taking off.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hRXkexz0YSg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f7e5a30-e2b3-49a8-f9ec-d0451abafdab"
      },
      "source": [
        "#Since we have to have fix length of sequence, check the maximun token length in \n",
        "#every sentences in all datasets and  we will use this max length for all sequences as fix-length size.\n",
        "max_len = 0\n",
        "for x in [df_train.sentence_1, df_train.sentence_2, df_dev.sentence_1, df_dev.sentence_2,df_test.sentence_1,df_test.sentence_2]:\n",
        "  for sent in x:\n",
        "    tokens = tokenizer.encode(sent) #tokenize\n",
        "    tokens_len = len(tokens)\n",
        "    \n",
        "    # keep tracking the higest number of tokens\n",
        "    if tokens_len > max_len:\n",
        "      max_len = tokens_len\n",
        "print(\"Higest tokens number: %s .\" % (max_len))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Higest tokens number: 70 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HJVVdYnI0Q1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8-6qnrXwZ91",
        "colab_type": "text"
      },
      "source": [
        "# Part-1: Sentence Level Embedding Extraction\n",
        "For Sentence Embedding Extraction, last 4 hidden layers are concatenated and meaning pooling of words in a sequence/sentence is done. So, the final dimension of a sentence vector representation is 768*4 =3072."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNtl2Tj-OOS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to extract sentence level embedding from Bert Model\n",
        "def sent_embedding(sent, model):\n",
        "  \"\"\"\n",
        "   Concatenate from last 4 layers and Mean pooling of words in sentences\n",
        "\n",
        "  Args:\n",
        "     sent: list of sentences\n",
        "     model: BERT pre-trained model\n",
        "\n",
        "  Returns:\n",
        "     sent_embedding: 2d tensor \n",
        "\n",
        "  \"\"\"\n",
        "  # tokenize  each sequence into fix-length size of 70 tokens\n",
        "  tokens = tokenizer.batch_encode_plus( sent,\n",
        "                                       max_length= 70, # each sequence size\n",
        "                                       padding= 'max_length', # padding\n",
        "                                       add_special_tokens = True, # add '[CLS]'and '[SEP]'\n",
        "                                       return_attention_mask = True, # attention mask \n",
        "                                       return_tensors='pt',  # return PyTorch tensors\n",
        "                                      )\n",
        "   \n",
        "  \n",
        "\n",
        "  #feed input_ids to BERT model\n",
        "  with torch.no_grad():  # reduces memory consumption\n",
        "        outputs = model(tokens['input_ids'], tokens['attention_mask'] ) # feed input_ids, attention_mask\n",
        "        hidden_states = outputs[2] # all hidden layers\n",
        "\n",
        "\n",
        "\n",
        "  #mean pooling of words in a senquence/sentence and concatenation of last 4 hidden layers \n",
        "  #sent_embeding = torch.cat(tuple([hidden_states[i].mean(dim=1) for i in [-4,-3,-2,-1]]), dim = 1)\n",
        "  #sent_embeding = hidden_states[-2].mean(dim=1) \n",
        "  concat_embeding = torch.cat(tuple([hidden_states[i] for i in [-4,-3,-2,-1]]), dim = 2) #concatenation last 4 hidden layers\n",
        "  print('Dimension after Last_four_layers concatenation: ',concat_embeding.shape )\n",
        "  padded = tokens['attention_mask'].unsqueeze(2) # insert size one at 2 position\n",
        "  mul_out = torch.mul(concat_embeding, padded)# make zeros vector for paddding tokens\n",
        "  sent_embeding = mul_out.mean(dim=1) # average pooling  of tokens\n",
        "  print('Sentence embedding dimension: ',sent_embeding.shape )\n",
        "   \n",
        "  return sent_embeding\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5AASUSgMJi5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "366c740b19874f039955eee0352e74d8",
            "17c092ece6ab410d8b761834d1a03ef0",
            "d6d544f332a34f8a8f7edf3450a6524d",
            "f05e58955a3f43a59b1ceae008c84bed",
            "7b4b262a3c8040d995f454e2c0d387fd",
            "8c4d03b3b07d4e35bc47f6ba99b3d524",
            "14713082f861489aa658a32598f164d9",
            "68f3b1056dbb49f8b305310ec766965c",
            "a6ffa6c35ef14279b846545320fda2a3",
            "716df54703244ca588006bd631dd0a38",
            "d1092c27518e4e50a3e67e304a3cfc7a",
            "e1405d1ce5c7435487625f57b0ac30c9",
            "84cfa8a013314aa8bb4e8954697d33f1",
            "559e19352cbe421382290aac82257154",
            "027d388861a8483c89aba2e3a5d3686d",
            "2abdc20a224a45858e0a0132a1ebe4c0"
          ]
        },
        "outputId": "ec2837bd-50f1-41bb-8c7b-a15046fdda10"
      },
      "source": [
        "# initiate the pre-trained model\n",
        "model = BertModel.from_pretrained(  'bert-base-uncased',\n",
        "                                     output_hidden_states = True # return all hidden-states\n",
        "                                    )\n",
        "#put model in evaluation\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "366c740b19874f039955eee0352e74d8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6ffa6c35ef14279b846545320fda2a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Inv66sv5NkNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOn7EXoMRNTb",
        "colab_type": "text"
      },
      "source": [
        "# Extract Sentence embedding\n",
        "Now, lets extract sentence level vector representation for all datasets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG0mK0m0zJHs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4165e31c-539a-4833-85f9-7deac30d2cf8"
      },
      "source": [
        "%%time\n",
        "#dev dataset\n",
        "df_dev_sentence_1 = sent_embedding(df_dev.sentence_1, model)\n",
        "df_dev_sentence_2 = sent_embedding(df_dev.sentence_2, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimension after Last_four_layers concatenation:  torch.Size([1500, 70, 3072])\n",
            "Sentence embedding dimension:  torch.Size([1500, 3072])\n",
            "Dimension after Last_four_layers concatenation:  torch.Size([1500, 70, 3072])\n",
            "Sentence embedding dimension:  torch.Size([1500, 3072])\n",
            "CPU times: user 9min 14s, sys: 7.94 s, total: 9min 22s\n",
            "Wall time: 9min 22s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj3ks6x98cQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37r03c58pruB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "108e0941-9bc2-41bd-8ca0-5a65c45c489a"
      },
      "source": [
        "%%time\n",
        "#test dataset\n",
        "df_test_sentence_1 = sent_embedding(df_test.sentence_1, model)\n",
        "df_test_sentence_2 = sent_embedding(df_test.sentence_2, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimension after Last_four_layers concatenation:  torch.Size([1379, 70, 3072])\n",
            "Sentence embedding dimension:  torch.Size([1379, 3072])\n",
            "Dimension after Last_four_layers concatenation:  torch.Size([1379, 70, 3072])\n",
            "Sentence embedding dimension:  torch.Size([1379, 3072])\n",
            "CPU times: user 5min 16s, sys: 2.65 s, total: 5min 19s\n",
            "Wall time: 5min 19s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPfxsq_BSvY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNbpHF-US11U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "7695d67e-16d7-4da1-bb4c-6f6422435f89"
      },
      "source": [
        "%%time\n",
        "#train dataset\n",
        "train_embed_sentence_1 =  []\n",
        "train_embed_sentence_2 =  []\n",
        "\n",
        "#make batches\n",
        "for x in range(0, df_train.shape[0], 1500):\n",
        "  embed_1= sent_embedding(df_train.sentence_1[x: x+1500], model)\n",
        "  embed_2= sent_embedding(df_train.sentence_2[x: x+1500], model)\n",
        "  train_embed_sentence_1.extend(embed_1)\n",
        "  train_embed_sentence_2.extend(embed_2)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimension after Last_four_layers concatenation:  torch.Size([1500, 70, 3072])\n",
            "Sentence embedding dimension:  torch.Size([1500, 3072])\n",
            "Dimension after Last_four_layers concatenation:  torch.Size([1500, 70, 3072])\n",
            "Sentence embedding dimension:  torch.Size([1500, 3072])\n",
            "Dimension after Last_four_layers concatenation:  torch.Size([1500, 70, 3072])\n",
            "Sentence embedding dimension:  torch.Size([1500, 3072])\n",
            "Dimension after Last_four_layers concatenation:  torch.Size([1500, 70, 3072])\n",
            "Sentence embedding dimension:  torch.Size([1500, 3072])\n",
            "Dimension after Last_four_layers concatenation:  torch.Size([1500, 70, 3072])\n",
            "Sentence embedding dimension:  torch.Size([1500, 3072])\n",
            "Dimension after Last_four_layers concatenation:  torch.Size([1500, 70, 3072])\n",
            "Sentence embedding dimension:  torch.Size([1500, 3072])\n",
            "Dimension after Last_four_layers concatenation:  torch.Size([1249, 70, 3072])\n",
            "Sentence embedding dimension:  torch.Size([1249, 3072])\n",
            "Dimension after Last_four_layers concatenation:  torch.Size([1249, 70, 3072])\n",
            "Sentence embedding dimension:  torch.Size([1249, 3072])\n",
            "CPU times: user 22min 12s, sys: 10.9 s, total: 22min 23s\n",
            "Wall time: 22min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1NAwk-PelS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sentence level vector represetnation in train dataset\n",
        "df_train_sentence_1 = torch.stack(train_embed_sentence_1) # change list of tensors >>> 2d tensor\n",
        "df_train_sentence_2 = torch.stack(train_embed_sentence_2) # change list of tensors >>> 2d tensor\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_RkbrOCvr3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W9QSzRMREQM",
        "colab_type": "text"
      },
      "source": [
        "# Calculate Cosine Similarity\n",
        "Now, sentence level vector representation of each pair sentence is used to cosine similarity. Cosine similarity is calcualed on all 3 datasets just to know how the extracted sentence level embedding perform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwwMvRGPRC5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine #cosine distance\n",
        "from sklearn.preprocessing import MinMaxScaler # minmax scaling\n",
        "from scipy.stats import pearsonr # pearson correlation\n",
        "from scipy.stats import spearmanr # spearman correlation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gEbjpc5obHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to calculate similarity score \n",
        "def calc_similarity_score(embed_1, embed_2):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    embed_1(numpy array): first sentence embedding\n",
        "    embed_2(numpy array): second sentence embedding\n",
        "\n",
        "  Return:\n",
        "    scaled_cosine_score(list) : cosine score between embed_1 and embed_2 \n",
        "    with range (0,5)\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "  #collect similarity score\n",
        "  #cosine_sim_score = []\n",
        "  \n",
        "  for x,y in zip(embed_1, embed_2):\n",
        "\n",
        "    distance = cosine(x, y) # cosine distance\n",
        "    cosine_sim = 1 - distance # cosine similarity\n",
        "    cosine_sim_score.append(cosine_sim) \n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  #scaled the similarity score to (0,5)\n",
        "  scaler = MinMaxScaler(feature_range=(0,5)) # initiate minmaxscaler\n",
        "  scaled_cosine_score = scaler.fit_transform(np.transpose([cosine_sim_score])) #scaled to (0,5)\n",
        "  \n",
        "  return scaled_cosine_score.round(3)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b53f69trJD8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPnbqdPFGcNo",
        "colab_type": "text"
      },
      "source": [
        "# Cosine Similarity on Dev Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Snu8V7kOLcWW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "91a431b8-69b9-4723-f8e1-014a1e720499"
      },
      "source": [
        "#evaluate on dev data\n",
        "dev_gold_label = df_dev.loc[:,'score(0-5)'].values\n",
        "\n",
        "#cosine similarity score(0,5)\n",
        "dev_cosin_score = calc_similarity_score(df_dev_sentence_1, df_dev_sentence_2)\n",
        "dev_cosi_score = dev_cosin_score.flatten()\n",
        "\n",
        "dev_person_score, _ = pearsonr(dev_gold_label, dev_cosi_score)\n",
        "dev_sperman_score, _ = spearmanr(dev_gold_label, dev_cosi_score)\n",
        "print(\"Pearson score: {} \\nSpearman score: {}\".format(dev_person_score, dev_sperman_score))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pearson score: 0.5929747726822713 \n",
            "Spearman score: 0.5956354804822067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7JCeD4ywYUu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1ebbbf52-239a-4bb2-c50e-b08b3398bc8f"
      },
      "source": [
        "#evaluate on dev data\n",
        "dev_gold_label = df_dev.loc[:,'score(0-5)'].values\n",
        "\n",
        "#cosine similarity score(0,5)\n",
        "dev_cosin_score = calc_similarity_score(df_dev_sentence_1, df_dev_sentence_2)\n",
        "dev_cosi_score = dev_cosin_score.flatten()\n",
        "\n",
        "dev_person_score, _ = pearsonr(dev_gold_label, dev_cosi_score)\n",
        "dev_sperman_score, _ = spearmanr(dev_gold_label, dev_cosi_score)\n",
        "print(\"Pearson score: {} \\nSpearman score: {}\".format(dev_person_score, dev_sperman_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pearson score: 0.518103036697131 \n",
            "Spearman score: 0.5194084407752799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDXkrAkrOf_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyHoBEbjOjwU",
        "colab_type": "text"
      },
      "source": [
        "# Cosine similarity on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRWBuenJMeUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7b562ba7-a8fa-40ea-9191-656892b3059b"
      },
      "source": [
        "#evaluate test data\n",
        "test_gold_label = df_test.loc[:,'score(0-5)'].values\n",
        "\n",
        "#cosine similarity score(0,5)\n",
        "test_cosin_score = calc_similarity_score(df_test_sentence_1, df_test_sentence_2) \n",
        "test_cos_score = test_cosin_score.flatten()\n",
        "\n",
        "test_person_score, _ = pearsonr(test_gold_label, test_cos_score)\n",
        "test_sperman_score, _ = spearmanr(test_gold_label, test_cos_score)\n",
        "print(\"Pearson score: {} \\nSpearman score: {}\".format(test_person_score, test_sperman_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pearson score: 0.4767268597706366 \n",
            "Spearman score: 0.4695436549422946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E0Z4ffWPEQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_1XGht4GQh_",
        "colab_type": "text"
      },
      "source": [
        "# Cosine Similarity on Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnCYFAULSU3N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "db73b4b9-cebd-430c-b54e-7225eefc12bf"
      },
      "source": [
        "#evaluate train data\n",
        "train_gold_label = df_train.loc[:,'score(0-5)'].values\n",
        "\n",
        "#cosine similarity score(0,5)\n",
        "train_cosin_score = calc_similarity_score(df_train_sentence_1, df_train_sentence_2) \n",
        "train_cos_score = train_cosin_score.flatten()\n",
        "\n",
        "train_person_score, _ = pearsonr(train_gold_label, train_cos_score)\n",
        "train_sperman_score, _ = spearmanr(train_gold_label, train_cos_score)\n",
        "print(\"Pearson score: {} \\nSpearman score: {}\".format(train_person_score, train_sperman_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pearson score: 0.5128756007975535 \n",
            "Spearman score: 0.48559941654711763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9bD9I7s02Eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fL8zk1xCduJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4K0cpKC03t3",
        "colab_type": "text"
      },
      "source": [
        "# Part-2: Fine-tune Bert\n",
        "We will  fine-tune the  pre-trained BERT(bert-base-uncased) model with STS-b train dataset. So, the custom model is defined using pytorch nn.module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBO8LnzX5T8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import necessary libraries\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader #pytorch dataset and dataloader\n",
        "from transformers import  AdamW, get_linear_schedule_with_warmup #optimizer and learning rate scheduler\n",
        "from collections import defaultdict  #store train, valid scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0mqIXgTpOcv",
        "colab_type": "text"
      },
      "source": [
        "# Custom Model\n",
        "This custom model uses the Siamese Network structure. The output layer is just the cosine similairty. No additonal layers.  The vector representation of a sentence is the concatenation of the last 4 hidden layers and mean pooling of the words in a sentence/sequence. The Mean Square Error(MSE) Loss is used as loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSIIZmvz02nK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define our custom model\n",
        "class SentenceSimilarityModel(nn.Module):\n",
        "  \"\"\"Bert model to calculate cosine similarity\"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(SentenceSimilarityModel, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                          output_hidden_states = True # return all hidden-states\n",
        "                                          )\n",
        "    self.out = nn.CosineSimilarity(dim=1, eps=1e-6) # cosine similarity\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, input_ids_1, attention_mask_1, input_ids_2, attention_mask_2):\n",
        "    \"\"\"\n",
        "        Args:\n",
        "          input_ids_1(tensor) : input_ids of first sentence\n",
        "          input_ids_2(tensor) : input_ids of second sentence\n",
        "          attention_mask_1(tensor): attention_mask of first sentence\n",
        "          attention_mask_2(tensor): attention_mask of second sentence\n",
        "\n",
        "       Returns:\n",
        "          cosine_score(1d tensor): Cosine similarity between first and second sentence\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    #first sentence embedding\n",
        "    output_1 = self.bert(\n",
        "        input_ids=input_ids_1,\n",
        "        attention_mask=attention_mask_1\n",
        "    )\n",
        "    \n",
        "\n",
        "    hidden_states_1 = output_1[2] #hidden states only\n",
        "    #sent_embeding_1 = torch.cat(tuple([hidden_states_1[i].mean(dim=1) for i in [-4,-3,-2,-1]]), dim = 1) #concat last four hidden layers\n",
        "    \n",
        "    \n",
        "    concat_embeding_1 = torch.cat(tuple([hidden_states_1[i] for i in [-4,-3,-2,-1]]), dim = 2) # last four hidden layers\n",
        "    padded_1 = attention_mask_1.unsqueeze(2) #insert size one at position 2\n",
        "    mul_out_1 = torch.mul(concat_embeding_1, padded_1)#make zeros vector for paddding tokens\n",
        "    sent_embeding_1 = mul_out_1.mean(dim=1) # pooling average of tokens\n",
        "    #out_1 = mul_out_1[:, 0, :] #cls token\n",
        " \n",
        "    \n",
        "\n",
        "\n",
        "    #second sentence embedding\n",
        "    output_2 = self.bert(\n",
        "        input_ids=input_ids_2,\n",
        "        attention_mask=attention_mask_2\n",
        "    )\n",
        "\n",
        "    hidden_states_2 = output_2[2]\n",
        "    #sent_embeding_2 = torch.cat(tuple([hidden_states_2[i].mean(dim=1) for i in [-4,-3,-2,-1]]), dim = 1)\n",
        "\n",
        "    \n",
        "    concat_embeding_2 = torch.cat(tuple([hidden_states_2[i] for i in [-4,-3,-2,-1]]), dim = 2) # last four layers\n",
        "    padded_2 = attention_mask_2.unsqueeze(2) #insert size one at position 2\n",
        "    mul_out_2 = torch.mul(concat_embeding_2, padded_2)#make zeros vector for paddding tokens\n",
        "    sent_embeding_2 = mul_out_2.mean(dim=1) # pooling average of tokens\n",
        "    #out_2 = mul_out_2[:, 0, :] #cls token\n",
        " \n",
        "    \n",
        "    \n",
        "\n",
        "    #calculate cosine similarity\n",
        "    cosine_score = self.out(sent_embeding_1, sent_embeding_2)\n",
        "    \n",
        "    return cosine_score\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2sV5xjD4TAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQsxqYZpQ11y",
        "colab_type": "text"
      },
      "source": [
        "# Create Pytorch Dataset\n",
        "Lets create pytorch dataset that returns input_ids, attention_mask, and gold_score from each sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEa5bH6zQH97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define function to pytorch Dataset\n",
        "class SimilarityDataset(Dataset):\n",
        "  \"\"\" Pytorch dataset that returns input_ids, attension_mask from first, second sentence,\n",
        "   and gold_score  of STS-B dataset\"\"\"\n",
        "\n",
        "  def __init__(self, sent_1s, sent_2s, scores, tokenizer, max_len):\n",
        "    \"\"\"\n",
        "     Args:\n",
        "       sent_1s(numpy array): Array of first sentences\n",
        "       sent_2s(numpy array): Array of second sentences\n",
        "       scores(float): Gold score (0-5)\n",
        "       tokenizer: Higging Face Bert Tokenizer\n",
        "       max_len(int): Maximun token length\n",
        "      \n",
        "    \"\"\"\n",
        "    self.sent_1s = sent_1s\n",
        "    self.sent_2s = sent_2s\n",
        "    self.scores = scores\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.sent_1s) #total no. of samples\n",
        "\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    first_sent = self.sent_1s[item]  #first sentencs\n",
        "    second_sent = self.sent_2s[item] #second sentence\n",
        "    score = self.scores[item] \n",
        "\n",
        "    #encode first sentence\n",
        "    first_sent_encoding = self.tokenizer.encode_plus( first_sent,\n",
        "                                          add_special_tokens=True, #add ['CLS'] and ['SEP']\n",
        "                                          max_length=self.max_len, # set max len for padding\n",
        "                                          return_token_type_ids=False, #set false to segment_ids\n",
        "                                          padding='max_length', # padding\n",
        "                                          return_attention_mask=True,  # return attention mask\n",
        "                                          return_tensors='pt', # pytorch tensor\n",
        "                                          )\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    #encode second sentence\n",
        "    second_sent_encoding = self.tokenizer.encode_plus( second_sent,\n",
        "                                          add_special_tokens=True,\n",
        "                                          max_length=self.max_len,\n",
        "                                          return_token_type_ids=False,\n",
        "                                          padding= 'max_length',\n",
        "                                          return_attention_mask=True,\n",
        "                                          return_tensors='pt',\n",
        "                                          )\n",
        "    \n",
        "    return {\n",
        "        'first_sent' :{ \n",
        "            'input_ids' : first_sent_encoding['input_ids'].flatten(),\n",
        "            'attention_mask' :first_sent_encoding['attention_mask'].flatten()\n",
        "        },\n",
        "\n",
        "        'second_sent' :{\n",
        "            'input_ids' : second_sent_encoding['input_ids'].flatten(),\n",
        "            'attention_mask' :second_sent_encoding['attention_mask'].flatten()\n",
        "        },\n",
        "\n",
        "        'score' : torch.tensor(score)\n",
        "    }\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFUrIv5XkOCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHN6hIpCVh20",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch Data Loader\n",
        "It provides an iterable over the given dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcSgz7WOgyjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define pytorch data loader\n",
        "def data_loader(df, tokenizer, max_len, batch_size):\n",
        "  \"\"\"\n",
        "    Agrs:\n",
        "       df(panda dataframe): dataset\n",
        "       tokenizer(Hugging face tokeniser): Bert Tokonizer\n",
        "       mac_len(int): Maximun tokens length in a sequence/sentence\n",
        "       batch_size(int): Number of samples in a batch\n",
        "\n",
        "    Return:\n",
        "      Dataloader(pytorch dataloader): Dataset with given batch size\n",
        "  \"\"\"\n",
        "  dataset = SimilarityDataset(\n",
        "      sent_1s =df.sentence_1.to_numpy(),\n",
        "      sent_2s =df.sentence_2.to_numpy(),\n",
        "      scores =df.loc[:,'scaled_score(0-1)'].to_numpy(),\n",
        "      tokenizer=tokenizer,\n",
        "      max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader( \n",
        "      dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle= True\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWpK0RpoLpuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y2Ftr_BMK8M",
        "colab_type": "text"
      },
      "source": [
        "# Re-scaled gold score from (0-5) to (0,1)\n",
        "\n",
        "Before making the Data to Pytorch Dataloader, lets re-scaled the 'gold score' to (0,1). This is done because the cosine similarity score is (0,1). So, it makes sense to calculate the loss during the model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-0tO4XVL5il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#re-scale to all datasets\n",
        "df_train['scaled_score(0-1)'] = MinMaxScaler(feature_range=(0,1)).fit_transform(df_train[['score(0-5)']])\n",
        "df_dev['scaled_score(0-1)'] = MinMaxScaler(feature_range=(0,1)).fit_transform(df_dev[['score(0-5)']])\n",
        "df_test['scaled_score(0-1)'] = MinMaxScaler(feature_range=(0,1)).fit_transform(df_test[['score(0-5)']])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAzolCLNOXng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C87nbyp-kqTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create data loader\n",
        "BATCH_SIZE = 16\n",
        "train_data_loader = data_loader( df_train, tokenizer, 70, BATCH_SIZE) # train data loader\n",
        "dev_data_loader = data_loader(df_dev, tokenizer, 70, BATCH_SIZE )# dev data loader\n",
        "test_data_loader = data_loader(df_test, tokenizer, 70, BATCH_SIZE )# test data loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSK-Pz-xZ8tz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ad3edab-515b-447b-b5f2-5f4341fe2b78"
      },
      "source": [
        "data = next(iter(dev_data_loader))\n",
        "data['first_sent']['input_ids'].type()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'torch.LongTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYxIsuUb9gbE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a5f6bd8-a10f-4cd3-cf76-95d6c6323303"
      },
      "source": [
        "data['first_sent']['input_ids'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 70])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWrMV32Mejxa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "dcfedee2-db3b-477e-814a-c01c3de444d1"
      },
      "source": [
        "for x in dev_data_loader:\n",
        "  print(x['first_sent']['input_ids'][2])\n",
        "  print(x['second_sent']['input_ids'][2])\n",
        "  print(x['score'][2])\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 101, 1037, 2158, 2003, 2652, 1037, 2858, 1012,  102,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
            "tensor([ 101, 1996, 2611, 2003, 2652, 1996, 2858, 1012,  102,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
            "tensor(0.4500, dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpfHcjS2j9sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a= custom_model(data['first_sent']['input_ids'].to(device),\n",
        "            data['first_sent']['attention_mask'].to(device),\n",
        "             data['second_sent']['input_ids'].to(device),\n",
        "             data['second_sent']['attention_mask'].to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qoluCuHAmD4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7cea35b0-12b9-4699-cfc1-d83aef3ad565"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9702, 0.8730, 0.7471, 0.8861, 0.8098, 0.7904, 0.9214, 0.9458, 0.7957,\n",
              "        0.9480, 0.8451, 0.9207, 0.8648, 0.7366, 0.8596, 0.9437, 0.9484, 0.7933,\n",
              "        0.8892, 0.8938, 0.9666, 0.9563, 0.7771, 0.9720, 0.9511, 0.7326, 0.9018,\n",
              "        0.7925, 0.7553, 0.9461, 0.7543, 0.8967], device='cuda:0',\n",
              "       grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL5vKM48kLCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define model training function\n",
        "def model_train(model, dataloader, device, loss_fun, optimizer, scheduler):\n",
        "  \"\"\"\n",
        "     Args:\n",
        "       model: Custom model\n",
        "       dataloader: Pytorh data loader\n",
        "       device: device to compute\n",
        "       loss_fun:  loss function( MES loss)\n",
        "       optimizer: optimizer (Adamw)\n",
        "       scheduler: learning rate schedule\n",
        "\n",
        "    Returns:\n",
        "       training loss, and Pearson correlation between gold_score and predicted score\n",
        "       \n",
        "  \"\"\"\n",
        "\n",
        "  #put model in training mode\n",
        "  model.train()\n",
        "\n",
        "  losses = []\n",
        "  pearson_score = []\n",
        "  \n",
        "  #each batch of training data\n",
        "  for batch in dataloader:\n",
        "    \n",
        "    #first sentence\n",
        "    input_ids_1 = batch['first_sent']['input_ids'].to(device)\n",
        "    atten_ids_1 = batch['first_sent']['attention_mask'].to(device)\n",
        "\n",
        "    #second sentence\n",
        "    input_ids_2 = batch['second_sent']['input_ids'].to(device)\n",
        "    atten_ids_2 = batch['second_sent']['attention_mask'].to(device)\n",
        "\n",
        "    #gold score\n",
        "    gold_score = batch['score'].to(device).float() # change to float dtype as same as model output\n",
        "    \n",
        "    #clear previously calculated gradients\n",
        "    model.zero_grad()\n",
        "\n",
        "    #model forward pass\n",
        "    output = model(input_ids_1, atten_ids_1, input_ids_2, atten_ids_2) # output dtype --> float tenosr \n",
        "    '''\n",
        "    #scaled the similarity score i.e. 'output' to (0,5)\n",
        "    reshaped_output = output.reshape(output.shape[0],1) # reshape from (16) -->> (16,1)\n",
        "    scaler = MinMaxScaler(feature_range=(0,5)) #initate minmaxscaler\n",
        "    scaled_cosine_score = scaler.fit_transform(reshaped_output.detach().cpu()) #scale column wise\n",
        "    '''\n",
        "    #Calculate Pearson Correlation score\n",
        "    p_score = pearsonr(output.detach().cpu(), gold_score.detach().cpu())\n",
        "    pearson_score.append(p_score[0])\n",
        "    \n",
        "    #perform loss\n",
        "    loss = loss_fun(output, gold_score)\n",
        "    losses.append(loss.item()) \n",
        "\n",
        "    loss.backward() # perform backward pass to calculate gradients\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)# Clip the norm of the gradients to 1.0.\n",
        "    optimizer.step() #update parameters\n",
        "    scheduler.step() #update learning rate\n",
        "    \n",
        "  return np.mean(losses), np.mean(pearson_score)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8L3_n2OC6V8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF9Mdd8cbOZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define evaluation function\n",
        "def model_eval(model, dataloader, device, loss_fun):\n",
        "  \"\"\"\n",
        "     Args:\n",
        "       model: Custom model\n",
        "       dataloader: pytorch data loader\n",
        "       device: device to compute\n",
        "       loss_fun:  loss function( MES loss)\n",
        "       \n",
        "    Returns:\n",
        "       Evaluation loss, and Pearson correlation between gold_score and predicted score\n",
        "       \n",
        "  \"\"\"\n",
        "\n",
        "  #put model in evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  losses = []\n",
        "  pearson_score = []\n",
        "  \n",
        "\n",
        "  #tell model not to compute or store gradients\n",
        "  with torch.no_grad(): \n",
        "\n",
        "    #each batch of evaluation data\n",
        "    for batch in dataloader:\n",
        "      #first sentence\n",
        "      input_ids_1 = batch['first_sent']['input_ids'].to(device)\n",
        "      atten_ids_1 = batch['first_sent']['attention_mask'].to(device)\n",
        "\n",
        "      #second sentence\n",
        "      input_ids_2 = batch['second_sent']['input_ids'].to(device)\n",
        "      atten_ids_2 = batch['second_sent']['attention_mask'].to(device)\n",
        "\n",
        "      #gold score\n",
        "      gold_score = batch['score'].to(device).float() # change to float dtype as same as model output\n",
        "\n",
        "      #model forward pass\n",
        "      model = model\n",
        "      output = model(input_ids_1, atten_ids_1, input_ids_2, atten_ids_2) # output type --> float tensor \n",
        "\n",
        "      #perform loss\n",
        "      loss = loss_fun(output, gold_score)\n",
        "      losses.append(loss.item()) \n",
        "\n",
        "\n",
        "      '''''\n",
        "      #scaled the similarity score i.e. 'output' to (0,5)\n",
        "      reshaped_output = output.reshape(output.shape[0],1) # reshape from (16) >> (16,1)\n",
        "      scaler = MinMaxScaler(feature_range=(0,5)) #initate minmaxscaler\n",
        "      scaled_cosine_score = scaler.fit_transform(reshaped_output.detach().cpu()) #scale column wise\n",
        "      '''\n",
        "      \n",
        "      #Calculate Pearson Correlation score\n",
        "      p_score = pearsonr(output.detach().cpu(), gold_score.detach().cpu())\n",
        "      pearson_score.append(p_score[0])\n",
        "\n",
        "\n",
        "  return np.mean(losses), np.mean(pearson_score)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11ykQ6rTqkxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjNtLyGbqlXE",
        "colab_type": "text"
      },
      "source": [
        "# Training Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V20oZVOTpzGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initiate model\n",
        "custom_model = SentenceSimilarityModel()\n",
        "custom_model = custom_model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YevjZFxRe-09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3d4657b-bc39-45ed-90b7-44c7f68f2171"
      },
      "source": [
        "#check list of parameter\n",
        "#for param_tensor in custom_model.state_dict():\n",
        "#   print(param_tensor, \"\\t\", custom_model.state_dict()[param_tensor].size())\n",
        "len(custom_model.state_dict())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvbYoLWoJyl_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "4be5a1f8-d00b-44bd-e488-8a7864c26a4c"
      },
      "source": [
        "#check paramerts in model\n",
        "params = list(custom_model.named_parameters())\n",
        "print(len(params))\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print()\n",
        "\n",
        "for p in params[21:21+16]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print()\n",
        "for p in params[-2:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "199\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "bert.encoder.layer.1.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.1.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.1.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.1.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.1.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.1.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.1.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.1.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.1.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.1.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.1.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.1.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.1.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.1.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqp_aZ3rXvDs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9c18e27-5708-4be8-9aed-88234eebf4f3"
      },
      "source": [
        "#out custome model \n",
        "custom_model\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentenceSimilarityModel(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (out): CosineSimilarity()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF1DKIKahNjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB0dR8XirJTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 4 # number of training epoch\n",
        "optimizer =AdamW(custom_model.parameters(), lr=3e-5, eps=1e-8) # Adam optimizer\n",
        "total_steps = len(train_data_loader) * EPOCHS # total number training steps\n",
        "\n",
        "#learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(  \n",
        "  optimizer,  \n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")  \n",
        "\n",
        "#MSE loss function\n",
        "loss_fn = nn.MSELoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N9aKvyVjmCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7QsUASlg4wS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "0d5e4724-5d6e-4e09-c2b5-a096afb997f0"
      },
      "source": [
        "%%time\n",
        "#Training process\n",
        "epochs_score = defaultdict(list)\n",
        "val_score = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print('Epoch {:}/{:}'.format(epoch + 1, EPOCHS))\n",
        "  print('=='*5)\n",
        "  print()\n",
        "\n",
        "  train_loss, train_Pearson_score = model_train(custom_model, train_data_loader, device, loss_fn, optimizer, scheduler)\n",
        "  print('Train loss is: {}, train_Pearson_score is {}'.format(train_loss,train_Pearson_score))\n",
        "\n",
        "  #store values\n",
        "  epochs_score['train_loss'].append(train_loss) #train losss\n",
        "  epochs_score['train_Pearson_score'].append(train_Pearson_score) # pearson correlation\n",
        "\n",
        "\n",
        "  val_loss, val_Pearson_score = model_eval(custom_model, dev_data_loader, device, loss_fn)\n",
        "  print('Validation loss is: {}, Validation_Pearson_score is {}'.format(val_loss,val_Pearson_score))\n",
        "  \n",
        "  #store values\n",
        "  epochs_score['val_loss'].append(val_loss) #train losss\n",
        "  epochs_score['val_Pearson_score'].append(val_Pearson_score) # pearson correlation\n",
        "\n",
        "  #save model with high validaiton score\n",
        "  if val_Pearson_score >  val_score:\n",
        "    val_score = val_Pearson_score\n",
        "    torch.save(custom_model.state_dict(), 'best_model.bin')\n",
        "\n",
        "print()\n",
        "print('Training completed......')\n",
        "epochs_score\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "==========\n",
            "\n",
            "Train loss is: 0.014850491575068897, train_Pearson_score is 0.9095253426930726\n",
            "Validation loss is: 0.029453454192410758, Validation_Pearson_score is 0.8596345902946204\n",
            "Epoch 2/4\n",
            "==========\n",
            "\n",
            "Train loss is: 0.008308044855948538, train_Pearson_score is 0.9507620315805678\n",
            "Validation loss is: 0.028082741582964327, Validation_Pearson_score is 0.8628200338581528\n",
            "Epoch 3/4\n",
            "==========\n",
            "\n",
            "Train loss is: 0.005935145596029341, train_Pearson_score is 0.9658815727894156\n",
            "Validation loss is: 0.028189612146308447, Validation_Pearson_score is 0.8550283151967495\n",
            "Epoch 4/4\n",
            "==========\n",
            "\n",
            "Train loss is: 0.005526766769859629, train_Pearson_score is 0.969138802258031\n",
            "Validation loss is: 0.0281864658315131, Validation_Pearson_score is 0.8579226058427706\n",
            "\n",
            "Training completed......\n",
            "CPU times: user 13min 10s, sys: 6min 49s, total: 20min\n",
            "Wall time: 20min 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM8LYNxMWQan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1au3LlrwHE7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "7a39728a-e11a-4e43-aa18-fe1c7f546878"
      },
      "source": [
        "#plot training and validation score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "train_score = epochs_score['train_Pearson_score'] # train_score\n",
        "valid_score = epochs_score['val_Pearson_score'] # valid_score\n",
        " \n",
        "\n",
        "sns.set(style='darkgrid') #set plot style\n",
        "sns.set(rc={'figure.figsize':(9,6)}) # set figure size\n",
        "plt.plot(train_score ,'-o', label= 'Train_score' )#plot train score\n",
        "plt.plot(valid_score, '-o', label='Valid_score') # plot valid score\n",
        "plt.title('Model Training') #  title\n",
        "plt.ylabel('Pearson Coefficient') # ylabel\n",
        "plt.xlabel('No. of epochs') # xlabel\n",
        "plt.ylim([0.6,1]) #set the ylabel limit\n",
        "plt.legend(loc=4) #label \n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfmfngOm4az8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "b1bf30e9-7a97-4479-c90f-4692884f7d2a"
      },
      "source": [
        "epochs_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(list,\n",
              "            {'train_Pearson_score': [0.9095253426930726,\n",
              "              0.9507620315805678,\n",
              "              0.9658815727894156,\n",
              "              0.969138802258031],\n",
              "             'train_loss': [0.014850491575068897,\n",
              "              0.008308044855948538,\n",
              "              0.005935145596029341,\n",
              "              0.005526766769859629],\n",
              "             'val_Pearson_score': [0.8596345902946204,\n",
              "              0.8628200338581528,\n",
              "              0.8550283151967495,\n",
              "              0.8579226058427706],\n",
              "             'val_loss': [0.029453454192410758,\n",
              "              0.028082741582964327,\n",
              "              0.028189612146308447,\n",
              "              0.0281864658315131]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH6c-4v6FmRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW7EMbm8_bLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWMFCXm1P_pj",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate on test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hCGvi34Mx03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#evaluate on test data\n",
        "test_loss, test_Pearson_score = model_eval(\n",
        "                                      custom_model, \n",
        "                                      test_data_loader, \n",
        "                                      device, \n",
        "                                      loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqMif_hPPveW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a0cc763-af8d-45e2-a12e-1709a535dd81"
      },
      "source": [
        "print(test_loss, test_Pearson_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.030865792506213845 0.8435864555838117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6cfDRC6iEan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#evaluate on test data\n",
        "test_loss, test_Pearson_score = model_eval(\n",
        "                                      custom_model, \n",
        "                                      test_data_loader, \n",
        "                                      device, \n",
        "                                      loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSA41M_ViG7i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "788833a0-0396-4e6c-8764-b8389e02505e"
      },
      "source": [
        "print(test_loss, test_Pearson_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.19161386008577785 0.47228528910939277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9aAcR1qhayQ",
        "colab_type": "text"
      },
      "source": [
        "# Save and Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryrceZodhZQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save model\n",
        "torch.save(custom_model.state_dict(), 'fine_tuned_model_state.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o52SHrJtQFhl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36e53f4c-4823-40f2-dd3c-57d7fcf22df8"
      },
      "source": [
        "#load model and evaluate on test data\n",
        "fine_tuned_model = SentenceSimilarityModel()\n",
        "fine_tuned_model.load_state_dict(torch.load('/content/best_model.bin'))\n",
        "test_loss, test_Pearson_score = model_eval(\n",
        "                                      fine_tuned_model.to(device),\n",
        "                                      test_data_loader, \n",
        "                                      device, \n",
        "                                      loss_fn)\n",
        "print(test_loss, test_Pearson_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.03092721268406202 0.8363047344782726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCfjOQ9LxAMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clear unused GPU\n",
        "with torch.cuda.device('cuda:0'):\n",
        "   torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXV9pXvpxGhS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "98d9ffb6-925b-4fd0-8d3c-d9889420dcf7"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun 30 13:41:20 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    58W / 149W |   2651MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br1EJ76Du1fK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1HQwbw7wQTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}