{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ELMo Semantic Text Similarity",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOt5ViWxKrEAVM4eRSquJSI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/glingden/Natural-Language-Processing-NLP/blob/master/ELMo_Semantic_Text_Similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEoQXujKs2a7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv8PlCFwtLVR",
        "colab_type": "text"
      },
      "source": [
        "# ELMo Semantic Text Similarity\n",
        "In this notebook, the ELMo (original) model is used for finding  semantic text similarity between a pair of sentences.  The [STS_B benchmark](https://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark) dataset is used for this work. This dataset consists of separate training, validation and test data. The [allenlp framework](https://github.com/allenai/allennlp) is used to carry out the work. The work in this notebook contains two parts:\n",
        "1. Sentence level embedding extraction from the pre-trained  model and apply cosine similarity between the pair sentences (No fine-tunned, but only using sentence vector representation from the pretrained model)\n",
        "\n",
        "2. Fine-tune: The STS_B train dataset is used for fine tunning the model and validation dataset is used for model validation. And, the fine-tunned model is used to predict the test dataset. For fine-tunning, Siamese Network with cosine similarity output is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z257XE5jt4vd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAOJH5dVu2sF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import necessary dependencies\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler # minmax scaling\n",
        "from scipy.spatial.distance import cosine #cosine distance\n",
        "from scipy.stats import pearsonr # pearson correlation\n",
        "from scipy.stats import spearmanr # spearman correlation\n",
        "from collections import defaultdict, Counter #store scores\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Dict, Iterable, List, Union #for arugument types\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc5TCFuMvHqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7okYOiguEj_",
        "colab_type": "text"
      },
      "source": [
        "GPU from Google Colab is used in this work. So, check if GPU is avaiable, and if not rasie error. We have to identify and specify GPU as device use it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29n1AjEBuGJF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f60dd51a-9dd0-423c-be21-d03a72f03ca4"
      },
      "source": [
        "#check GPU is available or not \n",
        "if torch.cuda.is_available():\n",
        "\n",
        "  device = torch.device(\"cuda\")\n",
        "  current_dev = torch.cuda.current_device()\n",
        "  print('Found GPU :', torch.cuda.get_device_name(0))\n",
        "  print(current_dev)\n",
        "  \n",
        "\n",
        "else:\n",
        "    print('Not found, use CPU instead')\n",
        "    device = torch.device(\"cpu\")\n",
        "  \n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU : Tesla K80\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIXt0MioucXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aFaxUequbiM",
        "colab_type": "text"
      },
      "source": [
        "#Load Dataset\n",
        "Dataset is stored at Google drive. So, google drive is mounted at '/content/drive' to access them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7my5BW_ueGo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6b4f4bbb-e9c2-4c96-9fd2-75b95f47010a"
      },
      "source": [
        "#mount the drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvF5Gn1PuhPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load dataset\n",
        "dataset_types = [ \"sts-train.csv\", \"sts-dev.csv\", \"sts-test.csv\",] # 3 datasets\n",
        "col_names = [\"genre\", \"file\", \"years\", \"_\", \"score(0-5)\", \"sentence_1\", \"sentence_2\"] #columns names\n",
        "\n",
        "#collect as a list of pandas dataframes\n",
        "df_list = []\n",
        "for dataset in dataset_types:\n",
        "  df = pd.read_csv(\"/content/drive/My Drive/Google_Colab/stsbenchmark_dataset/\"+ dataset, \n",
        "                 delimiter=',' , \n",
        "                 header= None,\n",
        "                 names= col_names\n",
        "                )\n",
        "  \n",
        "\n",
        "  df_list.append(df)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M94UX0W3vXZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "9aa70fdf-b8bc-4336-fa57-e37e4f296731"
      },
      "source": [
        "#separate dataset (train, dev and test)\n",
        "df_train = df_list[0]\n",
        "df_dev = df_list[1]\n",
        "df_test = df_list[2]\n",
        "df_train.sample(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>file</th>\n",
              "      <th>years</th>\n",
              "      <th>_</th>\n",
              "      <th>score(0-5)</th>\n",
              "      <th>sentence_1</th>\n",
              "      <th>sentence_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>MSRvid</td>\n",
              "      <td>2012test</td>\n",
              "      <td>594</td>\n",
              "      <td>3.0</td>\n",
              "      <td>A person is adding food in a pan.</td>\n",
              "      <td>A woman puts rice into a pan.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3685</th>\n",
              "      <td>main-news</td>\n",
              "      <td>deft-news</td>\n",
              "      <td>2014</td>\n",
              "      <td>235</td>\n",
              "      <td>3.2</td>\n",
              "      <td>the north korean government has warned the sou...</td>\n",
              "      <td>the north korean government stated if the sout...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5503</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2015</td>\n",
              "      <td>1388</td>\n",
              "      <td>5.0</td>\n",
              "      <td>US believes Syrian government used chemical we...</td>\n",
              "      <td>US suspects Syria used chemical weapons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1280</th>\n",
              "      <td>main-captions</td>\n",
              "      <td>images</td>\n",
              "      <td>2014</td>\n",
              "      <td>410</td>\n",
              "      <td>3.4</td>\n",
              "      <td>a man on a dirt bike jumping very high.</td>\n",
              "      <td>A man on a motorbike jumping with the sky behi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2238</th>\n",
              "      <td>main-forum</td>\n",
              "      <td>deft-forum</td>\n",
              "      <td>2014</td>\n",
              "      <td>238</td>\n",
              "      <td>2.8</td>\n",
              "      <td>My parents have told me it is bad for you.</td>\n",
              "      <td>My Sheriff has told me its bad for you.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              genre  ...                                         sentence_2\n",
              "392   main-captions  ...                      A woman puts rice into a pan.\n",
              "3685      main-news  ...  the north korean government stated if the sout...\n",
              "5503      main-news  ...            US suspects Syria used chemical weapons\n",
              "1280  main-captions  ...  A man on a motorbike jumping with the sky behi...\n",
              "2238     main-forum  ...            My Sheriff has told me its bad for you.\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWIT6kbjvv8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7xJZN34zSR0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "outputId": "4094f313-4d74-4144-ce99-db0fa3ab6698"
      },
      "source": [
        "#install allen nlp\n",
        "!pip install allennlp"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: allennlp in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.14.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.41.1)\n",
            "Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.12)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n",
            "Requirement already satisfied: spacy<2.3,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.2.4)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.1)\n",
            "Requirement already satisfied: torch<1.6.0,>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.5.1+cu101)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.22.2.post1)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.10.0)\n",
            "Requirement already satisfied: overrides==3.0.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.0)\n",
            "Requirement already satisfied: transformers<2.12,>=2.9 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.11.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n",
            "Requirement already satisfied: jsonnet>=0.10.0; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.16.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.20 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (1.17.20)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.10.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.9.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (8.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (49.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.12.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp) (0.7.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp) (0.4.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.12.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.6.0,>=1.5.0->allennlp) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp) (1.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp) (0.0.43)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp) (0.1.91)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp) (20.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.20->boto3->allennlp) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.20->boto3->allennlp) (0.15.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle->allennlp) (3.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.12,>=2.9->allennlp) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<2.12,>=2.9->allennlp) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IeZVGQzzSVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#allennlp libraries\n",
        "from overrides import overrides\n",
        "from allennlp.data import DatasetReader, Instance, DataLoader, Vocabulary\n",
        "from allennlp.data.fields import  TextField, ArrayField\n",
        "from allennlp.data.fields.text_field import TextFieldTensors\n",
        "from allennlp.data.tokenizers import Tokenizer, SpacyTokenizer, WhitespaceTokenizer\n",
        "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
        "from allennlp.data.samplers import BasicBatchSampler, BucketBatchSampler, RandomSampler\n",
        "from allennlp.modules import Seq2VecEncoder\n",
        "from allennlp.training.metrics import PearsonCorrelation\n",
        "from allennlp.training.util import evaluate \n",
        "from allennlp.nn.util import get_text_field_mask, move_to_device\n",
        "from allennlp.nn import util\n",
        "from allennlp.models import Model\n",
        "from allennlp.predictors import Predictor\n",
        "\n",
        "#elmo module\n",
        "from allennlp.modules.elmo import Elmo, batch_to_ids \n",
        "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
        "from allennlp.modules.token_embedders import ElmoTokenEmbedder\n",
        "from allennlp.data.token_indexers.elmo_indexer import ELMoTokenCharactersIndexer"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbktPEM_zeok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahtrlqrpvY2Q",
        "colab_type": "text"
      },
      "source": [
        "#Count tokens in Sequences\n",
        "Since we have to have equal length of every sequence in a batch, check the maximun token length in every sentences in all datasets. We will use this max length while preparing dataset. More details in 'Prepare dataset' section.\n",
        "\n",
        "Or, we may use the other best max-length. So that there is no risk of loss of much tokens while doing truncating and not require  much padding in the sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwUW7EIqvaCb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "242d8923-61d0-4561-897f-11c820f3f255"
      },
      "source": [
        "#counts tokens in sequences\n",
        "dataset_all = [df_train.sentence_1, df_train.sentence_2, df_dev.sentence_1, df_dev.sentence_2,df_test.sentence_1,df_test.sentence_2] #list of all dataset\n",
        "dataset_type_name = ['df_train.sentence_1', 'df_train.sentence_2', 'df_dev.sentence_1', 'df_dev.sentence_2', 'df_test.sentence_1', 'df_test.sentence_2'] #name of dataset\n",
        "\n",
        "max_len = 0 # tokens max count in overall datasets\n",
        "token_len_list = [] #store token counts for each dataset\n",
        "higest_token_len = {} # store higest token counts in each dataset\n",
        "\n",
        "\n",
        "#zip and iterate over all datasets\n",
        "for nam_data, each_dataset in zip(dataset_type_name, dataset_all):\n",
        "  token_len_dataset = [] #store each sequence count of each dataset\n",
        "  max_len_seq= 0 # max count of  sequence in each dataset \n",
        "\n",
        "  #iterate over sequences in each dataset\n",
        "  for sent in each_dataset:\n",
        "    tokenizer = SpacyTokenizer()# tokenizer\n",
        "    #tokenizer = WhitespaceTokenizer()# tokenizer\n",
        "    tokens = tokenizer.tokenize(sent) #tokenize\n",
        "    tokens_len = len(tokens) # count length\n",
        "    token_len_dataset.append(tokens_len) \n",
        "    \n",
        "    \n",
        "    # keep tracking the higest counts in each dataset\n",
        "    if tokens_len > max_len_seq:\n",
        "      max_len_seq = tokens_len\n",
        "    \n",
        "    #higest count overall dataset\n",
        "    if max_len_seq > max_len:\n",
        "      max_len = max_len_seq\n",
        "       \n",
        "  higest_token_len[nam_data] =  max_len_seq \n",
        "  token_len_list.append(token_len_dataset)\n",
        "\n",
        "print(\"Higest tokens number among 3 datasets: %s .\" % (max_len))\n",
        "print()\n",
        "print('Higest counts in each dataset:\\n')\n",
        "higest_token_len\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Higest tokens number among 3 datasets: 137 .\n",
            "\n",
            "Higest counts in each dataset:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'df_dev.sentence_1': 39,\n",
              " 'df_dev.sentence_2': 37,\n",
              " 'df_test.sentence_1': 37,\n",
              " 'df_test.sentence_2': 34,\n",
              " 'df_train.sentence_1': 135,\n",
              " 'df_train.sentence_2': 137}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udVMh6givdK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yOwV_PK0PDH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "31f8063b-3fba-4982-eba9-4b6f2f428ef8"
      },
      "source": [
        "#Plot the diagram to show the tokens' length distribution in dataset\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# data to plot\n",
        "data = token_len_list \n",
        "\n",
        "#creates subplots  with nrows=3, ncols=2\n",
        "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12,11))\n",
        "sns.set(style='darkgrid') #set plot style\n",
        "\n",
        "#change 'axes' to 1d, zip and emumerate\n",
        "for i, (name, axe)  in enumerate(zip(dataset_type_name, axes.flatten())):\n",
        "  sns.distplot(token_len_list[i], axlabel ='Tokens Count', ax=axe) #distplot type\n",
        "  name = name + ': (tokens_max_count= '+ str(higest_token_len[name]) + ')' #title (for example: df_train.sentence_1:(max_count=70))\n",
        "  axe.set_title(name) #title for each suplots\n",
        "fig.tight_layout()#fit nicely\n",
        "plt.show()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x792 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgbu7Nmd0RFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlEva5jM1xRz",
        "colab_type": "text"
      },
      "source": [
        "#Prepare Dataset\n",
        "Allennlp frame requires their own type of dataset object  while modeling the algorithms. So, \n",
        "we prepare as per the requirement of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOVX-ym-1vV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataset reader class\n",
        "class SemanticTextDataReader(DatasetReader):\n",
        "  '''' Read the dataset and return allennlp instance of  each data '''\n",
        "  def __init__(self, \n",
        "               lazy: bool = False, \n",
        "               tokenizer = None, \n",
        "               token_indexers: Dict[str, TokenIndexer] = None, \n",
        "               max_tokens: int = None\n",
        "               ):\n",
        "    super().__init__(lazy)\n",
        "    self.tokenizer = tokenizer or WhitespaceTokenizer() #tokenizer\n",
        "    self.token_indexers = token_indexers or {'tokens': SingleIdTokenIndexer()} #token indexer\n",
        "    self.max_tokens = max_tokens #set max_tokens for padding or truncating\n",
        "    \n",
        "\n",
        "  #convert given text into instance\n",
        "  @overrides\n",
        "  def text_to_instance(self, sent_1: str, sent_2: str, gold_score: float = None) -> Instance:\n",
        "    ''' Return given sequence into allennlp Instance '''\n",
        "    \n",
        "    #tokenize text\n",
        "    token_1 = self.tokenizer.tokenize(sent_1) #first sent\n",
        "    token_2 = self.tokenizer.tokenize(sent_2) #second sent\n",
        "    \n",
        "    #tokens upto max token-size\n",
        "    if self.max_tokens:\n",
        "            token_1 = token_1[:self.max_tokens]\n",
        "            token_2 = token_2[:self.max_tokens]\n",
        "    \n",
        "    #Textfield\n",
        "    text_field_1 = TextField(token_1, self.token_indexers) \n",
        "    text_field_2 = TextField(token_2, self.token_indexers)\n",
        "\n",
        "    #fields contain 'Textfield' and 'LabelField'\n",
        "    fields = {'first_sent': text_field_1, 'second_sent': text_field_2 } \n",
        "    \n",
        "    #check score/label is given or not\n",
        "    if gold_score is not None:\n",
        "      fields['score'] = ArrayField(np.array([gold_score])) # labelfield\n",
        "   \n",
        "    return Instance(fields) #instance with inputs and outputs fields \n",
        "\n",
        "    \n",
        "  #Read dataset and convert them to Iterable Instance\n",
        "  @overrides\n",
        "  def _read(self, file_path: str) -> Iterable[Instance]:\n",
        "    ''' Read dataset and process them '''\n",
        "    \n",
        "    #read data with pandas\n",
        "    df = pd.read_csv(file_path, \n",
        "              delimiter=',' , \n",
        "              header= None,\n",
        "              names= col_names\n",
        "              )\n",
        "    \n",
        "    #scale down gold-score(0-5) to (0-1) since cosine-simialrity score(0-1)\n",
        "    df['scaled_score(0-1)'] = MinMaxScaler(feature_range=(0,1)).fit_transform(df[['score(0-5)']])\n",
        "    print('Data reading started .....')\n",
        "    \n",
        "    \n",
        "    #iterate over rows in df\n",
        "    for index, row in df.iterrows():\n",
        "      sent_1 = row['sentence_1']#first sent\n",
        "      sent_2 = row['sentence_2']#second sent\n",
        "      gold_score = row['scaled_score(0-1)']#score\n",
        "      yield self.text_to_instance(sent_1, sent_2, gold_score) #iterable\n",
        "\n",
        "    print('...... Completed.')\n",
        "    print()\n",
        "  \n",
        "    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzJXUvFQ2zep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1d113ae9-6f58-40f2-b7ae-bba5374cf433"
      },
      "source": [
        "#Read dataset\n",
        "file_path = \"/content/drive/My Drive/Google_Colab/stsbenchmark_dataset/\" #file path\n",
        "dataset_types = [ \"sts-train.csv\", \"sts-dev.csv\", \"sts-test.csv\",] # 3 datasets\n",
        "col_names = [\"genre\", \"file\", \"years\", \"_\", \"score(0-5)\", \"sentence_1\", \"sentence_2\"] #columns names\n",
        "max_tokens = [137, 39, 37] #max-tokens for each dataset\n",
        "\n",
        "text_tokenizer = SpacyTokenizer() #tokenizer\n",
        "elmo_indexer = ELMoTokenCharactersIndexer() #Elmocharacter Indexer\n",
        "\n",
        "dataset_instances = {}\n",
        "#use max-token length based on data\n",
        "for i ,x in enumerate(dataset_types):\n",
        "  if x == dataset_types[i]:\n",
        "    max_token = max_tokens[i]\n",
        "    dataset_reader = SemanticTextDataReader(tokenizer= text_tokenizer,  token_indexers={'elmo_tokens': elmo_indexer}, max_tokens=max_token) #initia datareader\n",
        "    instances = dataset_reader.read(os.path.join(file_path, dataset_types[i]))\n",
        "    dataset_instances[x]  = instances\n",
        "  \n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "269it [00:00, 1081.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data reading started .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5749it [00:04, 1239.80it/s]\n",
            "164it [00:00, 1639.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "...... Completed.\n",
            "\n",
            "Data reading started .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1500it [00:01, 1092.83it/s]\n",
            "189it [00:00, 1886.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "...... Completed.\n",
            "\n",
            "Data reading started .....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1379it [00:00, 1517.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "...... Completed.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8MrA2wKoOlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPROQ2zj3QTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d84f3d0f-eec8-41ac-f567-870d9995ef3c"
      },
      "source": [
        "#check the dataset instances\n",
        "for x in dataset_instances['sts-train.csv']:\n",
        "  print(x)\n",
        "  break"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Instance with fields:\n",
            " \t first_sent: TextField of length 6 with text: \n",
            " \t\t[A, plane, is, taking, off, .]\n",
            " \t\tand TokenIndexers : {'elmo_tokens': 'ELMoTokenCharactersIndexer'} \n",
            " \t second_sent: TextField of length 7 with text: \n",
            " \t\t[An, air, plane, is, taking, off, .]\n",
            " \t\tand TokenIndexers : {'elmo_tokens': 'ELMoTokenCharactersIndexer'} \n",
            " \t score: ArrayField with shape: (1,) and dtype: <class 'numpy.float32'>. \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuhHumosAOT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHsg8zKGkgGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2E6cSkQBjNk",
        "colab_type": "text"
      },
      "source": [
        "#Prepare Vocabulary and DataLoader\n",
        "Eventhough we don't have to make new vocabulary here, we have to create vocab object and have to do indexing to all the dataset instances. So, each token/character get certain index(integer value) according to ELMO pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HztJShABBl12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "vocab = Vocabulary() #initiate vocabulary \n",
        "dataset_instances['sts-train.csv'].index_with(vocab) #token indexing \n",
        "dataset_instances['sts-dev.csv'].index_with(vocab)\n",
        "dataset_instances['sts-test.csv'].index_with(vocab)\n",
        "\n",
        "#random sample and batch train data\n",
        "sampler_tr = RandomSampler(data_source=dataset_instances['sts-train.csv']) \n",
        "batch_sampler_tr = BasicBatchSampler(sampler_tr, batch_size=32, drop_last=False) \n",
        "train_data_loader = DataLoader(dataset_instances['sts-train.csv'], batch_sampler=batch_sampler_tr)\n",
        "\n",
        "#batch dev data\n",
        "dev_data_loader = DataLoader(dataset_instances['sts-dev.csv'], batch_size=32,)\n",
        "\n",
        "#batch test data\n",
        "test_data_loader = DataLoader(dataset_instances['sts-test.csv'], batch_size=32,) \n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUKAhw9RsoPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOEz12AaB-L7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "160db3f4-364d-4b90-ae55-f68905a2e902"
      },
      "source": [
        "#check train dataloader \n",
        "batch = next(iter(train_data_loader))\n",
        "batch"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'first_sent': {'elmo_tokens': {'elmo_tokens': tensor([[[259,  83, 102,  ..., 261, 261, 261],\n",
              "            [259, 106, 111,  ..., 261, 261, 261],\n",
              "            [259,  67, 112,  ..., 261, 261, 261],\n",
              "            ...,\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0]],\n",
              "   \n",
              "           [[259,  66, 260,  ..., 261, 261, 261],\n",
              "            [259, 120, 112,  ..., 261, 261, 261],\n",
              "            [259, 106, 116,  ..., 261, 261, 261],\n",
              "            ...,\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0]],\n",
              "   \n",
              "           [[259,  85, 105,  ..., 261, 261, 261],\n",
              "            [259,  52,  49,  ..., 261, 261, 261],\n",
              "            [259,  99, 112,  ..., 261, 261, 261],\n",
              "            ...,\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0]],\n",
              "   \n",
              "           ...,\n",
              "   \n",
              "           [[259,  84, 118,  ..., 261, 261, 261],\n",
              "            [259,  99, 112,  ..., 261, 261, 261],\n",
              "            [259, 108, 106,  ..., 261, 261, 261],\n",
              "            ...,\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0]],\n",
              "   \n",
              "           [[259,  81,  98,  ..., 261, 261, 261],\n",
              "            [259,  40, 116,  ..., 261, 261, 261],\n",
              "            [259,  78, 118,  ..., 261, 261, 261],\n",
              "            ...,\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0]],\n",
              "   \n",
              "           [[259,  87, 112,  ..., 261, 261, 261],\n",
              "            [259, 102, 115,  ..., 261, 261, 261],\n",
              "            [259, 106, 111,  ..., 261, 261, 261],\n",
              "            ...,\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0]]])}},\n",
              " 'score': tensor([[0.4800],\n",
              "         [0.2000],\n",
              "         [0.4000],\n",
              "         [0.0000],\n",
              "         [0.7200],\n",
              "         [0.3600],\n",
              "         [0.8000],\n",
              "         [0.1600],\n",
              "         [1.0000],\n",
              "         [0.4400],\n",
              "         [0.6800],\n",
              "         [0.8800],\n",
              "         [0.9200],\n",
              "         [0.5600],\n",
              "         [0.0400],\n",
              "         [0.5200],\n",
              "         [0.4400],\n",
              "         [0.8000],\n",
              "         [0.0000],\n",
              "         [0.8400],\n",
              "         [0.7600],\n",
              "         [0.1000],\n",
              "         [0.4800],\n",
              "         [0.7000],\n",
              "         [0.4800],\n",
              "         [0.6000],\n",
              "         [0.6666],\n",
              "         [0.7000],\n",
              "         [1.0000],\n",
              "         [0.3600],\n",
              "         [0.4800],\n",
              "         [0.6000]]),\n",
              " 'second_sent': {'elmo_tokens': {'elmo_tokens': tensor([[[259,  81, 112,  ..., 261, 261, 261],\n",
              "            [259, 100, 112,  ..., 261, 261, 261],\n",
              "            [259, 105, 112,  ..., 261, 261, 261],\n",
              "            ...,\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0]],\n",
              "   \n",
              "           [[259,  66, 260,  ..., 261, 261, 261],\n",
              "            [259, 120, 112,  ..., 261, 261, 261],\n",
              "            [259, 106, 116,  ..., 261, 261, 261],\n",
              "            ...,\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0]],\n",
              "   \n",
              "           [[259,  85, 105,  ..., 261, 261, 261],\n",
              "            [259,  52,  49,  ..., 261, 261, 261],\n",
              "            [259,  99, 112,  ..., 261, 261, 261],\n",
              "            ...,\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0]],\n",
              "   \n",
              "           ...,\n",
              "   \n",
              "           [[259,  84, 118,  ..., 261, 261, 261],\n",
              "            [259,  99, 112,  ..., 261, 261, 261],\n",
              "            [259, 108, 106,  ..., 261, 261, 261],\n",
              "            ...,\n",
              "            [259, 240, 192,  ..., 261, 261, 261],\n",
              "            [259, 116, 260,  ..., 261, 261, 261],\n",
              "            [259,  87, 112,  ..., 261, 261, 261]],\n",
              "   \n",
              "           [[259,  81,  98,  ..., 261, 261, 261],\n",
              "            [259,  40, 116,  ..., 261, 261, 261],\n",
              "            [259,  78, 118,  ..., 261, 261, 261],\n",
              "            ...,\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0]],\n",
              "   \n",
              "           [[259,  87, 112,  ..., 261, 261, 261],\n",
              "            [259, 102, 115,  ..., 261, 261, 261],\n",
              "            [259, 100, 109,  ..., 261, 261, 261],\n",
              "            ...,\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0],\n",
              "            [  0,   0,   0,  ...,   0,   0,   0]]])}}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oobyFOSCAJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI3E7btXDbKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7ALUhpHDcIN",
        "colab_type": "text"
      },
      "source": [
        "# ElMo CharacterTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtRQ4oCnCWvt",
        "colab_type": "text"
      },
      "source": [
        "In ELMo, as like other  pretained model, the sequence is tokenized. And, the tokenized token is further splited into characters  with of 50 dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pkQiMqICP8m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d83d5c24-b94e-4ecb-a319-cbb8b6454e40"
      },
      "source": [
        "#a single batch contains collection of tokens and  single token is ocnverted into array of  character ids of 50 size\n",
        "print('Batch shape :', batch['first_sent']['elmo_tokens']['elmo_tokens'].shape) #(batch size, token length, char dim)\n",
        "print()\n",
        "print('tokens in a sequence: ')\n",
        "batch['first_sent']['elmo_tokens']['elmo_tokens'][0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch shape : torch.Size([32, 30, 50])\n",
            "\n",
            "tokens in a sequence: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[259, 117, 105,  ..., 261, 261, 261],\n",
              "        [259, 118, 111,  ..., 261, 261, 261],\n",
              "        [259, 116, 117,  ..., 261, 261, 261],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ...,   0,   0,   0],\n",
              "        [  0,   0,   0,  ...,   0,   0,   0],\n",
              "        [  0,   0,   0,  ...,   0,   0,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvg3MaiFtsMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLg-72Bet2MD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyIx1Ymyt5Cb",
        "colab_type": "text"
      },
      "source": [
        "#Part-1 ELMo Embedding Extraction\n",
        "Extract sentence level embedding is extracted with mean pooling over tokens in a sentence. The original elmo model is used  and the cosine similarity between a pair of sentence is calculated.  And, finally the pearson and spearman correlation score is computed between the gold-score and computed cosine similarity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b2kjD8Vk6Xv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "73715ea9-5c48-4a7b-9687-623f3c159eed"
      },
      "source": [
        "weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'\n",
        "options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json'\n",
        " \n",
        "#Two ways  ELMo representation can be computated in Allennlp\n",
        "# 1. ElmoTokenEmbeder \n",
        "elmo_embedding = ElmoTokenEmbedder(options_file = options_file, weight_file = weight_file, requires_grad = False)\n",
        "word_embedding = BasicTextFieldEmbedder({\"elmo_tokens\": elmo_embedding}) \n",
        "\n",
        "#2. direclty Elmo module\n",
        "elmo_embedder = Elmo( options_file, \n",
        "                     weight_file,\n",
        "                     num_output_representations =1,\n",
        "                     requires_grad = False,\n",
        "                     ) "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 336/336 [00:00<00:00, 879155.42B/s]\n",
            "100%|██████████| 374434792/374434792 [00:08<00:00, 43413757.97B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlaNiLRkw-c0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLTYc79Ew-4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data loader\n",
        "#extract embedding, calcuate pearson and spearman correlation\n",
        "def batch_elmo_embedder(dataset: DataLoader, elmo_embedder: BasicTextFieldEmbedder, cos:nn.CosineSimilarity):\n",
        "  pear_score_list = [] #pearson score\n",
        "  sperman_score_list = [] # sperman score \n",
        "  '''\n",
        "  elmo_embeded_1 = torch.tensor([]) #store embedding\n",
        "  elmo_embeded_2 = torch.tensor([])\n",
        "  gold_score = torch.tensor([])#gold score '''\n",
        "\n",
        "  #iterate over each batchs\n",
        "  for batch in dataset:\n",
        "    \n",
        "    #first sentence\n",
        "    elmo_embeding_1 = elmo_embedder(batch['first_sent']['tokens']['elmo_tokens']) #return token embeding and mask\n",
        "    token_level_embedding_1 = elmo_embeding_1['elmo_representations'][0] # token embedding\n",
        "    sent_level_embedding_1 = token_level_embedding_1.mean(dim=1) # tokens mean pooling\n",
        "    \n",
        "\n",
        "    #second sentence\n",
        "    elmo_embeding_2 = elmo_embedder(batch['second_sent']['tokens']['elmo_tokens']) #return token embeding and mask\n",
        "    token_level_embedding_2 = elmo_embeding_2['elmo_representations'][0] # token embedding\n",
        "    sent_level_embedding_2 = token_level_embedding_2.mean(dim=1) # tokens mean pooling\n",
        "    \n",
        "    #gold score\n",
        "    score = batch['score']\n",
        "    score = score.flatten() # 1d\n",
        "    \n",
        "    '''\n",
        "    elmo_embeded_1 = torch.cat((elmo_embeded, sent_level_embedding_1,), dim= 0 ) #concat embdding\n",
        "    elmo_embeded_2 = torch.cat((elmo_embeded, sent_level_embedding_1,), dim= 0 ) #concat embdding\n",
        "    gold_score = torch.cat((gold_score, score), dim= 0 ) #concat embdding '''\n",
        "    \n",
        "    #calculate cosine similarity between a pair of sentences\n",
        "    cosine_sim = cos(sent_level_embedding_1, sent_level_embedding_2)\n",
        "    cosine_sim = cosine_sim.flatten().detach() #numpy\n",
        " \n",
        "    #calcualte Pearson score\n",
        "    person_score, _ = pearsonr(score, cosine_sim) \n",
        "    pear_score_list.append(person_score)\n",
        "  \n",
        "    #calcualte Spearman score\n",
        "    sperman_score, _ = spearmanr(score, cosine_sim) \n",
        "    sperman_score_list.append(sperman_score)\n",
        "  \n",
        "  return np.mean(pear_score_list), np.mean(sperman_score_list)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hokNQor_VB4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc5396a1-60d6-4d13-a267-bb21b27adb54"
      },
      "source": [
        "#compute pearsons and spearman\n",
        "cos = cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "batch_elmo_embedder(test_data_loader, elmo_embedder, cos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.42302950514719806, 0.39722409909301976)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFMsdaFyFo39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl3NDxONt-ZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPaJB8jNurLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#extract elmo embedding from list of string\n",
        "def elmo_feature_embedding(data: List[str], \n",
        "                           elmo_embedder: BasicTextFieldEmbedder,\n",
        "                           tokenizer: Tokenizer, \n",
        "                           token_indexer: ELMoTokenCharactersIndexer, \n",
        "                           vocab: Vocabulary\n",
        "                           ):\n",
        "  '''\n",
        "  Extract elmo embedding of given sequence.\n",
        "\n",
        "    Args:\n",
        "      data(list): list of strings/sequences\n",
        "      elmo_embedder: allennlp elmo TextField embedder object\n",
        "      tokenizer: allennlp SpacyTokenizer object\n",
        "      token_indexer: allennlp ELMoTokenCharactersIndexer object\n",
        "      vocab: allennlp vocabualry object\n",
        "\n",
        "    Returns:\n",
        "       Sentence embedding(2d) of 1024 dimensions\n",
        "  \n",
        "  '''\n",
        "\n",
        "  #empty array to store elmo embedding vectors\n",
        "  sent_embedded = np.empty((0, 1024)) # size(,1024) \n",
        "  \n",
        "  #iterate over sequence \n",
        "  for sequence in data:\n",
        "    tokens = tokenizer.tokenize(sequence) # tokenize sequence\n",
        "    text_field = TextField(tokens, {'elmo_tokens': token_indexer}) #tokens to ELMoTokenCharactersIndexer\n",
        "    text_field.index(vocab) #character_ids based on vocab\n",
        "    padding_lengths = text_field.get_padding_lengths() # get tokens length\n",
        "    tensor_dict = text_field.as_tensor(padding_lengths) #change to TextFieldTensors\n",
        "    batch_tensor_dict = text_field.batch_tensors([tensor_dict]) # batch_tensor\n",
        "    elmo_embedded = elmo_embedder(batch_tensor_dict)# get token embedding\n",
        "    mean_tokens_embed = elmo_embedded.mean(dim=1)# mean pooling over tokens\n",
        "    sent_embedded = np.append(sent_embedded, mean_tokens_embed.detach().numpy(), axis=0) # append vertically\n",
        "    \n",
        "  return sent_embedded\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rokj7D-g6VDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to calculate similarity score \n",
        "def calc_similarity_score(embed_1, embed_2):\n",
        "\n",
        "  \"\"\"\n",
        "  Calcualte cosine simialrity between a pair of sentences.\n",
        "  \n",
        "    Args:\n",
        "      embed_1(numpy array): first sentence embedding\n",
        "      embed_2(numpy array): second sentence embedding\n",
        "\n",
        "    Return:\n",
        "      scaled_cosine_score(list) : cosine score between embed_1 \n",
        "      and embed_2 with range (0,5)\n",
        "  \"\"\"\n",
        "  \n",
        "  #collect similarity score\n",
        "  cosine_sim_score = []\n",
        "  \n",
        "  for x,y in zip(embed_1, embed_2):\n",
        "\n",
        "    distance = cosine(x, y) # cosine distance\n",
        "    cosine_sim = 1 - distance # cosine similarity\n",
        "    cosine_sim_score.append(cosine_sim) \n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  #scaled the similarity score to (0,5)\n",
        "  scaler = MinMaxScaler(feature_range=(0,5)) # initiate minmaxscaler\n",
        "  scaled_cosine_score = scaler.fit_transform(np.transpose([cosine_sim_score])) #scaled to (0,5)\n",
        "  \n",
        "  return scaled_cosine_score.round(3)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DpMNaMK7KRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculate pearson and spearman correlation\n",
        "def cal_pearson_spearman_score(x, y):\n",
        "  '''\n",
        "  Calculate Pearson and Spearman correlation between x, y.\n",
        "  Agrs:\n",
        "    x: array_like\n",
        "    y: array_like\n",
        "\n",
        "  Returns:\n",
        "    Pearson and Spearman score\n",
        "  '''\n",
        "\n",
        "  pearson_score, _ = pearsonr(x, y)#pearson score\n",
        "  sperman_score, _ = spearmanr(x, y)#spearman score\n",
        "\n",
        "  return pearson_score , sperman_score\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMc8Dbg2fLbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FT-J-9IusW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initiate necessary class object\n",
        "text_tokenizer = SpacyTokenizer() #tokenizer\n",
        "elmo_indexer = ELMoTokenCharactersIndexer() #character Indexer\n",
        "vocab = Vocabulary()# initiate vocab\n",
        "\n",
        "elmo_token_embedder = ElmoTokenEmbedder(options_file, weight_file) #elmo token embedder\n",
        "elmo_textfield_embedder = BasicTextFieldEmbedder({\"elmo_tokens\": elmo_token_embedder}) #textfield embedder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKsqXqz9u5Px",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7083ae85-e6df-4447-d830-1e016c650b71"
      },
      "source": [
        "%%time\n",
        "#extract embedding\n",
        "dev_first_sent_emlo_embeded = elmo_feature_embedding(df_dev.sentence_1.values.tolist(), elmo_textfield_embedder, text_tokenizer, elmo_indexer, vocab )\n",
        "dev_second_sent_emlo_embeded = elmo_feature_embedding(df_dev.sentence_2.values.tolist(), elmo_textfield_embedder, text_tokenizer, elmo_indexer, vocab )\n",
        "test_first_sent_emlo_embeded = elmo_feature_embedding(df_test.sentence_1.values.tolist(), elmo_textfield_embedder, text_tokenizer, elmo_indexer, vocab )\n",
        "test_second_sent_emlo_embeded = elmo_feature_embedding(df_test.sentence_2.values.tolist(), elmo_textfield_embedder, text_tokenizer, elmo_indexer, vocab )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 46min 47s, sys: 2.57 s, total: 46min 50s\n",
            "Wall time: 46min 54s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbz6DqF8vG9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPciWGOgvSVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "754eac9d-f405-436a-ea8e-9822c6717b06"
      },
      "source": [
        "#calcualte cosine similarity, pearson and spearman score\n",
        "elmo_pear_spear_score = defaultdict(list) #store scores\n",
        "\n",
        "dev_cos = calc_similarity_score(dev_first_sent_emlo_embeded, dev_second_sent_emlo_embeded).flatten()\n",
        "dev_pear, dev_spear = cal_pearson_spearman_score(dev_cos, df_dev.loc[:,'score(0-5)'].values )\n",
        "elmo_pear_spear_score['dev'].append(dev_pear)\n",
        "elmo_pear_spear_score['dev'].append(dev_pear)\n",
        "print('Dev data: Pearson score: {}, Spearman score: {}'.format(dev_pear,dev_spear))\n",
        "\n",
        "test_cos = calc_similarity_score(test_first_sent_emlo_embeded, test_second_sent_emlo_embeded).flatten()\n",
        "test_pear, test_spear = cal_pearson_spearman_score(test_cos, df_test.loc[:,'score(0-5)'].values )\n",
        "print('Test data: Pearson score: {}, Spearman score: {}'.format(test_pear,test_spear))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dev data: Pearson score: 0.6167761548996509, Spearman score: 0.6267256240989642\n",
            "Test data: Pearson score: 0.4737381895764178, Spearman score: 0.4499075352319293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VJjmWiKvVrj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "57341cad-820d-4d1e-ab66-1e1d96e4430c"
      },
      "source": [
        "#show in panda dataframe\n",
        "pd.DataFrame.from_dict({'Pearson': [dev_pear, test_pear ] , 'Spearman': [ dev_spear,test_spear ]},\n",
        "                          orient='index',\n",
        "                          columns=['Dev_Data', 'Test_Data']\n",
        "                          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dev_Data</th>\n",
              "      <th>Test_Data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Pearson</th>\n",
              "      <td>0.616776</td>\n",
              "      <td>0.473738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Spearman</th>\n",
              "      <td>0.626726</td>\n",
              "      <td>0.449908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Dev_Data  Test_Data\n",
              "Pearson   0.616776   0.473738\n",
              "Spearman  0.626726   0.449908"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LnbnszwyPYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg4CyVqHyQpA",
        "colab_type": "text"
      },
      "source": [
        "#Part-2: ELMO Fine-Tune\n",
        "We have used Siamese network structure to fine-tune the ELMO orginal pretrained model. The MSELos is used as loss function. The cosine similarity is used as output of the model. Pearsons correlation is used for model metric to evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4X4lMtSySxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define custom model for elmo fine-tuning\n",
        "class ElmoSentenceSimilarityModel(Model):\n",
        "  \"\"\" \n",
        "  Extract sentence embedding by meaning pooling over tokens in a sentence.\n",
        "  And, Calculate cosine similarity between extracted embeding of a pair of sentences.\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, encoder:Seq2VecEncoder, vocab: Vocabulary, model_type: str):\n",
        "    super().__init__(vocab)\n",
        "    weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'\n",
        "    options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json'\n",
        "    self.elmo_embedding = Elmo(options_file=options_file, \n",
        "                              weight_file=weight_file,\n",
        "                              num_output_representations =1,\n",
        "                              requires_grad = True,\n",
        "                              #scalar_mix_parameters=[0.0, 0.0, 20.0]\n",
        "                              )\n",
        "    \n",
        "    elmo_embedding = ElmoTokenEmbedder(options_file = options_file, weight_file = weight_file, requires_grad = True)\n",
        "    self.word_embedding = BasicTextFieldEmbedder({\"elmo_tokens\": elmo_embedding})\n",
        "    self.encoder = encoder\n",
        "    self.model_type = model_type\n",
        "    self.pearson = PearsonCorrelation( )\n",
        "    self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "    self.loss = nn.MSELoss( )\n",
        "    \n",
        "    \n",
        "  #Evalutate, and computes the loss\n",
        "  def forward(self, first_sent: TextFieldTensors, second_sent: TextFieldTensors, score: torch.Tensor=None):\n",
        "    #print('Computed with', self.model_type)\n",
        "\n",
        "    #with Elmo module\n",
        "    if self.model_type =='BasicTextFieldEmbedder':\n",
        "      \n",
        "      #self.elmo_embedding = self.elmo_embedding.to(device) #gpu\n",
        "\n",
        "      #first sentence embedding\n",
        "      first_token_ids = first_sent['elmo_tokens']['elmo_tokens'].to(device) #move to gpu\n",
        "      first_embedding = self.elmo_embedding(first_token_ids) #first sentence\n",
        "      first_tokens_embed = first_embedding['elmo_representations'][0] #token embedding\n",
        "      first_sent_embed = first_tokens_embed.mean(dim=1) # sentence embedding --> mean pooling over tokens\n",
        "      \n",
        "      #second sentence embedding\n",
        "      second_token_ids = second_sent['elmo_tokens']['elmo_tokens'].to(device)\n",
        "      second_embedding = self.elmo_embedding(second_token_ids) #second sentence\n",
        "      second_tokens_embed = second_embedding['elmo_representations'][0] \n",
        "      second_sent_embed = second_tokens_embed.mean(dim=1)\n",
        "      \n",
        "   #with ElmoTextFieldEmbedder\n",
        "    elif self.model_type == 'Elmo':\n",
        "      \n",
        "      #first sentence\n",
        "      first_sent = move_to_device(first_sent, device)#gpu\n",
        "      first_embedding = self.word_embedding(first_sent)#get embedding\n",
        "      first_mask = get_text_field_mask(first_sent)#get mask\n",
        "      first_sent_embed = self.encoder(first_embedding,first_mask)#encoder\n",
        "      \n",
        "      #second sentence\n",
        "      second_sent = move_to_device(second_sent, device)\n",
        "      second_embedding = self.word_embedding(second_sent) \n",
        "      second_mask = get_text_field_mask(second_sent)\n",
        "      second_sent_embed = self.encoder(second_embedding,second_mask) \n",
        "\n",
        "    else:\n",
        "      return \"Enter model_type: 'Elmo' or 'BasicTextFieldEmbedder'\"\n",
        "\n",
        "\n",
        "    #cosine similarity\n",
        "    cosine_sim = self.cos(first_sent_embed, second_sent_embed)\n",
        "    \n",
        "    #output \n",
        "    output = {'cos_sim': cosine_sim.detach().cpu().numpy() }\n",
        "    \n",
        "    #check if glod label is given\n",
        "    if score is not None:\n",
        "       gold_score = score.to(device).flatten() #gold score\n",
        "       \n",
        "       #compute loss\n",
        "       loss = self.loss(cosine_sim, gold_score) \n",
        "       output['loss'] = loss \n",
        "\n",
        "       #compute metric (pearson correlation)\n",
        "       self.pearson(cosine_sim, gold_score) \n",
        "\n",
        "    return output\n",
        "  \n",
        "  #get metric score\n",
        "  def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
        "        return {'pearson(r)': self.pearson.get_metric(reset)}\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjNylIGNmSWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "0b2f4a6e-0080-48a1-ff58-7092ebbe11f7"
      },
      "source": [
        "#test the model\n",
        "our_model = ElmoSentenceSimilarityModel(seq2vec, vocab, 'BasicTextFieldEmbedder')\n",
        "our_model= our_model.to(device)\n",
        "our_model.forward(batch['first_sent'], batch['second_sent'])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computated using BasicTextFieldEmbedder!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cos_sim': array([0.71767837, 0.4840387 , 0.5784778 , 0.5688363 , 0.8238631 ,\n",
              "        0.49422294, 0.6748473 , 0.66733736, 0.47579944, 0.58670837,\n",
              "        0.62128097, 0.5984307 , 0.6032391 , 0.41196772, 0.67139107,\n",
              "        0.57306653, 0.57381994, 0.5746926 , 0.6337103 , 0.5490279 ,\n",
              "        0.5638805 , 0.59083086, 0.5465851 , 0.6107117 , 0.5181722 ,\n",
              "        0.43171626, 0.5952812 , 0.71191853, 0.27890387, 0.75662214,\n",
              "        0.774285  , 0.7628022 ], dtype=float32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoJxuzdkoil1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPbPJpP8ir3l",
        "colab_type": "text"
      },
      "source": [
        "#Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7QqHTOlzML2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training setup\n",
        "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, BagOfEmbeddingsEncoder\n",
        "from allennlp.training.trainer import Trainer, GradientDescentTrainer\n",
        "from allennlp.training import TensorboardWriter\n",
        "import torch.optim as optim\n",
        "from allennlp.training.optimizers import AdamOptimizer\n",
        "from allennlp.common import JsonDict\n",
        "\n",
        "#encoder\n",
        "seq2vec = BagOfEmbeddingsEncoder(embedding_dim=1024, averaged=True)\n",
        "\n",
        "#initiate our model\n",
        "emodel = ElmoSentenceSimilarityModel(seq2vec, vocab, 'BasicTextFieldEmbedder')\n",
        "#emodel = ElmoSentenceSimilarityModel(seq2vec, vocab, 'Elmo')\n",
        "emodel = emodel.to(device)#gpu\n",
        "\n",
        "#tbw = TensorboardWriter()\n",
        "parameters = [[n, p]for n, p in emodel.named_parameters() if p.requires_grad]\n",
        "\n",
        "#optimizer = optim.Adam(params=emodel.parameters(), lr=0.003) #optimizer\n",
        "optimizer = AdamOptimizer(model_parameters=parameters,  lr=0.003) #optimizer\n",
        "serialization_dir = '/content/drive/My Drive/Google_Colab/Elmo' #location to save result\n",
        "\n",
        "#training setup\n",
        "trainer = GradientDescentTrainer(       \n",
        "    model=emodel,\n",
        "    serialization_dir=serialization_dir,\n",
        "    data_loader = train_data_loader,\n",
        "    validation_data_loader = dev_data_loader,\n",
        "    num_epochs = 10,\n",
        "    optimizer = optimizer,\n",
        "    cuda_device = 0,\n",
        "    #tensorboard_writer = tbw,\n",
        "    )"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ao7HEDvn154",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvHZ-V2tzYTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logging.getLogger().setLevel(logging.CRITICAL)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXm7vJeOtxLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "ba4bfbaa-0e06-4f98-8df3-d3355bcef426"
      },
      "source": [
        "%%time\n",
        "print(\"Starting training\\n\")\n",
        "train = trainer.train()\n",
        "print(\"\\nFinished training\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting training\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "pearson(r): 0.4313, loss: 0.0724, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [03:22<00:00,  1.12s/it]\n",
            "pearson(r): 0.5649, loss: 0.1541, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:08<00:00,  5.23it/s]\n",
            "pearson(r): 0.5764, loss: 0.0573, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [03:24<00:00,  1.13s/it]\n",
            "pearson(r): 0.5732, loss: 0.1385, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:08<00:00,  5.37it/s]\n",
            "pearson(r): 0.5120, loss: 0.0652, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [03:20<00:00,  1.11s/it]\n",
            "pearson(r): 0.5633, loss: 0.1612, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:08<00:00,  5.36it/s]\n",
            "pearson(r): 0.6536, loss: 0.0495, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [03:24<00:00,  1.13s/it]\n",
            "pearson(r): 0.5505, loss: 0.1528, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:08<00:00,  5.38it/s]\n",
            "pearson(r): 0.7232, loss: 0.0418, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [03:23<00:00,  1.13s/it]\n",
            "pearson(r): 0.5638, loss: 0.1464, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:08<00:00,  5.36it/s]\n",
            "pearson(r): 0.7673, loss: 0.0364, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [03:23<00:00,  1.13s/it]\n",
            "pearson(r): 0.5742, loss: 0.1426, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:08<00:00,  5.38it/s]\n",
            "pearson(r): 0.8072, loss: 0.0314, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [03:21<00:00,  1.12s/it]\n",
            "pearson(r): 0.5781, loss: 0.1381, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:08<00:00,  5.37it/s]\n",
            "pearson(r): 0.8263, loss: 0.0287, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [03:24<00:00,  1.13s/it]\n",
            "pearson(r): 0.5744, loss: 0.1290, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:08<00:00,  5.36it/s]\n",
            "pearson(r): 0.8431, loss: 0.0263, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [03:24<00:00,  1.13s/it]\n",
            "pearson(r): 0.5731, loss: 0.1307, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:08<00:00,  5.38it/s]\n",
            "pearson(r): 0.8538, loss: 0.0248, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [03:22<00:00,  1.12s/it]\n",
            "pearson(r): 0.5727, loss: 0.1186, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:08<00:00,  5.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Finished training\n",
            "CPU times: user 29min 51s, sys: 5min 29s, total: 35min 21s\n",
            "Wall time: 36min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ5_DkGao5Lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQle25Fro6WW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0498534-b9ca-4e9c-fb2a-d0f4fd011b51"
      },
      "source": [
        "%%time\n",
        "print(\"Starting training\\n\")\n",
        "train = trainer.train()\n",
        "print(\"\\nFinished training\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/180 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting training\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "pearson(r): 0.3972, loss: 0.0783, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [06:55<00:00,  1.91s/it]\n",
            "pearson(r): 0.3972, loss: 0.0783, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [06:55<00:00,  2.31s/it]\n",
            "\n",
            "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.6165, loss: 0.0844, reg_loss: 0.0000 ||:   2%|▏         | 1/47 [00:00<00:12,  3.79it/s]\u001b[A\n",
            "pearson(r): 0.5935, loss: 0.0982, reg_loss: 0.0000 ||:   4%|▍         | 2/47 [00:00<00:12,  3.65it/s]\u001b[A\n",
            "pearson(r): 0.6192, loss: 0.0973, reg_loss: 0.0000 ||:   6%|▋         | 3/47 [00:00<00:12,  3.42it/s]\u001b[A\n",
            "pearson(r): 0.6275, loss: 0.1205, reg_loss: 0.0000 ||:   9%|▊         | 4/47 [00:01<00:12,  3.34it/s]\u001b[A\n",
            "pearson(r): 0.6108, loss: 0.1173, reg_loss: 0.0000 ||:  11%|█         | 5/47 [00:01<00:12,  3.49it/s]\u001b[A\n",
            "pearson(r): 0.6133, loss: 0.1141, reg_loss: 0.0000 ||:  13%|█▎        | 6/47 [00:01<00:12,  3.37it/s]\u001b[A\n",
            "pearson(r): 0.5936, loss: 0.1271, reg_loss: 0.0000 ||:  15%|█▍        | 7/47 [00:02<00:12,  3.29it/s]\u001b[A\n",
            "pearson(r): 0.5950, loss: 0.1322, reg_loss: 0.0000 ||:  17%|█▋        | 8/47 [00:02<00:12,  3.08it/s]\u001b[A\n",
            "pearson(r): 0.5813, loss: 0.1371, reg_loss: 0.0000 ||:  19%|█▉        | 9/47 [00:02<00:13,  2.90it/s]\u001b[A\n",
            "pearson(r): 0.5884, loss: 0.1387, reg_loss: 0.0000 ||:  21%|██▏       | 10/47 [00:03<00:13,  2.80it/s]\u001b[A\n",
            "pearson(r): 0.5895, loss: 0.1341, reg_loss: 0.0000 ||:  23%|██▎       | 11/47 [00:03<00:13,  2.63it/s]\u001b[A\n",
            "pearson(r): 0.5878, loss: 0.1352, reg_loss: 0.0000 ||:  26%|██▌       | 12/47 [00:04<00:13,  2.56it/s]\u001b[A\n",
            "pearson(r): 0.5793, loss: 0.1396, reg_loss: 0.0000 ||:  28%|██▊       | 13/47 [00:04<00:13,  2.49it/s]\u001b[A\n",
            "pearson(r): 0.5895, loss: 0.1389, reg_loss: 0.0000 ||:  30%|██▉       | 14/47 [00:04<00:13,  2.49it/s]\u001b[A\n",
            "pearson(r): 0.5797, loss: 0.1443, reg_loss: 0.0000 ||:  32%|███▏      | 15/47 [00:05<00:13,  2.43it/s]\u001b[A\n",
            "pearson(r): 0.5707, loss: 0.1493, reg_loss: 0.0000 ||:  34%|███▍      | 16/47 [00:05<00:12,  2.40it/s]\u001b[A\n",
            "pearson(r): 0.5642, loss: 0.1479, reg_loss: 0.0000 ||:  36%|███▌      | 17/47 [00:06<00:12,  2.35it/s]\u001b[A\n",
            "pearson(r): 0.5644, loss: 0.1500, reg_loss: 0.0000 ||:  38%|███▊      | 18/47 [00:06<00:12,  2.37it/s]\u001b[A\n",
            "pearson(r): 0.5718, loss: 0.1499, reg_loss: 0.0000 ||:  40%|████      | 19/47 [00:07<00:11,  2.36it/s]\u001b[A\n",
            "pearson(r): 0.5610, loss: 0.1542, reg_loss: 0.0000 ||:  43%|████▎     | 20/47 [00:07<00:12,  2.18it/s]\u001b[A\n",
            "pearson(r): 0.5517, loss: 0.1586, reg_loss: 0.0000 ||:  45%|████▍     | 21/47 [00:08<00:12,  2.03it/s]\u001b[A\n",
            "pearson(r): 0.5385, loss: 0.1631, reg_loss: 0.0000 ||:  47%|████▋     | 22/47 [00:08<00:12,  1.93it/s]\u001b[A\n",
            "pearson(r): 0.5286, loss: 0.1650, reg_loss: 0.0000 ||:  49%|████▉     | 23/47 [00:09<00:12,  1.85it/s]\u001b[A\n",
            "pearson(r): 0.5144, loss: 0.1694, reg_loss: 0.0000 ||:  51%|█████     | 24/47 [00:09<00:13,  1.77it/s]\u001b[A\n",
            "pearson(r): 0.4985, loss: 0.1740, reg_loss: 0.0000 ||:  53%|█████▎    | 25/47 [00:10<00:12,  1.74it/s]\u001b[A\n",
            "pearson(r): 0.4899, loss: 0.1761, reg_loss: 0.0000 ||:  55%|█████▌    | 26/47 [00:11<00:11,  1.79it/s]\u001b[A\n",
            "pearson(r): 0.4856, loss: 0.1781, reg_loss: 0.0000 ||:  57%|█████▋    | 27/47 [00:11<00:11,  1.79it/s]\u001b[A\n",
            "pearson(r): 0.4788, loss: 0.1798, reg_loss: 0.0000 ||:  60%|█████▉    | 28/47 [00:12<00:10,  1.74it/s]\u001b[A\n",
            "pearson(r): 0.4680, loss: 0.1851, reg_loss: 0.0000 ||:  62%|██████▏   | 29/47 [00:12<00:10,  1.77it/s]\u001b[A\n",
            "pearson(r): 0.4614, loss: 0.1884, reg_loss: 0.0000 ||:  64%|██████▍   | 30/47 [00:13<00:09,  1.78it/s]\u001b[A\n",
            "pearson(r): 0.4498, loss: 0.1922, reg_loss: 0.0000 ||:  66%|██████▌   | 31/47 [00:13<00:08,  1.80it/s]\u001b[A\n",
            "pearson(r): 0.4577, loss: 0.1899, reg_loss: 0.0000 ||:  68%|██████▊   | 32/47 [00:14<00:08,  1.68it/s]\u001b[A\n",
            "pearson(r): 0.4682, loss: 0.1861, reg_loss: 0.0000 ||:  70%|███████   | 33/47 [00:15<00:08,  1.64it/s]\u001b[A\n",
            "pearson(r): 0.4767, loss: 0.1825, reg_loss: 0.0000 ||:  72%|███████▏  | 34/47 [00:15<00:08,  1.57it/s]\u001b[A\n",
            "pearson(r): 0.4821, loss: 0.1796, reg_loss: 0.0000 ||:  74%|███████▍  | 35/47 [00:16<00:08,  1.46it/s]\u001b[A\n",
            "pearson(r): 0.4854, loss: 0.1775, reg_loss: 0.0000 ||:  77%|███████▋  | 36/47 [00:17<00:07,  1.46it/s]\u001b[A\n",
            "pearson(r): 0.4906, loss: 0.1753, reg_loss: 0.0000 ||:  79%|███████▊  | 37/47 [00:18<00:06,  1.47it/s]\u001b[A\n",
            "pearson(r): 0.4933, loss: 0.1728, reg_loss: 0.0000 ||:  81%|████████  | 38/47 [00:18<00:06,  1.47it/s]\u001b[A\n",
            "pearson(r): 0.4998, loss: 0.1702, reg_loss: 0.0000 ||:  83%|████████▎ | 39/47 [00:19<00:05,  1.45it/s]\u001b[A\n",
            "pearson(r): 0.4985, loss: 0.1704, reg_loss: 0.0000 ||:  85%|████████▌ | 40/47 [00:19<00:04,  1.63it/s]\u001b[A\n",
            "pearson(r): 0.4939, loss: 0.1692, reg_loss: 0.0000 ||:  87%|████████▋ | 41/47 [00:20<00:03,  1.86it/s]\u001b[A\n",
            "pearson(r): 0.4971, loss: 0.1688, reg_loss: 0.0000 ||:  89%|████████▉ | 42/47 [00:20<00:02,  2.15it/s]\u001b[A\n",
            "pearson(r): 0.4932, loss: 0.1699, reg_loss: 0.0000 ||:  91%|█████████▏| 43/47 [00:20<00:01,  2.34it/s]\u001b[A\n",
            "pearson(r): 0.4927, loss: 0.1698, reg_loss: 0.0000 ||:  94%|█████████▎| 44/47 [00:21<00:01,  2.48it/s]\u001b[A\n",
            "pearson(r): 0.4865, loss: 0.1716, reg_loss: 0.0000 ||:  96%|█████████▌| 45/47 [00:21<00:00,  2.64it/s]\u001b[A\n",
            "pearson(r): 0.4869, loss: 0.1737, reg_loss: 0.0000 ||:  98%|█████████▊| 46/47 [00:21<00:00,  2.66it/s]\u001b[A\n",
            "pearson(r): 0.4874, loss: 0.1742, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:22<00:00,  2.11it/s]\n",
            "\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.2034, loss: 0.1066, reg_loss: 0.0000 ||:   1%|          | 1/180 [00:07<22:02,  7.39s/it]\u001b[A\n",
            "pearson(r): 0.3746, loss: 0.0844, reg_loss: 0.0000 ||:   1%|          | 2/180 [00:09<17:24,  5.87s/it]\u001b[A\n",
            "pearson(r): 0.4014, loss: 0.0747, reg_loss: 0.0000 ||:   2%|▏         | 3/180 [00:11<13:27,  4.56s/it]\u001b[A\n",
            "pearson(r): 0.4459, loss: 0.0696, reg_loss: 0.0000 ||:   2%|▏         | 4/180 [00:13<11:05,  3.78s/it]\u001b[A\n",
            "pearson(r): 0.4918, loss: 0.0658, reg_loss: 0.0000 ||:   3%|▎         | 5/180 [00:15<09:22,  3.21s/it]\u001b[A\n",
            "pearson(r): 0.4903, loss: 0.0668, reg_loss: 0.0000 ||:   3%|▎         | 6/180 [00:17<08:46,  3.03s/it]\u001b[A\n",
            "pearson(r): 0.4819, loss: 0.0660, reg_loss: 0.0000 ||:   4%|▍         | 7/180 [00:22<10:04,  3.49s/it]\u001b[A\n",
            "pearson(r): 0.4871, loss: 0.0626, reg_loss: 0.0000 ||:   4%|▍         | 8/180 [00:24<08:35,  3.00s/it]\u001b[A\n",
            "pearson(r): 0.4510, loss: 0.0646, reg_loss: 0.0000 ||:   5%|▌         | 9/180 [00:30<11:31,  4.04s/it]\u001b[A\n",
            "pearson(r): 0.4497, loss: 0.0654, reg_loss: 0.0000 ||:   6%|▌         | 10/180 [00:32<09:43,  3.43s/it]\u001b[A\n",
            "pearson(r): 0.4640, loss: 0.0654, reg_loss: 0.0000 ||:   6%|▌         | 11/180 [00:34<08:36,  3.06s/it]\u001b[A\n",
            "pearson(r): 0.4683, loss: 0.0652, reg_loss: 0.0000 ||:   7%|▋         | 12/180 [00:37<08:04,  2.89s/it]\u001b[A\n",
            "pearson(r): 0.4821, loss: 0.0642, reg_loss: 0.0000 ||:   7%|▋         | 13/180 [00:38<06:54,  2.48s/it]\u001b[A\n",
            "pearson(r): 0.4937, loss: 0.0624, reg_loss: 0.0000 ||:   8%|▊         | 14/180 [00:41<06:45,  2.44s/it]\u001b[A\n",
            "pearson(r): 0.5137, loss: 0.0617, reg_loss: 0.0000 ||:   8%|▊         | 15/180 [00:42<06:11,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.5040, loss: 0.0632, reg_loss: 0.0000 ||:   9%|▉         | 16/180 [00:45<06:35,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.5077, loss: 0.0631, reg_loss: 0.0000 ||:   9%|▉         | 17/180 [00:47<05:58,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.5187, loss: 0.0624, reg_loss: 0.0000 ||:  10%|█         | 18/180 [00:49<05:46,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.5069, loss: 0.0634, reg_loss: 0.0000 ||:  11%|█         | 19/180 [00:51<05:41,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.5022, loss: 0.0632, reg_loss: 0.0000 ||:  11%|█         | 20/180 [00:58<09:16,  3.48s/it]\u001b[A\n",
            "pearson(r): 0.5059, loss: 0.0637, reg_loss: 0.0000 ||:  12%|█▏        | 21/180 [01:00<08:17,  3.13s/it]\u001b[A\n",
            "pearson(r): 0.5007, loss: 0.0646, reg_loss: 0.0000 ||:  12%|█▏        | 22/180 [01:02<07:18,  2.78s/it]\u001b[A\n",
            "pearson(r): 0.5033, loss: 0.0634, reg_loss: 0.0000 ||:  13%|█▎        | 23/180 [01:04<06:32,  2.50s/it]\u001b[A\n",
            "pearson(r): 0.5059, loss: 0.0633, reg_loss: 0.0000 ||:  13%|█▎        | 24/180 [01:06<06:04,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.5168, loss: 0.0629, reg_loss: 0.0000 ||:  14%|█▍        | 25/180 [01:08<05:46,  2.24s/it]\u001b[A\n",
            "pearson(r): 0.5221, loss: 0.0625, reg_loss: 0.0000 ||:  14%|█▍        | 26/180 [01:10<05:59,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.5285, loss: 0.0616, reg_loss: 0.0000 ||:  15%|█▌        | 27/180 [01:12<05:40,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.5230, loss: 0.0617, reg_loss: 0.0000 ||:  16%|█▌        | 28/180 [01:14<05:32,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.5175, loss: 0.0621, reg_loss: 0.0000 ||:  16%|█▌        | 29/180 [01:16<05:16,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.5197, loss: 0.0620, reg_loss: 0.0000 ||:  17%|█▋        | 30/180 [01:19<05:47,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.5206, loss: 0.0618, reg_loss: 0.0000 ||:  17%|█▋        | 31/180 [01:21<05:35,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.5245, loss: 0.0616, reg_loss: 0.0000 ||:  18%|█▊        | 32/180 [01:23<05:11,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.5271, loss: 0.0611, reg_loss: 0.0000 ||:  18%|█▊        | 33/180 [01:26<05:53,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.5347, loss: 0.0608, reg_loss: 0.0000 ||:  19%|█▉        | 34/180 [01:28<05:42,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.5345, loss: 0.0611, reg_loss: 0.0000 ||:  19%|█▉        | 35/180 [01:31<05:37,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.5355, loss: 0.0611, reg_loss: 0.0000 ||:  20%|██        | 36/180 [01:32<05:10,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.5336, loss: 0.0611, reg_loss: 0.0000 ||:  21%|██        | 37/180 [01:34<05:04,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.5365, loss: 0.0608, reg_loss: 0.0000 ||:  21%|██        | 38/180 [01:36<04:58,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.5316, loss: 0.0614, reg_loss: 0.0000 ||:  22%|██▏       | 39/180 [01:39<05:32,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.5348, loss: 0.0613, reg_loss: 0.0000 ||:  22%|██▏       | 40/180 [01:41<04:58,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.5319, loss: 0.0617, reg_loss: 0.0000 ||:  23%|██▎       | 41/180 [01:43<04:45,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.5315, loss: 0.0620, reg_loss: 0.0000 ||:  23%|██▎       | 42/180 [01:44<04:25,  1.92s/it]\u001b[A\n",
            "pearson(r): 0.5298, loss: 0.0618, reg_loss: 0.0000 ||:  24%|██▍       | 43/180 [01:46<04:21,  1.91s/it]\u001b[A\n",
            "pearson(r): 0.5270, loss: 0.0623, reg_loss: 0.0000 ||:  24%|██▍       | 44/180 [01:48<04:23,  1.94s/it]\u001b[A\n",
            "pearson(r): 0.5287, loss: 0.0623, reg_loss: 0.0000 ||:  25%|██▌       | 45/180 [01:50<04:22,  1.94s/it]\u001b[A\n",
            "pearson(r): 0.5308, loss: 0.0623, reg_loss: 0.0000 ||:  26%|██▌       | 46/180 [01:52<04:23,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.5364, loss: 0.0619, reg_loss: 0.0000 ||:  26%|██▌       | 47/180 [01:54<04:17,  1.94s/it]\u001b[A\n",
            "pearson(r): 0.5382, loss: 0.0616, reg_loss: 0.0000 ||:  27%|██▋       | 48/180 [01:57<04:32,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.5403, loss: 0.0613, reg_loss: 0.0000 ||:  27%|██▋       | 49/180 [01:59<04:27,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.5385, loss: 0.0614, reg_loss: 0.0000 ||:  28%|██▊       | 50/180 [02:00<04:18,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.5399, loss: 0.0613, reg_loss: 0.0000 ||:  28%|██▊       | 51/180 [02:03<04:22,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.5416, loss: 0.0613, reg_loss: 0.0000 ||:  29%|██▉       | 52/180 [02:04<03:53,  1.83s/it]\u001b[A\n",
            "pearson(r): 0.5402, loss: 0.0613, reg_loss: 0.0000 ||:  29%|██▉       | 53/180 [02:08<05:07,  2.42s/it]\u001b[A\n",
            "pearson(r): 0.5392, loss: 0.0616, reg_loss: 0.0000 ||:  30%|███       | 54/180 [02:10<05:14,  2.49s/it]\u001b[A\n",
            "pearson(r): 0.5421, loss: 0.0614, reg_loss: 0.0000 ||:  31%|███       | 55/180 [02:12<04:54,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.5468, loss: 0.0616, reg_loss: 0.0000 ||:  31%|███       | 56/180 [02:15<04:52,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.5426, loss: 0.0615, reg_loss: 0.0000 ||:  32%|███▏      | 57/180 [02:17<04:30,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.5401, loss: 0.0616, reg_loss: 0.0000 ||:  32%|███▏      | 58/180 [02:18<04:15,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.5391, loss: 0.0614, reg_loss: 0.0000 ||:  33%|███▎      | 59/180 [02:20<04:07,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.5403, loss: 0.0612, reg_loss: 0.0000 ||:  33%|███▎      | 60/180 [02:22<04:06,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.5425, loss: 0.0609, reg_loss: 0.0000 ||:  34%|███▍      | 61/180 [02:25<04:24,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.5399, loss: 0.0611, reg_loss: 0.0000 ||:  34%|███▍      | 62/180 [02:28<04:58,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.5439, loss: 0.0609, reg_loss: 0.0000 ||:  35%|███▌      | 63/180 [02:30<04:44,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.5444, loss: 0.0607, reg_loss: 0.0000 ||:  36%|███▌      | 64/180 [02:33<04:45,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.5463, loss: 0.0605, reg_loss: 0.0000 ||:  36%|███▌      | 65/180 [02:34<04:05,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.5471, loss: 0.0604, reg_loss: 0.0000 ||:  37%|███▋      | 66/180 [02:36<03:52,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.5496, loss: 0.0603, reg_loss: 0.0000 ||:  37%|███▋      | 67/180 [02:39<04:02,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.5458, loss: 0.0605, reg_loss: 0.0000 ||:  38%|███▊      | 68/180 [02:41<04:20,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.5445, loss: 0.0607, reg_loss: 0.0000 ||:  38%|███▊      | 69/180 [02:45<05:00,  2.71s/it]\u001b[A\n",
            "pearson(r): 0.5412, loss: 0.0610, reg_loss: 0.0000 ||:  39%|███▉      | 70/180 [02:47<04:34,  2.49s/it]\u001b[A\n",
            "pearson(r): 0.5391, loss: 0.0611, reg_loss: 0.0000 ||:  39%|███▉      | 71/180 [02:49<04:16,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.5383, loss: 0.0609, reg_loss: 0.0000 ||:  40%|████      | 72/180 [02:51<04:02,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.5381, loss: 0.0612, reg_loss: 0.0000 ||:  41%|████      | 73/180 [02:53<03:57,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.5372, loss: 0.0612, reg_loss: 0.0000 ||:  41%|████      | 74/180 [02:56<04:22,  2.47s/it]\u001b[A\n",
            "pearson(r): 0.5378, loss: 0.0610, reg_loss: 0.0000 ||:  42%|████▏     | 75/180 [02:58<04:03,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.5377, loss: 0.0607, reg_loss: 0.0000 ||:  42%|████▏     | 76/180 [03:01<04:31,  2.61s/it]\u001b[A\n",
            "pearson(r): 0.5379, loss: 0.0608, reg_loss: 0.0000 ||:  43%|████▎     | 77/180 [03:03<04:08,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.5347, loss: 0.0613, reg_loss: 0.0000 ||:  43%|████▎     | 78/180 [03:07<04:49,  2.84s/it]\u001b[A\n",
            "pearson(r): 0.5350, loss: 0.0611, reg_loss: 0.0000 ||:  44%|████▍     | 79/180 [03:11<05:27,  3.24s/it]\u001b[A\n",
            "pearson(r): 0.5337, loss: 0.0612, reg_loss: 0.0000 ||:  44%|████▍     | 80/180 [03:13<04:41,  2.81s/it]\u001b[A\n",
            "pearson(r): 0.5380, loss: 0.0613, reg_loss: 0.0000 ||:  45%|████▌     | 81/180 [03:15<04:04,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.5369, loss: 0.0613, reg_loss: 0.0000 ||:  46%|████▌     | 82/180 [03:18<04:17,  2.63s/it]\u001b[A\n",
            "pearson(r): 0.5381, loss: 0.0615, reg_loss: 0.0000 ||:  46%|████▌     | 83/180 [03:21<04:16,  2.65s/it]\u001b[A\n",
            "pearson(r): 0.5394, loss: 0.0611, reg_loss: 0.0000 ||:  47%|████▋     | 84/180 [03:22<03:51,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.5381, loss: 0.0612, reg_loss: 0.0000 ||:  47%|████▋     | 85/180 [03:25<03:58,  2.51s/it]\u001b[A\n",
            "pearson(r): 0.5368, loss: 0.0609, reg_loss: 0.0000 ||:  48%|████▊     | 86/180 [03:28<03:59,  2.55s/it]\u001b[A\n",
            "pearson(r): 0.5388, loss: 0.0607, reg_loss: 0.0000 ||:  48%|████▊     | 87/180 [03:31<04:04,  2.63s/it]\u001b[A\n",
            "pearson(r): 0.5402, loss: 0.0605, reg_loss: 0.0000 ||:  49%|████▉     | 88/180 [03:33<04:00,  2.61s/it]\u001b[A\n",
            "pearson(r): 0.5407, loss: 0.0604, reg_loss: 0.0000 ||:  49%|████▉     | 89/180 [03:35<03:47,  2.50s/it]\u001b[A\n",
            "pearson(r): 0.5412, loss: 0.0605, reg_loss: 0.0000 ||:  50%|█████     | 90/180 [03:37<03:30,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.5420, loss: 0.0606, reg_loss: 0.0000 ||:  51%|█████     | 91/180 [03:39<03:18,  2.24s/it]\u001b[A\n",
            "pearson(r): 0.5415, loss: 0.0607, reg_loss: 0.0000 ||:  51%|█████     | 92/180 [03:42<03:17,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.5420, loss: 0.0607, reg_loss: 0.0000 ||:  52%|█████▏    | 93/180 [03:44<03:06,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.5431, loss: 0.0605, reg_loss: 0.0000 ||:  52%|█████▏    | 94/180 [03:46<03:00,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.5465, loss: 0.0603, reg_loss: 0.0000 ||:  53%|█████▎    | 95/180 [03:47<02:53,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.5446, loss: 0.0606, reg_loss: 0.0000 ||:  53%|█████▎    | 96/180 [03:51<03:33,  2.54s/it]\u001b[A\n",
            "pearson(r): 0.5435, loss: 0.0609, reg_loss: 0.0000 ||:  54%|█████▍    | 97/180 [03:54<03:38,  2.63s/it]\u001b[A\n",
            "pearson(r): 0.5430, loss: 0.0609, reg_loss: 0.0000 ||:  54%|█████▍    | 98/180 [03:56<03:21,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.5443, loss: 0.0608, reg_loss: 0.0000 ||:  55%|█████▌    | 99/180 [03:58<03:04,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.5423, loss: 0.0610, reg_loss: 0.0000 ||:  56%|█████▌    | 100/180 [04:00<02:54,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.5410, loss: 0.0610, reg_loss: 0.0000 ||:  56%|█████▌    | 101/180 [04:02<02:47,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.5406, loss: 0.0609, reg_loss: 0.0000 ||:  57%|█████▋    | 102/180 [04:04<02:44,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.5402, loss: 0.0609, reg_loss: 0.0000 ||:  57%|█████▋    | 103/180 [04:06<02:34,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.5393, loss: 0.0610, reg_loss: 0.0000 ||:  58%|█████▊    | 104/180 [04:08<02:35,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.5397, loss: 0.0608, reg_loss: 0.0000 ||:  58%|█████▊    | 105/180 [04:11<02:50,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.5394, loss: 0.0610, reg_loss: 0.0000 ||:  59%|█████▉    | 106/180 [04:13<02:49,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.5396, loss: 0.0611, reg_loss: 0.0000 ||:  59%|█████▉    | 107/180 [04:15<02:47,  2.30s/it]\u001b[A\n",
            "pearson(r): 0.5396, loss: 0.0610, reg_loss: 0.0000 ||:  60%|██████    | 108/180 [04:17<02:33,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.5377, loss: 0.0611, reg_loss: 0.0000 ||:  61%|██████    | 109/180 [04:21<03:10,  2.69s/it]\u001b[A\n",
            "pearson(r): 0.5380, loss: 0.0611, reg_loss: 0.0000 ||:  61%|██████    | 110/180 [04:23<02:56,  2.52s/it]\u001b[A\n",
            "pearson(r): 0.5377, loss: 0.0612, reg_loss: 0.0000 ||:  62%|██████▏   | 111/180 [04:25<02:43,  2.37s/it]\u001b[A\n",
            "pearson(r): 0.5393, loss: 0.0611, reg_loss: 0.0000 ||:  62%|██████▏   | 112/180 [04:27<02:31,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.5398, loss: 0.0610, reg_loss: 0.0000 ||:  63%|██████▎   | 113/180 [04:29<02:25,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.5399, loss: 0.0610, reg_loss: 0.0000 ||:  63%|██████▎   | 114/180 [04:31<02:21,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.5397, loss: 0.0608, reg_loss: 0.0000 ||:  64%|██████▍   | 115/180 [04:33<02:17,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.5416, loss: 0.0607, reg_loss: 0.0000 ||:  64%|██████▍   | 116/180 [04:35<02:15,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.5414, loss: 0.0606, reg_loss: 0.0000 ||:  65%|██████▌   | 117/180 [04:38<02:16,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.5416, loss: 0.0605, reg_loss: 0.0000 ||:  66%|██████▌   | 118/180 [04:40<02:09,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.5415, loss: 0.0606, reg_loss: 0.0000 ||:  66%|██████▌   | 119/180 [04:41<02:00,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.5413, loss: 0.0606, reg_loss: 0.0000 ||:  67%|██████▋   | 120/180 [04:44<02:04,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.5406, loss: 0.0605, reg_loss: 0.0000 ||:  67%|██████▋   | 121/180 [04:45<01:57,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.5404, loss: 0.0605, reg_loss: 0.0000 ||:  68%|██████▊   | 122/180 [04:48<01:59,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.5404, loss: 0.0605, reg_loss: 0.0000 ||:  68%|██████▊   | 123/180 [04:50<01:59,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.5404, loss: 0.0606, reg_loss: 0.0000 ||:  69%|██████▉   | 124/180 [04:52<02:07,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.5411, loss: 0.0605, reg_loss: 0.0000 ||:  69%|██████▉   | 125/180 [04:55<02:01,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.5417, loss: 0.0604, reg_loss: 0.0000 ||:  70%|███████   | 126/180 [04:56<01:53,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.5409, loss: 0.0603, reg_loss: 0.0000 ||:  71%|███████   | 127/180 [04:59<01:58,  2.24s/it]\u001b[A\n",
            "pearson(r): 0.5405, loss: 0.0604, reg_loss: 0.0000 ||:  71%|███████   | 128/180 [05:01<01:53,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.5397, loss: 0.0604, reg_loss: 0.0000 ||:  72%|███████▏  | 129/180 [05:03<01:49,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.5407, loss: 0.0603, reg_loss: 0.0000 ||:  72%|███████▏  | 130/180 [05:05<01:45,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.5409, loss: 0.0602, reg_loss: 0.0000 ||:  73%|███████▎  | 131/180 [05:07<01:39,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.5388, loss: 0.0604, reg_loss: 0.0000 ||:  73%|███████▎  | 132/180 [05:11<02:01,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.5377, loss: 0.0607, reg_loss: 0.0000 ||:  74%|███████▍  | 133/180 [05:13<01:57,  2.49s/it]\u001b[A\n",
            "pearson(r): 0.5385, loss: 0.0606, reg_loss: 0.0000 ||:  74%|███████▍  | 134/180 [05:15<01:49,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.5382, loss: 0.0607, reg_loss: 0.0000 ||:  75%|███████▌  | 135/180 [05:17<01:41,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.5381, loss: 0.0607, reg_loss: 0.0000 ||:  76%|███████▌  | 136/180 [05:19<01:39,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.5372, loss: 0.0608, reg_loss: 0.0000 ||:  76%|███████▌  | 137/180 [05:21<01:34,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.5375, loss: 0.0608, reg_loss: 0.0000 ||:  77%|███████▋  | 138/180 [05:23<01:28,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.5387, loss: 0.0607, reg_loss: 0.0000 ||:  77%|███████▋  | 139/180 [05:25<01:26,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.5367, loss: 0.0610, reg_loss: 0.0000 ||:  78%|███████▊  | 140/180 [05:28<01:25,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.5379, loss: 0.0609, reg_loss: 0.0000 ||:  78%|███████▊  | 141/180 [05:30<01:20,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.5394, loss: 0.0608, reg_loss: 0.0000 ||:  79%|███████▉  | 142/180 [05:32<01:18,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.5402, loss: 0.0608, reg_loss: 0.0000 ||:  79%|███████▉  | 143/180 [05:34<01:16,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.5404, loss: 0.0608, reg_loss: 0.0000 ||:  80%|████████  | 144/180 [05:36<01:15,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.5404, loss: 0.0608, reg_loss: 0.0000 ||:  81%|████████  | 145/180 [05:38<01:11,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.5412, loss: 0.0607, reg_loss: 0.0000 ||:  81%|████████  | 146/180 [05:40<01:10,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.5431, loss: 0.0606, reg_loss: 0.0000 ||:  82%|████████▏ | 147/180 [05:42<01:08,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.5442, loss: 0.0605, reg_loss: 0.0000 ||:  82%|████████▏ | 148/180 [05:44<01:07,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.5442, loss: 0.0605, reg_loss: 0.0000 ||:  83%|████████▎ | 149/180 [05:46<01:04,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.5445, loss: 0.0605, reg_loss: 0.0000 ||:  83%|████████▎ | 150/180 [05:53<01:43,  3.45s/it]\u001b[A\n",
            "pearson(r): 0.5450, loss: 0.0605, reg_loss: 0.0000 ||:  84%|████████▍ | 151/180 [05:56<01:36,  3.33s/it]\u001b[A\n",
            "pearson(r): 0.5446, loss: 0.0605, reg_loss: 0.0000 ||:  84%|████████▍ | 152/180 [05:58<01:24,  3.00s/it]\u001b[A\n",
            "pearson(r): 0.5439, loss: 0.0606, reg_loss: 0.0000 ||:  85%|████████▌ | 153/180 [06:00<01:13,  2.74s/it]\u001b[A\n",
            "pearson(r): 0.5446, loss: 0.0607, reg_loss: 0.0000 ||:  86%|████████▌ | 154/180 [06:03<01:08,  2.62s/it]\u001b[A\n",
            "pearson(r): 0.5444, loss: 0.0607, reg_loss: 0.0000 ||:  86%|████████▌ | 155/180 [06:04<01:00,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.5450, loss: 0.0607, reg_loss: 0.0000 ||:  87%|████████▋ | 156/180 [06:06<00:54,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.5473, loss: 0.0605, reg_loss: 0.0000 ||:  87%|████████▋ | 157/180 [06:08<00:49,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.5464, loss: 0.0605, reg_loss: 0.0000 ||:  88%|████████▊ | 158/180 [06:11<00:48,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.5453, loss: 0.0607, reg_loss: 0.0000 ||:  88%|████████▊ | 159/180 [06:14<00:55,  2.64s/it]\u001b[A\n",
            "pearson(r): 0.5435, loss: 0.0608, reg_loss: 0.0000 ||:  89%|████████▉ | 160/180 [06:17<00:54,  2.75s/it]\u001b[A\n",
            "pearson(r): 0.5425, loss: 0.0608, reg_loss: 0.0000 ||:  89%|████████▉ | 161/180 [06:19<00:47,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.5417, loss: 0.0608, reg_loss: 0.0000 ||:  90%|█████████ | 162/180 [06:21<00:42,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.5416, loss: 0.0610, reg_loss: 0.0000 ||:  91%|█████████ | 163/180 [06:23<00:38,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.5422, loss: 0.0610, reg_loss: 0.0000 ||:  91%|█████████ | 164/180 [06:28<00:45,  2.85s/it]\u001b[A\n",
            "pearson(r): 0.5413, loss: 0.0611, reg_loss: 0.0000 ||:  92%|█████████▏| 165/180 [06:29<00:38,  2.56s/it]\u001b[A\n",
            "pearson(r): 0.5417, loss: 0.0610, reg_loss: 0.0000 ||:  92%|█████████▏| 166/180 [06:31<00:33,  2.42s/it]\u001b[A\n",
            "pearson(r): 0.5418, loss: 0.0609, reg_loss: 0.0000 ||:  93%|█████████▎| 167/180 [06:34<00:30,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.5434, loss: 0.0608, reg_loss: 0.0000 ||:  93%|█████████▎| 168/180 [06:36<00:27,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.5441, loss: 0.0607, reg_loss: 0.0000 ||:  94%|█████████▍| 169/180 [06:39<00:27,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.5439, loss: 0.0606, reg_loss: 0.0000 ||:  94%|█████████▍| 170/180 [06:41<00:24,  2.42s/it]\u001b[A\n",
            "pearson(r): 0.5429, loss: 0.0606, reg_loss: 0.0000 ||:  95%|█████████▌| 171/180 [06:43<00:20,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.5435, loss: 0.0605, reg_loss: 0.0000 ||:  96%|█████████▌| 172/180 [06:45<00:17,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.5427, loss: 0.0606, reg_loss: 0.0000 ||:  96%|█████████▌| 173/180 [06:47<00:15,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.5420, loss: 0.0607, reg_loss: 0.0000 ||:  97%|█████████▋| 174/180 [06:49<00:12,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.5421, loss: 0.0606, reg_loss: 0.0000 ||:  97%|█████████▋| 175/180 [06:51<00:10,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.5415, loss: 0.0606, reg_loss: 0.0000 ||:  98%|█████████▊| 176/180 [06:53<00:08,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.5405, loss: 0.0607, reg_loss: 0.0000 ||:  98%|█████████▊| 177/180 [06:55<00:06,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.5403, loss: 0.0608, reg_loss: 0.0000 ||:  99%|█████████▉| 178/180 [06:57<00:03,  1.94s/it]\u001b[A\n",
            "pearson(r): 0.5404, loss: 0.0608, reg_loss: 0.0000 ||:  99%|█████████▉| 179/180 [06:59<00:02,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.5395, loss: 0.0610, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [07:01<00:00,  2.34s/it]\n",
            "\n",
            "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.6165, loss: 0.0792, reg_loss: 0.0000 ||:   2%|▏         | 1/47 [00:00<00:12,  3.62it/s]\u001b[A\n",
            "pearson(r): 0.6493, loss: 0.0833, reg_loss: 0.0000 ||:   4%|▍         | 2/47 [00:00<00:12,  3.54it/s]\u001b[A\n",
            "pearson(r): 0.6782, loss: 0.0756, reg_loss: 0.0000 ||:   6%|▋         | 3/47 [00:00<00:13,  3.33it/s]\u001b[A\n",
            "pearson(r): 0.7046, loss: 0.0869, reg_loss: 0.0000 ||:   9%|▊         | 4/47 [00:01<00:13,  3.28it/s]\u001b[A\n",
            "pearson(r): 0.7213, loss: 0.0802, reg_loss: 0.0000 ||:  11%|█         | 5/47 [00:01<00:12,  3.40it/s]\u001b[A\n",
            "pearson(r): 0.7072, loss: 0.0801, reg_loss: 0.0000 ||:  13%|█▎        | 6/47 [00:01<00:12,  3.32it/s]\u001b[A\n",
            "pearson(r): 0.7041, loss: 0.0847, reg_loss: 0.0000 ||:  15%|█▍        | 7/47 [00:02<00:12,  3.28it/s]\u001b[A\n",
            "pearson(r): 0.7090, loss: 0.0870, reg_loss: 0.0000 ||:  17%|█▋        | 8/47 [00:02<00:12,  3.09it/s]\u001b[A\n",
            "pearson(r): 0.6890, loss: 0.0927, reg_loss: 0.0000 ||:  19%|█▉        | 9/47 [00:02<00:13,  2.91it/s]\u001b[A\n",
            "pearson(r): 0.6846, loss: 0.0935, reg_loss: 0.0000 ||:  21%|██▏       | 10/47 [00:03<00:13,  2.79it/s]\u001b[A\n",
            "pearson(r): 0.6798, loss: 0.0915, reg_loss: 0.0000 ||:  23%|██▎       | 11/47 [00:03<00:13,  2.58it/s]\u001b[A\n",
            "pearson(r): 0.6858, loss: 0.0912, reg_loss: 0.0000 ||:  26%|██▌       | 12/47 [00:04<00:13,  2.53it/s]\u001b[A\n",
            "pearson(r): 0.6748, loss: 0.0962, reg_loss: 0.0000 ||:  28%|██▊       | 13/47 [00:04<00:13,  2.47it/s]\u001b[A\n",
            "pearson(r): 0.6803, loss: 0.0964, reg_loss: 0.0000 ||:  30%|██▉       | 14/47 [00:04<00:13,  2.48it/s]\u001b[A\n",
            "pearson(r): 0.6648, loss: 0.1030, reg_loss: 0.0000 ||:  32%|███▏      | 15/47 [00:05<00:13,  2.43it/s]\u001b[A\n",
            "pearson(r): 0.6572, loss: 0.1063, reg_loss: 0.0000 ||:  34%|███▍      | 16/47 [00:05<00:12,  2.38it/s]\u001b[A\n",
            "pearson(r): 0.6498, loss: 0.1058, reg_loss: 0.0000 ||:  36%|███▌      | 17/47 [00:06<00:12,  2.34it/s]\u001b[A\n",
            "pearson(r): 0.6495, loss: 0.1067, reg_loss: 0.0000 ||:  38%|███▊      | 18/47 [00:06<00:12,  2.35it/s]\u001b[A\n",
            "pearson(r): 0.6566, loss: 0.1065, reg_loss: 0.0000 ||:  40%|████      | 19/47 [00:07<00:11,  2.35it/s]\u001b[A\n",
            "pearson(r): 0.6486, loss: 0.1092, reg_loss: 0.0000 ||:  43%|████▎     | 20/47 [00:07<00:12,  2.18it/s]\u001b[A\n",
            "pearson(r): 0.6381, loss: 0.1122, reg_loss: 0.0000 ||:  45%|████▍     | 21/47 [00:08<00:12,  2.03it/s]\u001b[A\n",
            "pearson(r): 0.6218, loss: 0.1150, reg_loss: 0.0000 ||:  47%|████▋     | 22/47 [00:08<00:13,  1.92it/s]\u001b[A\n",
            "pearson(r): 0.6115, loss: 0.1153, reg_loss: 0.0000 ||:  49%|████▉     | 23/47 [00:09<00:13,  1.84it/s]\u001b[A\n",
            "pearson(r): 0.5961, loss: 0.1189, reg_loss: 0.0000 ||:  51%|█████     | 24/47 [00:10<00:13,  1.76it/s]\u001b[A\n",
            "pearson(r): 0.5807, loss: 0.1219, reg_loss: 0.0000 ||:  53%|█████▎    | 25/47 [00:10<00:12,  1.73it/s]\u001b[A\n",
            "pearson(r): 0.5736, loss: 0.1231, reg_loss: 0.0000 ||:  55%|█████▌    | 26/47 [00:11<00:11,  1.78it/s]\u001b[A\n",
            "pearson(r): 0.5669, loss: 0.1244, reg_loss: 0.0000 ||:  57%|█████▋    | 27/47 [00:11<00:11,  1.79it/s]\u001b[A\n",
            "pearson(r): 0.5616, loss: 0.1246, reg_loss: 0.0000 ||:  60%|█████▉    | 28/47 [00:12<00:10,  1.74it/s]\u001b[A\n",
            "pearson(r): 0.5552, loss: 0.1272, reg_loss: 0.0000 ||:  62%|██████▏   | 29/47 [00:12<00:10,  1.76it/s]\u001b[A\n",
            "pearson(r): 0.5491, loss: 0.1293, reg_loss: 0.0000 ||:  64%|██████▍   | 30/47 [00:13<00:09,  1.78it/s]\u001b[A\n",
            "pearson(r): 0.5408, loss: 0.1309, reg_loss: 0.0000 ||:  66%|██████▌   | 31/47 [00:13<00:08,  1.80it/s]\u001b[A\n",
            "pearson(r): 0.5463, loss: 0.1295, reg_loss: 0.0000 ||:  68%|██████▊   | 32/47 [00:14<00:08,  1.69it/s]\u001b[A\n",
            "pearson(r): 0.5535, loss: 0.1269, reg_loss: 0.0000 ||:  70%|███████   | 33/47 [00:15<00:08,  1.64it/s]\u001b[A\n",
            "pearson(r): 0.5598, loss: 0.1244, reg_loss: 0.0000 ||:  72%|███████▏  | 34/47 [00:16<00:08,  1.58it/s]\u001b[A\n",
            "pearson(r): 0.5640, loss: 0.1224, reg_loss: 0.0000 ||:  74%|███████▍  | 35/47 [00:16<00:08,  1.47it/s]\u001b[A\n",
            "pearson(r): 0.5662, loss: 0.1211, reg_loss: 0.0000 ||:  77%|███████▋  | 36/47 [00:17<00:07,  1.46it/s]\u001b[A\n",
            "pearson(r): 0.5703, loss: 0.1197, reg_loss: 0.0000 ||:  79%|███████▊  | 37/47 [00:18<00:06,  1.46it/s]\u001b[A\n",
            "pearson(r): 0.5721, loss: 0.1181, reg_loss: 0.0000 ||:  81%|████████  | 38/47 [00:18<00:06,  1.47it/s]\u001b[A\n",
            "pearson(r): 0.5762, loss: 0.1164, reg_loss: 0.0000 ||:  83%|████████▎ | 39/47 [00:19<00:05,  1.45it/s]\u001b[A\n",
            "pearson(r): 0.5750, loss: 0.1167, reg_loss: 0.0000 ||:  85%|████████▌ | 40/47 [00:19<00:04,  1.64it/s]\u001b[A\n",
            "pearson(r): 0.5741, loss: 0.1156, reg_loss: 0.0000 ||:  87%|████████▋ | 41/47 [00:20<00:03,  1.87it/s]\u001b[A\n",
            "pearson(r): 0.5757, loss: 0.1156, reg_loss: 0.0000 ||:  89%|████████▉ | 42/47 [00:20<00:02,  2.14it/s]\u001b[A\n",
            "pearson(r): 0.5741, loss: 0.1163, reg_loss: 0.0000 ||:  91%|█████████▏| 43/47 [00:20<00:01,  2.32it/s]\u001b[A\n",
            "pearson(r): 0.5707, loss: 0.1165, reg_loss: 0.0000 ||:  94%|█████████▎| 44/47 [00:21<00:01,  2.47it/s]\u001b[A\n",
            "pearson(r): 0.5660, loss: 0.1181, reg_loss: 0.0000 ||:  96%|█████████▌| 45/47 [00:21<00:00,  2.65it/s]\u001b[A\n",
            "pearson(r): 0.5679, loss: 0.1193, reg_loss: 0.0000 ||:  98%|█████████▊| 46/47 [00:22<00:00,  2.68it/s]\u001b[A\n",
            "pearson(r): 0.5647, loss: 0.1200, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:22<00:00,  2.10it/s]\n",
            "\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.3531, loss: 0.0541, reg_loss: 0.0000 ||:   1%|          | 1/180 [00:02<06:59,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.6203, loss: 0.0474, reg_loss: 0.0000 ||:   1%|          | 2/180 [00:04<06:35,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.6529, loss: 0.0484, reg_loss: 0.0000 ||:   2%|▏         | 3/180 [00:06<06:52,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.5984, loss: 0.0496, reg_loss: 0.0000 ||:   2%|▏         | 4/180 [00:09<07:06,  2.42s/it]\u001b[A\n",
            "pearson(r): 0.5371, loss: 0.0567, reg_loss: 0.0000 ||:   3%|▎         | 5/180 [00:11<06:43,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.5406, loss: 0.0544, reg_loss: 0.0000 ||:   3%|▎         | 6/180 [00:14<07:41,  2.65s/it]\u001b[A\n",
            "pearson(r): 0.5366, loss: 0.0540, reg_loss: 0.0000 ||:   4%|▍         | 7/180 [00:16<06:47,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.5423, loss: 0.0548, reg_loss: 0.0000 ||:   4%|▍         | 8/180 [00:18<06:21,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.5605, loss: 0.0525, reg_loss: 0.0000 ||:   5%|▌         | 9/180 [00:20<06:20,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.5742, loss: 0.0519, reg_loss: 0.0000 ||:   6%|▌         | 10/180 [00:22<05:43,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.5980, loss: 0.0506, reg_loss: 0.0000 ||:   6%|▌         | 11/180 [00:24<05:34,  1.98s/it]\u001b[A\n",
            "pearson(r): 0.5993, loss: 0.0507, reg_loss: 0.0000 ||:   7%|▋         | 12/180 [00:26<05:54,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.6135, loss: 0.0501, reg_loss: 0.0000 ||:   7%|▋         | 13/180 [00:28<05:51,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.6108, loss: 0.0512, reg_loss: 0.0000 ||:   8%|▊         | 14/180 [00:30<05:52,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.6121, loss: 0.0516, reg_loss: 0.0000 ||:   8%|▊         | 15/180 [00:32<05:34,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.6151, loss: 0.0512, reg_loss: 0.0000 ||:   9%|▉         | 16/180 [00:34<05:32,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.6047, loss: 0.0520, reg_loss: 0.0000 ||:   9%|▉         | 17/180 [00:36<05:18,  1.96s/it]\u001b[A\n",
            "pearson(r): 0.5917, loss: 0.0529, reg_loss: 0.0000 ||:  10%|█         | 18/180 [00:38<05:11,  1.93s/it]\u001b[A\n",
            "pearson(r): 0.5877, loss: 0.0530, reg_loss: 0.0000 ||:  11%|█         | 19/180 [00:42<06:35,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.5871, loss: 0.0534, reg_loss: 0.0000 ||:  11%|█         | 20/180 [00:44<06:32,  2.45s/it]\u001b[A\n",
            "pearson(r): 0.5909, loss: 0.0539, reg_loss: 0.0000 ||:  12%|█▏        | 21/180 [00:46<05:52,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.5837, loss: 0.0537, reg_loss: 0.0000 ||:  12%|█▏        | 22/180 [00:49<07:03,  2.68s/it]\u001b[A\n",
            "pearson(r): 0.5854, loss: 0.0528, reg_loss: 0.0000 ||:  13%|█▎        | 23/180 [00:51<06:07,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.5964, loss: 0.0532, reg_loss: 0.0000 ||:  13%|█▎        | 24/180 [00:53<05:40,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.5964, loss: 0.0520, reg_loss: 0.0000 ||:  14%|█▍        | 25/180 [00:55<05:29,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.6023, loss: 0.0510, reg_loss: 0.0000 ||:  14%|█▍        | 26/180 [00:57<05:25,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.6086, loss: 0.0505, reg_loss: 0.0000 ||:  15%|█▌        | 27/180 [00:59<05:28,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.6104, loss: 0.0500, reg_loss: 0.0000 ||:  16%|█▌        | 28/180 [01:01<05:07,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.6074, loss: 0.0499, reg_loss: 0.0000 ||:  16%|█▌        | 29/180 [01:03<05:13,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.6029, loss: 0.0498, reg_loss: 0.0000 ||:  17%|█▋        | 30/180 [01:06<05:41,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.6043, loss: 0.0500, reg_loss: 0.0000 ||:  17%|█▋        | 31/180 [01:09<05:59,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.6089, loss: 0.0498, reg_loss: 0.0000 ||:  18%|█▊        | 32/180 [01:11<05:54,  2.40s/it]\u001b[A\n",
            "pearson(r): 0.6113, loss: 0.0497, reg_loss: 0.0000 ||:  18%|█▊        | 33/180 [01:13<05:46,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.6034, loss: 0.0507, reg_loss: 0.0000 ||:  19%|█▉        | 34/180 [01:17<06:50,  2.81s/it]\u001b[A\n",
            "pearson(r): 0.6087, loss: 0.0505, reg_loss: 0.0000 ||:  19%|█▉        | 35/180 [01:24<09:35,  3.97s/it]\u001b[A\n",
            "pearson(r): 0.6071, loss: 0.0507, reg_loss: 0.0000 ||:  20%|██        | 36/180 [01:26<08:21,  3.48s/it]\u001b[A\n",
            "pearson(r): 0.6144, loss: 0.0506, reg_loss: 0.0000 ||:  21%|██        | 37/180 [01:28<07:04,  2.97s/it]\u001b[A\n",
            "pearson(r): 0.6123, loss: 0.0507, reg_loss: 0.0000 ||:  21%|██        | 38/180 [01:30<06:46,  2.86s/it]\u001b[A\n",
            "pearson(r): 0.6130, loss: 0.0511, reg_loss: 0.0000 ||:  22%|██▏       | 39/180 [01:32<05:56,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.6147, loss: 0.0512, reg_loss: 0.0000 ||:  22%|██▏       | 40/180 [01:34<05:16,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.6177, loss: 0.0509, reg_loss: 0.0000 ||:  23%|██▎       | 41/180 [01:36<04:59,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.6176, loss: 0.0510, reg_loss: 0.0000 ||:  23%|██▎       | 42/180 [01:38<05:13,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.6095, loss: 0.0516, reg_loss: 0.0000 ||:  24%|██▍       | 43/180 [01:42<06:12,  2.72s/it]\u001b[A\n",
            "pearson(r): 0.6077, loss: 0.0517, reg_loss: 0.0000 ||:  24%|██▍       | 44/180 [01:45<06:03,  2.67s/it]\u001b[A\n",
            "pearson(r): 0.6070, loss: 0.0519, reg_loss: 0.0000 ||:  25%|██▌       | 45/180 [01:47<05:52,  2.61s/it]\u001b[A\n",
            "pearson(r): 0.6064, loss: 0.0523, reg_loss: 0.0000 ||:  26%|██▌       | 46/180 [01:49<05:08,  2.30s/it]\u001b[A\n",
            "pearson(r): 0.6065, loss: 0.0523, reg_loss: 0.0000 ||:  26%|██▌       | 47/180 [01:51<04:51,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.6102, loss: 0.0521, reg_loss: 0.0000 ||:  27%|██▋       | 48/180 [01:52<04:36,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.6121, loss: 0.0520, reg_loss: 0.0000 ||:  27%|██▋       | 49/180 [01:55<04:36,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.6113, loss: 0.0519, reg_loss: 0.0000 ||:  28%|██▊       | 50/180 [01:58<05:07,  2.37s/it]\u001b[A\n",
            "pearson(r): 0.6113, loss: 0.0521, reg_loss: 0.0000 ||:  28%|██▊       | 51/180 [02:00<04:53,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.6111, loss: 0.0524, reg_loss: 0.0000 ||:  29%|██▉       | 52/180 [02:02<04:45,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.6122, loss: 0.0524, reg_loss: 0.0000 ||:  29%|██▉       | 53/180 [02:03<04:13,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.6107, loss: 0.0529, reg_loss: 0.0000 ||:  30%|███       | 54/180 [02:10<07:02,  3.35s/it]\u001b[A\n",
            "pearson(r): 0.6133, loss: 0.0528, reg_loss: 0.0000 ||:  31%|███       | 55/180 [02:12<06:14,  2.99s/it]\u001b[A\n",
            "pearson(r): 0.6151, loss: 0.0527, reg_loss: 0.0000 ||:  31%|███       | 56/180 [02:14<05:26,  2.63s/it]\u001b[A\n",
            "pearson(r): 0.6128, loss: 0.0529, reg_loss: 0.0000 ||:  32%|███▏      | 57/180 [02:16<05:08,  2.51s/it]\u001b[A\n",
            "pearson(r): 0.6138, loss: 0.0531, reg_loss: 0.0000 ||:  32%|███▏      | 58/180 [02:18<04:47,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.6128, loss: 0.0532, reg_loss: 0.0000 ||:  33%|███▎      | 59/180 [02:20<04:26,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.6126, loss: 0.0533, reg_loss: 0.0000 ||:  33%|███▎      | 60/180 [02:21<04:04,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.6141, loss: 0.0531, reg_loss: 0.0000 ||:  34%|███▍      | 61/180 [02:24<04:09,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.6162, loss: 0.0530, reg_loss: 0.0000 ||:  34%|███▍      | 62/180 [02:25<03:53,  1.98s/it]\u001b[A\n",
            "pearson(r): 0.6172, loss: 0.0530, reg_loss: 0.0000 ||:  35%|███▌      | 63/180 [02:28<03:58,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.6183, loss: 0.0527, reg_loss: 0.0000 ||:  36%|███▌      | 64/180 [02:30<04:14,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.6187, loss: 0.0526, reg_loss: 0.0000 ||:  36%|███▌      | 65/180 [02:32<04:08,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.6170, loss: 0.0527, reg_loss: 0.0000 ||:  37%|███▋      | 66/180 [02:34<04:12,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.6177, loss: 0.0527, reg_loss: 0.0000 ||:  37%|███▋      | 67/180 [02:37<04:07,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.6183, loss: 0.0525, reg_loss: 0.0000 ||:  38%|███▊      | 68/180 [02:38<03:47,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.6175, loss: 0.0525, reg_loss: 0.0000 ||:  38%|███▊      | 69/180 [02:41<04:17,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.6168, loss: 0.0526, reg_loss: 0.0000 ||:  39%|███▉      | 70/180 [02:43<04:01,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.6136, loss: 0.0529, reg_loss: 0.0000 ||:  39%|███▉      | 71/180 [02:45<03:47,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.6119, loss: 0.0531, reg_loss: 0.0000 ||:  40%|████      | 72/180 [02:49<04:47,  2.66s/it]\u001b[A\n",
            "pearson(r): 0.6115, loss: 0.0533, reg_loss: 0.0000 ||:  41%|████      | 73/180 [02:51<04:30,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.6125, loss: 0.0533, reg_loss: 0.0000 ||:  41%|████      | 74/180 [02:53<04:17,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.6127, loss: 0.0534, reg_loss: 0.0000 ||:  42%|████▏     | 75/180 [02:56<04:05,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.6119, loss: 0.0536, reg_loss: 0.0000 ||:  42%|████▏     | 76/180 [02:58<04:19,  2.50s/it]\u001b[A\n",
            "pearson(r): 0.6118, loss: 0.0535, reg_loss: 0.0000 ||:  43%|████▎     | 77/180 [03:00<04:00,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.6130, loss: 0.0535, reg_loss: 0.0000 ||:  43%|████▎     | 78/180 [03:03<03:58,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.6126, loss: 0.0536, reg_loss: 0.0000 ||:  44%|████▍     | 79/180 [03:05<04:08,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.6125, loss: 0.0535, reg_loss: 0.0000 ||:  44%|████▍     | 80/180 [03:07<03:50,  2.30s/it]\u001b[A\n",
            "pearson(r): 0.6123, loss: 0.0535, reg_loss: 0.0000 ||:  45%|████▌     | 81/180 [03:09<03:38,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.6144, loss: 0.0533, reg_loss: 0.0000 ||:  46%|████▌     | 82/180 [03:11<03:27,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.6149, loss: 0.0533, reg_loss: 0.0000 ||:  46%|████▌     | 83/180 [03:13<03:25,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.6160, loss: 0.0532, reg_loss: 0.0000 ||:  47%|████▋     | 84/180 [03:16<03:22,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.6162, loss: 0.0531, reg_loss: 0.0000 ||:  47%|████▋     | 85/180 [03:18<03:34,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.6153, loss: 0.0530, reg_loss: 0.0000 ||:  48%|████▊     | 86/180 [03:20<03:23,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.6156, loss: 0.0529, reg_loss: 0.0000 ||:  48%|████▊     | 87/180 [03:22<03:23,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.6170, loss: 0.0529, reg_loss: 0.0000 ||:  49%|████▉     | 88/180 [03:24<03:14,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.6164, loss: 0.0530, reg_loss: 0.0000 ||:  49%|████▉     | 89/180 [03:26<03:11,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.6180, loss: 0.0529, reg_loss: 0.0000 ||:  50%|█████     | 90/180 [03:28<03:06,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.6179, loss: 0.0528, reg_loss: 0.0000 ||:  51%|█████     | 91/180 [03:30<02:57,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.6190, loss: 0.0528, reg_loss: 0.0000 ||:  51%|█████     | 92/180 [03:32<02:54,  1.98s/it]\u001b[A\n",
            "pearson(r): 0.6172, loss: 0.0530, reg_loss: 0.0000 ||:  52%|█████▏    | 93/180 [03:36<03:54,  2.69s/it]\u001b[A\n",
            "pearson(r): 0.6182, loss: 0.0529, reg_loss: 0.0000 ||:  52%|█████▏    | 94/180 [03:39<03:43,  2.60s/it]\u001b[A\n",
            "pearson(r): 0.6180, loss: 0.0529, reg_loss: 0.0000 ||:  53%|█████▎    | 95/180 [03:41<03:41,  2.60s/it]\u001b[A\n",
            "pearson(r): 0.6173, loss: 0.0530, reg_loss: 0.0000 ||:  53%|█████▎    | 96/180 [03:44<03:42,  2.65s/it]\u001b[A\n",
            "pearson(r): 0.6180, loss: 0.0530, reg_loss: 0.0000 ||:  54%|█████▍    | 97/180 [03:46<03:16,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.6193, loss: 0.0529, reg_loss: 0.0000 ||:  54%|█████▍    | 98/180 [03:48<02:58,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.6175, loss: 0.0532, reg_loss: 0.0000 ||:  55%|█████▌    | 99/180 [03:54<04:47,  3.55s/it]\u001b[A\n",
            "pearson(r): 0.6169, loss: 0.0532, reg_loss: 0.0000 ||:  56%|█████▌    | 100/180 [03:57<04:09,  3.12s/it]\u001b[A\n",
            "pearson(r): 0.6176, loss: 0.0530, reg_loss: 0.0000 ||:  56%|█████▌    | 101/180 [03:59<03:40,  2.79s/it]\u001b[A\n",
            "pearson(r): 0.6164, loss: 0.0531, reg_loss: 0.0000 ||:  57%|█████▋    | 102/180 [04:01<03:22,  2.59s/it]\u001b[A\n",
            "pearson(r): 0.6173, loss: 0.0531, reg_loss: 0.0000 ||:  57%|█████▋    | 103/180 [04:03<03:15,  2.54s/it]\u001b[A\n",
            "pearson(r): 0.6177, loss: 0.0530, reg_loss: 0.0000 ||:  58%|█████▊    | 104/180 [04:06<03:29,  2.76s/it]\u001b[A\n",
            "pearson(r): 0.6183, loss: 0.0528, reg_loss: 0.0000 ||:  58%|█████▊    | 105/180 [04:08<03:06,  2.48s/it]\u001b[A\n",
            "pearson(r): 0.6175, loss: 0.0528, reg_loss: 0.0000 ||:  59%|█████▉    | 106/180 [04:11<03:03,  2.49s/it]\u001b[A\n",
            "pearson(r): 0.6182, loss: 0.0527, reg_loss: 0.0000 ||:  59%|█████▉    | 107/180 [04:13<02:57,  2.44s/it]\u001b[A\n",
            "pearson(r): 0.6171, loss: 0.0528, reg_loss: 0.0000 ||:  60%|██████    | 108/180 [04:15<02:45,  2.30s/it]\u001b[A\n",
            "pearson(r): 0.6167, loss: 0.0528, reg_loss: 0.0000 ||:  61%|██████    | 109/180 [04:17<02:34,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.6186, loss: 0.0526, reg_loss: 0.0000 ||:  61%|██████    | 110/180 [04:19<02:24,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.6196, loss: 0.0526, reg_loss: 0.0000 ||:  62%|██████▏   | 111/180 [04:21<02:27,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.6210, loss: 0.0526, reg_loss: 0.0000 ||:  62%|██████▏   | 112/180 [04:23<02:29,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.6214, loss: 0.0525, reg_loss: 0.0000 ||:  63%|██████▎   | 113/180 [04:25<02:24,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.6215, loss: 0.0525, reg_loss: 0.0000 ||:  63%|██████▎   | 114/180 [04:28<02:21,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.6217, loss: 0.0525, reg_loss: 0.0000 ||:  64%|██████▍   | 115/180 [04:30<02:22,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.6227, loss: 0.0525, reg_loss: 0.0000 ||:  64%|██████▍   | 116/180 [04:32<02:13,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.6233, loss: 0.0525, reg_loss: 0.0000 ||:  65%|██████▌   | 117/180 [04:34<02:10,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.6229, loss: 0.0525, reg_loss: 0.0000 ||:  66%|██████▌   | 118/180 [04:36<02:07,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.6239, loss: 0.0525, reg_loss: 0.0000 ||:  66%|██████▌   | 119/180 [04:38<02:13,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.6234, loss: 0.0525, reg_loss: 0.0000 ||:  67%|██████▋   | 120/180 [04:45<03:31,  3.53s/it]\u001b[A\n",
            "pearson(r): 0.6243, loss: 0.0523, reg_loss: 0.0000 ||:  67%|██████▋   | 121/180 [04:48<03:13,  3.28s/it]\u001b[A\n",
            "pearson(r): 0.6232, loss: 0.0523, reg_loss: 0.0000 ||:  68%|██████▊   | 122/180 [04:50<02:52,  2.98s/it]\u001b[A\n",
            "pearson(r): 0.6233, loss: 0.0523, reg_loss: 0.0000 ||:  68%|██████▊   | 123/180 [04:52<02:34,  2.71s/it]\u001b[A\n",
            "pearson(r): 0.6238, loss: 0.0522, reg_loss: 0.0000 ||:  69%|██████▉   | 124/180 [04:54<02:24,  2.58s/it]\u001b[A\n",
            "pearson(r): 0.6253, loss: 0.0521, reg_loss: 0.0000 ||:  69%|██████▉   | 125/180 [04:56<02:11,  2.40s/it]\u001b[A\n",
            "pearson(r): 0.6267, loss: 0.0521, reg_loss: 0.0000 ||:  70%|███████   | 126/180 [04:58<02:05,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.6271, loss: 0.0520, reg_loss: 0.0000 ||:  71%|███████   | 127/180 [05:01<02:02,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.6274, loss: 0.0519, reg_loss: 0.0000 ||:  71%|███████   | 128/180 [05:03<01:53,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.6283, loss: 0.0519, reg_loss: 0.0000 ||:  72%|███████▏  | 129/180 [05:05<01:58,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.6264, loss: 0.0521, reg_loss: 0.0000 ||:  72%|███████▏  | 130/180 [05:07<01:47,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.6258, loss: 0.0522, reg_loss: 0.0000 ||:  73%|███████▎  | 131/180 [05:09<01:42,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.6261, loss: 0.0521, reg_loss: 0.0000 ||:  73%|███████▎  | 132/180 [05:11<01:36,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.6266, loss: 0.0522, reg_loss: 0.0000 ||:  74%|███████▍  | 133/180 [05:13<01:43,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.6261, loss: 0.0522, reg_loss: 0.0000 ||:  74%|███████▍  | 134/180 [05:16<01:41,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.6266, loss: 0.0521, reg_loss: 0.0000 ||:  75%|███████▌  | 135/180 [05:17<01:33,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.6262, loss: 0.0521, reg_loss: 0.0000 ||:  76%|███████▌  | 136/180 [05:19<01:32,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.6262, loss: 0.0522, reg_loss: 0.0000 ||:  76%|███████▌  | 137/180 [05:21<01:28,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.6259, loss: 0.0521, reg_loss: 0.0000 ||:  77%|███████▋  | 138/180 [05:23<01:25,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.6251, loss: 0.0522, reg_loss: 0.0000 ||:  77%|███████▋  | 139/180 [05:27<01:39,  2.44s/it]\u001b[A\n",
            "pearson(r): 0.6236, loss: 0.0522, reg_loss: 0.0000 ||:  78%|███████▊  | 140/180 [05:29<01:29,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.6237, loss: 0.0522, reg_loss: 0.0000 ||:  78%|███████▊  | 141/180 [05:30<01:22,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.6234, loss: 0.0523, reg_loss: 0.0000 ||:  79%|███████▉  | 142/180 [05:33<01:21,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.6239, loss: 0.0523, reg_loss: 0.0000 ||:  79%|███████▉  | 143/180 [05:35<01:21,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.6240, loss: 0.0524, reg_loss: 0.0000 ||:  80%|████████  | 144/180 [05:37<01:18,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.6225, loss: 0.0525, reg_loss: 0.0000 ||:  81%|████████  | 145/180 [05:39<01:18,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.6216, loss: 0.0524, reg_loss: 0.0000 ||:  81%|████████  | 146/180 [05:41<01:14,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.6206, loss: 0.0525, reg_loss: 0.0000 ||:  82%|████████▏ | 147/180 [05:43<01:08,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.6199, loss: 0.0525, reg_loss: 0.0000 ||:  82%|████████▏ | 148/180 [05:47<01:26,  2.70s/it]\u001b[A\n",
            "pearson(r): 0.6195, loss: 0.0527, reg_loss: 0.0000 ||:  83%|████████▎ | 149/180 [05:49<01:17,  2.50s/it]\u001b[A\n",
            "pearson(r): 0.6185, loss: 0.0528, reg_loss: 0.0000 ||:  83%|████████▎ | 150/180 [05:51<01:09,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.6193, loss: 0.0527, reg_loss: 0.0000 ||:  84%|████████▍ | 151/180 [05:53<01:02,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.6194, loss: 0.0527, reg_loss: 0.0000 ||:  84%|████████▍ | 152/180 [05:55<00:58,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.6187, loss: 0.0528, reg_loss: 0.0000 ||:  85%|████████▌ | 153/180 [05:59<01:09,  2.57s/it]\u001b[A\n",
            "pearson(r): 0.6189, loss: 0.0527, reg_loss: 0.0000 ||:  86%|████████▌ | 154/180 [06:01<01:01,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.6186, loss: 0.0528, reg_loss: 0.0000 ||:  86%|████████▌ | 155/180 [06:02<00:53,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.6188, loss: 0.0527, reg_loss: 0.0000 ||:  87%|████████▋ | 156/180 [06:04<00:50,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.6183, loss: 0.0528, reg_loss: 0.0000 ||:  87%|████████▋ | 157/180 [06:06<00:45,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.6191, loss: 0.0528, reg_loss: 0.0000 ||:  88%|████████▊ | 158/180 [06:08<00:42,  1.91s/it]\u001b[A\n",
            "pearson(r): 0.6190, loss: 0.0528, reg_loss: 0.0000 ||:  88%|████████▊ | 159/180 [06:10<00:40,  1.93s/it]\u001b[A\n",
            "pearson(r): 0.6183, loss: 0.0529, reg_loss: 0.0000 ||:  89%|████████▉ | 160/180 [06:12<00:38,  1.92s/it]\u001b[A\n",
            "pearson(r): 0.6175, loss: 0.0530, reg_loss: 0.0000 ||:  89%|████████▉ | 161/180 [06:16<00:51,  2.68s/it]\u001b[A\n",
            "pearson(r): 0.6169, loss: 0.0532, reg_loss: 0.0000 ||:  90%|█████████ | 162/180 [06:18<00:46,  2.57s/it]\u001b[A\n",
            "pearson(r): 0.6174, loss: 0.0532, reg_loss: 0.0000 ||:  91%|█████████ | 163/180 [06:20<00:39,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.6177, loss: 0.0532, reg_loss: 0.0000 ||:  91%|█████████ | 164/180 [06:22<00:35,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.6180, loss: 0.0531, reg_loss: 0.0000 ||:  92%|█████████▏| 165/180 [06:25<00:35,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.6187, loss: 0.0531, reg_loss: 0.0000 ||:  92%|█████████▏| 166/180 [06:28<00:35,  2.52s/it]\u001b[A\n",
            "pearson(r): 0.6181, loss: 0.0531, reg_loss: 0.0000 ||:  93%|█████████▎| 167/180 [06:29<00:29,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.6182, loss: 0.0530, reg_loss: 0.0000 ||:  93%|█████████▎| 168/180 [06:32<00:29,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.6180, loss: 0.0530, reg_loss: 0.0000 ||:  94%|█████████▍| 169/180 [06:34<00:25,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.6178, loss: 0.0531, reg_loss: 0.0000 ||:  94%|█████████▍| 170/180 [06:36<00:21,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.6181, loss: 0.0530, reg_loss: 0.0000 ||:  95%|█████████▌| 171/180 [06:38<00:18,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.6184, loss: 0.0530, reg_loss: 0.0000 ||:  96%|█████████▌| 172/180 [06:41<00:20,  2.51s/it]\u001b[A\n",
            "pearson(r): 0.6193, loss: 0.0529, reg_loss: 0.0000 ||:  96%|█████████▌| 173/180 [06:44<00:16,  2.38s/it]\u001b[A\n",
            "pearson(r): 0.6194, loss: 0.0529, reg_loss: 0.0000 ||:  97%|█████████▋| 174/180 [06:45<00:13,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.6199, loss: 0.0529, reg_loss: 0.0000 ||:  97%|█████████▋| 175/180 [06:47<00:10,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.6195, loss: 0.0530, reg_loss: 0.0000 ||:  98%|█████████▊| 176/180 [06:49<00:08,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.6193, loss: 0.0530, reg_loss: 0.0000 ||:  98%|█████████▊| 177/180 [06:51<00:06,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.6179, loss: 0.0532, reg_loss: 0.0000 ||:  99%|█████████▉| 178/180 [06:53<00:03,  1.98s/it]\u001b[A\n",
            "pearson(r): 0.6169, loss: 0.0533, reg_loss: 0.0000 ||:  99%|█████████▉| 179/180 [06:55<00:02,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.6149, loss: 0.0535, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [06:58<00:00,  2.33s/it]\n",
            "\n",
            "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.5325, loss: 0.1332, reg_loss: 0.0000 ||:   2%|▏         | 1/47 [00:00<00:12,  3.70it/s]\u001b[A\n",
            "pearson(r): 0.5454, loss: 0.1566, reg_loss: 0.0000 ||:   4%|▍         | 2/47 [00:00<00:12,  3.60it/s]\u001b[A\n",
            "pearson(r): 0.6020, loss: 0.1641, reg_loss: 0.0000 ||:   6%|▋         | 3/47 [00:00<00:12,  3.41it/s]\u001b[A\n",
            "pearson(r): 0.5930, loss: 0.2166, reg_loss: 0.0000 ||:   9%|▊         | 4/47 [00:01<00:12,  3.36it/s]\u001b[A\n",
            "pearson(r): 0.5888, loss: 0.1978, reg_loss: 0.0000 ||:  11%|█         | 5/47 [00:01<00:12,  3.50it/s]\u001b[A\n",
            "pearson(r): 0.6017, loss: 0.1928, reg_loss: 0.0000 ||:  13%|█▎        | 6/47 [00:01<00:12,  3.38it/s]\u001b[A\n",
            "pearson(r): 0.5775, loss: 0.2120, reg_loss: 0.0000 ||:  15%|█▍        | 7/47 [00:02<00:12,  3.33it/s]\u001b[A\n",
            "pearson(r): 0.5742, loss: 0.2216, reg_loss: 0.0000 ||:  17%|█▋        | 8/47 [00:02<00:12,  3.11it/s]\u001b[A\n",
            "pearson(r): 0.5660, loss: 0.2237, reg_loss: 0.0000 ||:  19%|█▉        | 9/47 [00:02<00:13,  2.92it/s]\u001b[A\n",
            "pearson(r): 0.5575, loss: 0.2278, reg_loss: 0.0000 ||:  21%|██▏       | 10/47 [00:03<00:13,  2.82it/s]\u001b[A\n",
            "pearson(r): 0.5631, loss: 0.2223, reg_loss: 0.0000 ||:  23%|██▎       | 11/47 [00:03<00:13,  2.64it/s]\u001b[A\n",
            "pearson(r): 0.5591, loss: 0.2213, reg_loss: 0.0000 ||:  26%|██▌       | 12/47 [00:04<00:13,  2.59it/s]\u001b[A\n",
            "pearson(r): 0.5551, loss: 0.2226, reg_loss: 0.0000 ||:  28%|██▊       | 13/47 [00:04<00:13,  2.54it/s]\u001b[A\n",
            "pearson(r): 0.5554, loss: 0.2230, reg_loss: 0.0000 ||:  30%|██▉       | 14/47 [00:04<00:13,  2.53it/s]\u001b[A\n",
            "pearson(r): 0.5445, loss: 0.2289, reg_loss: 0.0000 ||:  32%|███▏      | 15/47 [00:05<00:12,  2.49it/s]\u001b[A\n",
            "pearson(r): 0.5407, loss: 0.2348, reg_loss: 0.0000 ||:  34%|███▍      | 16/47 [00:05<00:12,  2.44it/s]\u001b[A\n",
            "pearson(r): 0.5474, loss: 0.2321, reg_loss: 0.0000 ||:  36%|███▌      | 17/47 [00:06<00:12,  2.38it/s]\u001b[A\n",
            "pearson(r): 0.5380, loss: 0.2385, reg_loss: 0.0000 ||:  38%|███▊      | 18/47 [00:06<00:12,  2.39it/s]\u001b[A\n",
            "pearson(r): 0.5419, loss: 0.2395, reg_loss: 0.0000 ||:  40%|████      | 19/47 [00:07<00:11,  2.39it/s]\u001b[A\n",
            "pearson(r): 0.5265, loss: 0.2452, reg_loss: 0.0000 ||:  43%|████▎     | 20/47 [00:07<00:12,  2.22it/s]\u001b[A\n",
            "pearson(r): 0.5121, loss: 0.2526, reg_loss: 0.0000 ||:  45%|████▍     | 21/47 [00:08<00:12,  2.07it/s]\u001b[A\n",
            "pearson(r): 0.5005, loss: 0.2574, reg_loss: 0.0000 ||:  47%|████▋     | 22/47 [00:08<00:12,  1.95it/s]\u001b[A\n",
            "pearson(r): 0.4924, loss: 0.2611, reg_loss: 0.0000 ||:  49%|████▉     | 23/47 [00:09<00:12,  1.88it/s]\u001b[A\n",
            "pearson(r): 0.4795, loss: 0.2677, reg_loss: 0.0000 ||:  51%|█████     | 24/47 [00:09<00:12,  1.79it/s]\u001b[A\n",
            "pearson(r): 0.4627, loss: 0.2746, reg_loss: 0.0000 ||:  53%|█████▎    | 25/47 [00:10<00:12,  1.77it/s]\u001b[A\n",
            "pearson(r): 0.4567, loss: 0.2763, reg_loss: 0.0000 ||:  55%|█████▌    | 26/47 [00:10<00:11,  1.81it/s]\u001b[A\n",
            "pearson(r): 0.4474, loss: 0.2803, reg_loss: 0.0000 ||:  57%|█████▋    | 27/47 [00:11<00:11,  1.81it/s]\u001b[A\n",
            "pearson(r): 0.4367, loss: 0.2839, reg_loss: 0.0000 ||:  60%|█████▉    | 28/47 [00:12<00:10,  1.76it/s]\u001b[A\n",
            "pearson(r): 0.4231, loss: 0.2907, reg_loss: 0.0000 ||:  62%|██████▏   | 29/47 [00:12<00:10,  1.78it/s]\u001b[A\n",
            "pearson(r): 0.4130, loss: 0.2954, reg_loss: 0.0000 ||:  64%|██████▍   | 30/47 [00:13<00:09,  1.79it/s]\u001b[A\n",
            "pearson(r): 0.4068, loss: 0.2998, reg_loss: 0.0000 ||:  66%|██████▌   | 31/47 [00:13<00:08,  1.82it/s]\u001b[A\n",
            "pearson(r): 0.4111, loss: 0.2974, reg_loss: 0.0000 ||:  68%|██████▊   | 32/47 [00:14<00:08,  1.71it/s]\u001b[A\n",
            "pearson(r): 0.4195, loss: 0.2916, reg_loss: 0.0000 ||:  70%|███████   | 33/47 [00:15<00:08,  1.66it/s]\u001b[A\n",
            "pearson(r): 0.4270, loss: 0.2861, reg_loss: 0.0000 ||:  72%|███████▏  | 34/47 [00:15<00:08,  1.59it/s]\u001b[A\n",
            "pearson(r): 0.4333, loss: 0.2814, reg_loss: 0.0000 ||:  74%|███████▍  | 35/47 [00:16<00:08,  1.48it/s]\u001b[A\n",
            "pearson(r): 0.4356, loss: 0.2778, reg_loss: 0.0000 ||:  77%|███████▋  | 36/47 [00:17<00:07,  1.47it/s]\u001b[A\n",
            "pearson(r): 0.4400, loss: 0.2736, reg_loss: 0.0000 ||:  79%|███████▊  | 37/47 [00:17<00:06,  1.48it/s]\u001b[A\n",
            "pearson(r): 0.4457, loss: 0.2693, reg_loss: 0.0000 ||:  81%|████████  | 38/47 [00:18<00:06,  1.48it/s]\u001b[A\n",
            "pearson(r): 0.4515, loss: 0.2653, reg_loss: 0.0000 ||:  83%|████████▎ | 39/47 [00:19<00:05,  1.46it/s]\u001b[A\n",
            "pearson(r): 0.4479, loss: 0.2654, reg_loss: 0.0000 ||:  85%|████████▌ | 40/47 [00:19<00:04,  1.65it/s]\u001b[A\n",
            "pearson(r): 0.4490, loss: 0.2635, reg_loss: 0.0000 ||:  87%|████████▋ | 41/47 [00:20<00:03,  1.90it/s]\u001b[A\n",
            "pearson(r): 0.4510, loss: 0.2628, reg_loss: 0.0000 ||:  89%|████████▉ | 42/47 [00:20<00:02,  2.17it/s]\u001b[A\n",
            "pearson(r): 0.4474, loss: 0.2636, reg_loss: 0.0000 ||:  91%|█████████▏| 43/47 [00:20<00:01,  2.36it/s]\u001b[A\n",
            "pearson(r): 0.4470, loss: 0.2633, reg_loss: 0.0000 ||:  94%|█████████▎| 44/47 [00:21<00:01,  2.51it/s]\u001b[A\n",
            "pearson(r): 0.4448, loss: 0.2647, reg_loss: 0.0000 ||:  96%|█████████▌| 45/47 [00:21<00:00,  2.70it/s]\u001b[A\n",
            "pearson(r): 0.4443, loss: 0.2674, reg_loss: 0.0000 ||:  98%|█████████▊| 46/47 [00:21<00:00,  2.73it/s]\u001b[A\n",
            "pearson(r): 0.4399, loss: 0.2679, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:22<00:00,  2.14it/s]\n",
            "\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.5447, loss: 0.0897, reg_loss: 0.0000 ||:   1%|          | 1/180 [00:02<06:55,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.5457, loss: 0.0965, reg_loss: 0.0000 ||:   1%|          | 2/180 [00:04<06:31,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.4841, loss: 0.1022, reg_loss: 0.0000 ||:   2%|▏         | 3/180 [00:06<06:17,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.4710, loss: 0.1028, reg_loss: 0.0000 ||:   2%|▏         | 4/180 [00:08<06:10,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.4522, loss: 0.1028, reg_loss: 0.0000 ||:   3%|▎         | 5/180 [00:10<06:09,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.4352, loss: 0.1017, reg_loss: 0.0000 ||:   3%|▎         | 6/180 [00:15<08:27,  2.91s/it]\u001b[A\n",
            "pearson(r): 0.4712, loss: 0.1028, reg_loss: 0.0000 ||:   4%|▍         | 7/180 [00:17<07:55,  2.75s/it]\u001b[A\n",
            "pearson(r): 0.4784, loss: 0.0993, reg_loss: 0.0000 ||:   4%|▍         | 8/180 [00:19<07:19,  2.56s/it]\u001b[A\n",
            "pearson(r): 0.5047, loss: 0.0995, reg_loss: 0.0000 ||:   5%|▌         | 9/180 [00:21<06:46,  2.38s/it]\u001b[A\n",
            "pearson(r): 0.4847, loss: 0.0976, reg_loss: 0.0000 ||:   6%|▌         | 10/180 [00:23<06:14,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.4900, loss: 0.0957, reg_loss: 0.0000 ||:   6%|▌         | 11/180 [00:25<05:48,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.4735, loss: 0.0963, reg_loss: 0.0000 ||:   7%|▋         | 12/180 [00:26<05:24,  1.93s/it]\u001b[A\n",
            "pearson(r): 0.4540, loss: 0.0952, reg_loss: 0.0000 ||:   7%|▋         | 13/180 [00:28<05:31,  1.98s/it]\u001b[A\n",
            "pearson(r): 0.4149, loss: 0.0931, reg_loss: 0.0000 ||:   8%|▊         | 14/180 [00:31<05:39,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.4062, loss: 0.0915, reg_loss: 0.0000 ||:   8%|▊         | 15/180 [00:33<05:51,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.4010, loss: 0.0904, reg_loss: 0.0000 ||:   9%|▉         | 16/180 [00:35<05:46,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.4092, loss: 0.0873, reg_loss: 0.0000 ||:   9%|▉         | 17/180 [00:38<06:07,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.4055, loss: 0.0876, reg_loss: 0.0000 ||:  10%|█         | 18/180 [00:42<07:39,  2.84s/it]\u001b[A\n",
            "pearson(r): 0.3912, loss: 0.0864, reg_loss: 0.0000 ||:  11%|█         | 19/180 [00:46<08:22,  3.12s/it]\u001b[A\n",
            "pearson(r): 0.3899, loss: 0.0864, reg_loss: 0.0000 ||:  11%|█         | 20/180 [00:47<07:22,  2.76s/it]\u001b[A\n",
            "pearson(r): 0.3857, loss: 0.0861, reg_loss: 0.0000 ||:  12%|█▏        | 21/180 [00:49<06:25,  2.42s/it]\u001b[A\n",
            "pearson(r): 0.3907, loss: 0.0840, reg_loss: 0.0000 ||:  12%|█▏        | 22/180 [00:51<06:07,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.4079, loss: 0.0825, reg_loss: 0.0000 ||:  13%|█▎        | 23/180 [00:54<06:06,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.4139, loss: 0.0816, reg_loss: 0.0000 ||:  13%|█▎        | 24/180 [00:55<05:41,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.4173, loss: 0.0809, reg_loss: 0.0000 ||:  14%|█▍        | 25/180 [00:57<05:31,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.4238, loss: 0.0799, reg_loss: 0.0000 ||:  14%|█▍        | 26/180 [01:00<05:28,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.4225, loss: 0.0792, reg_loss: 0.0000 ||:  15%|█▌        | 27/180 [01:01<05:16,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.4265, loss: 0.0782, reg_loss: 0.0000 ||:  16%|█▌        | 28/180 [01:04<05:33,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.4296, loss: 0.0778, reg_loss: 0.0000 ||:  16%|█▌        | 29/180 [01:06<05:23,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.4256, loss: 0.0775, reg_loss: 0.0000 ||:  17%|█▋        | 30/180 [01:08<05:10,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.4159, loss: 0.0778, reg_loss: 0.0000 ||:  17%|█▋        | 31/180 [01:14<08:31,  3.43s/it]\u001b[A\n",
            "pearson(r): 0.4219, loss: 0.0769, reg_loss: 0.0000 ||:  18%|█▊        | 32/180 [01:16<07:25,  3.01s/it]\u001b[A\n",
            "pearson(r): 0.4202, loss: 0.0764, reg_loss: 0.0000 ||:  18%|█▊        | 33/180 [01:19<07:10,  2.93s/it]\u001b[A\n",
            "pearson(r): 0.4207, loss: 0.0761, reg_loss: 0.0000 ||:  19%|█▉        | 34/180 [01:22<06:43,  2.76s/it]\u001b[A\n",
            "pearson(r): 0.4188, loss: 0.0765, reg_loss: 0.0000 ||:  19%|█▉        | 35/180 [01:24<06:32,  2.71s/it]\u001b[A\n",
            "pearson(r): 0.4258, loss: 0.0758, reg_loss: 0.0000 ||:  20%|██        | 36/180 [01:26<05:56,  2.48s/it]\u001b[A\n",
            "pearson(r): 0.4270, loss: 0.0754, reg_loss: 0.0000 ||:  21%|██        | 37/180 [01:28<05:42,  2.40s/it]\u001b[A\n",
            "pearson(r): 0.4246, loss: 0.0756, reg_loss: 0.0000 ||:  21%|██        | 38/180 [01:30<05:25,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.4309, loss: 0.0748, reg_loss: 0.0000 ||:  22%|██▏       | 39/180 [01:32<05:08,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.4352, loss: 0.0743, reg_loss: 0.0000 ||:  22%|██▏       | 40/180 [01:34<05:00,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.4400, loss: 0.0741, reg_loss: 0.0000 ||:  23%|██▎       | 41/180 [01:36<04:33,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.4412, loss: 0.0737, reg_loss: 0.0000 ||:  23%|██▎       | 42/180 [01:38<04:39,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.4417, loss: 0.0733, reg_loss: 0.0000 ||:  24%|██▍       | 43/180 [01:40<04:25,  1.94s/it]\u001b[A\n",
            "pearson(r): 0.4391, loss: 0.0733, reg_loss: 0.0000 ||:  24%|██▍       | 44/180 [01:42<04:21,  1.92s/it]\u001b[A\n",
            "pearson(r): 0.4410, loss: 0.0731, reg_loss: 0.0000 ||:  25%|██▌       | 45/180 [01:44<04:24,  1.96s/it]\u001b[A\n",
            "pearson(r): 0.4430, loss: 0.0730, reg_loss: 0.0000 ||:  26%|██▌       | 46/180 [01:46<04:24,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.4448, loss: 0.0726, reg_loss: 0.0000 ||:  26%|██▌       | 47/180 [01:48<04:28,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.4414, loss: 0.0727, reg_loss: 0.0000 ||:  27%|██▋       | 48/180 [01:50<04:30,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.4438, loss: 0.0727, reg_loss: 0.0000 ||:  27%|██▋       | 49/180 [01:52<04:21,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.4416, loss: 0.0725, reg_loss: 0.0000 ||:  28%|██▊       | 50/180 [01:54<04:16,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.4477, loss: 0.0721, reg_loss: 0.0000 ||:  28%|██▊       | 51/180 [01:57<04:46,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.4505, loss: 0.0715, reg_loss: 0.0000 ||:  29%|██▉       | 52/180 [01:59<04:45,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.4485, loss: 0.0713, reg_loss: 0.0000 ||:  29%|██▉       | 53/180 [02:01<04:33,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.4571, loss: 0.0710, reg_loss: 0.0000 ||:  30%|███       | 54/180 [02:03<04:31,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.4588, loss: 0.0709, reg_loss: 0.0000 ||:  31%|███       | 55/180 [02:06<04:46,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.4551, loss: 0.0707, reg_loss: 0.0000 ||:  31%|███       | 56/180 [02:09<05:36,  2.71s/it]\u001b[A\n",
            "pearson(r): 0.4593, loss: 0.0706, reg_loss: 0.0000 ||:  32%|███▏      | 57/180 [02:11<04:51,  2.37s/it]\u001b[A\n",
            "pearson(r): 0.4588, loss: 0.0708, reg_loss: 0.0000 ||:  32%|███▏      | 58/180 [02:13<04:36,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.4580, loss: 0.0705, reg_loss: 0.0000 ||:  33%|███▎      | 59/180 [02:15<04:16,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.4535, loss: 0.0706, reg_loss: 0.0000 ||:  33%|███▎      | 60/180 [02:17<04:36,  2.30s/it]\u001b[A\n",
            "pearson(r): 0.4574, loss: 0.0703, reg_loss: 0.0000 ||:  34%|███▍      | 61/180 [02:19<04:21,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.4597, loss: 0.0701, reg_loss: 0.0000 ||:  34%|███▍      | 62/180 [02:21<04:11,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.4572, loss: 0.0703, reg_loss: 0.0000 ||:  35%|███▌      | 63/180 [02:23<04:06,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.4576, loss: 0.0700, reg_loss: 0.0000 ||:  36%|███▌      | 64/180 [02:25<03:59,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.4545, loss: 0.0705, reg_loss: 0.0000 ||:  36%|███▌      | 65/180 [02:32<06:25,  3.35s/it]\u001b[A\n",
            "pearson(r): 0.4537, loss: 0.0704, reg_loss: 0.0000 ||:  37%|███▋      | 66/180 [02:34<05:37,  2.96s/it]\u001b[A\n",
            "pearson(r): 0.4520, loss: 0.0703, reg_loss: 0.0000 ||:  37%|███▋      | 67/180 [02:36<05:15,  2.79s/it]\u001b[A\n",
            "pearson(r): 0.4522, loss: 0.0702, reg_loss: 0.0000 ||:  38%|███▊      | 68/180 [02:38<04:57,  2.65s/it]\u001b[A\n",
            "pearson(r): 0.4499, loss: 0.0702, reg_loss: 0.0000 ||:  38%|███▊      | 69/180 [02:41<04:41,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.4526, loss: 0.0700, reg_loss: 0.0000 ||:  39%|███▉      | 70/180 [02:42<04:04,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.4514, loss: 0.0701, reg_loss: 0.0000 ||:  39%|███▉      | 71/180 [02:45<04:04,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.4509, loss: 0.0704, reg_loss: 0.0000 ||:  40%|████      | 72/180 [02:47<03:55,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.4513, loss: 0.0700, reg_loss: 0.0000 ||:  41%|████      | 73/180 [02:49<03:57,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.4503, loss: 0.0699, reg_loss: 0.0000 ||:  41%|████      | 74/180 [02:51<03:45,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.4527, loss: 0.0698, reg_loss: 0.0000 ||:  42%|████▏     | 75/180 [02:54<04:34,  2.61s/it]\u001b[A\n",
            "pearson(r): 0.4542, loss: 0.0695, reg_loss: 0.0000 ||:  42%|████▏     | 76/180 [02:57<04:13,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.4543, loss: 0.0696, reg_loss: 0.0000 ||:  43%|████▎     | 77/180 [02:59<04:20,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.4536, loss: 0.0695, reg_loss: 0.0000 ||:  43%|████▎     | 78/180 [03:01<04:01,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.4533, loss: 0.0693, reg_loss: 0.0000 ||:  44%|████▍     | 79/180 [03:03<03:38,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.4549, loss: 0.0689, reg_loss: 0.0000 ||:  44%|████▍     | 80/180 [03:05<03:35,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.4577, loss: 0.0687, reg_loss: 0.0000 ||:  45%|████▌     | 81/180 [03:07<03:13,  1.95s/it]\u001b[A\n",
            "pearson(r): 0.4585, loss: 0.0686, reg_loss: 0.0000 ||:  46%|████▌     | 82/180 [03:09<03:17,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.4613, loss: 0.0685, reg_loss: 0.0000 ||:  46%|████▌     | 83/180 [03:11<03:11,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.4633, loss: 0.0682, reg_loss: 0.0000 ||:  47%|████▋     | 84/180 [03:13<03:12,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.4644, loss: 0.0682, reg_loss: 0.0000 ||:  47%|████▋     | 85/180 [03:15<03:14,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.4669, loss: 0.0682, reg_loss: 0.0000 ||:  48%|████▊     | 86/180 [03:16<03:00,  1.92s/it]\u001b[A\n",
            "pearson(r): 0.4698, loss: 0.0680, reg_loss: 0.0000 ||:  48%|████▊     | 87/180 [03:19<03:02,  1.96s/it]\u001b[A\n",
            "pearson(r): 0.4697, loss: 0.0679, reg_loss: 0.0000 ||:  49%|████▉     | 88/180 [03:21<03:11,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.4708, loss: 0.0679, reg_loss: 0.0000 ||:  49%|████▉     | 89/180 [03:23<03:04,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.4713, loss: 0.0679, reg_loss: 0.0000 ||:  50%|█████     | 90/180 [03:24<02:48,  1.88s/it]\u001b[A\n",
            "pearson(r): 0.4728, loss: 0.0677, reg_loss: 0.0000 ||:  51%|█████     | 91/180 [03:26<02:50,  1.92s/it]\u001b[A\n",
            "pearson(r): 0.4747, loss: 0.0674, reg_loss: 0.0000 ||:  51%|█████     | 92/180 [03:29<02:58,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.4727, loss: 0.0676, reg_loss: 0.0000 ||:  52%|█████▏    | 93/180 [03:31<03:13,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.4715, loss: 0.0674, reg_loss: 0.0000 ||:  52%|█████▏    | 94/180 [03:34<03:12,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.4722, loss: 0.0675, reg_loss: 0.0000 ||:  53%|█████▎    | 95/180 [03:37<03:49,  2.70s/it]\u001b[A\n",
            "pearson(r): 0.4736, loss: 0.0674, reg_loss: 0.0000 ||:  53%|█████▎    | 96/180 [03:40<03:34,  2.55s/it]\u001b[A\n",
            "pearson(r): 0.4749, loss: 0.0671, reg_loss: 0.0000 ||:  54%|█████▍    | 97/180 [03:41<03:17,  2.38s/it]\u001b[A\n",
            "pearson(r): 0.4759, loss: 0.0670, reg_loss: 0.0000 ||:  54%|█████▍    | 98/180 [03:43<02:53,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.4757, loss: 0.0670, reg_loss: 0.0000 ||:  55%|█████▌    | 99/180 [03:46<03:05,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.4767, loss: 0.0668, reg_loss: 0.0000 ||:  56%|█████▌    | 100/180 [03:49<03:37,  2.71s/it]\u001b[A\n",
            "pearson(r): 0.4768, loss: 0.0668, reg_loss: 0.0000 ||:  56%|█████▌    | 101/180 [03:56<05:07,  3.89s/it]\u001b[A\n",
            "pearson(r): 0.4788, loss: 0.0666, reg_loss: 0.0000 ||:  57%|█████▋    | 102/180 [03:59<04:32,  3.49s/it]\u001b[A\n",
            "pearson(r): 0.4790, loss: 0.0666, reg_loss: 0.0000 ||:  57%|█████▋    | 103/180 [04:01<03:54,  3.04s/it]\u001b[A\n",
            "pearson(r): 0.4796, loss: 0.0666, reg_loss: 0.0000 ||:  58%|█████▊    | 104/180 [04:03<03:41,  2.91s/it]\u001b[A\n",
            "pearson(r): 0.4784, loss: 0.0666, reg_loss: 0.0000 ||:  58%|█████▊    | 105/180 [04:05<03:15,  2.61s/it]\u001b[A\n",
            "pearson(r): 0.4787, loss: 0.0665, reg_loss: 0.0000 ||:  59%|█████▉    | 106/180 [04:08<03:16,  2.66s/it]\u001b[A\n",
            "pearson(r): 0.4793, loss: 0.0665, reg_loss: 0.0000 ||:  59%|█████▉    | 107/180 [04:10<03:00,  2.47s/it]\u001b[A\n",
            "pearson(r): 0.4784, loss: 0.0666, reg_loss: 0.0000 ||:  60%|██████    | 108/180 [04:11<02:38,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.4783, loss: 0.0664, reg_loss: 0.0000 ||:  61%|██████    | 109/180 [04:13<02:30,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.4780, loss: 0.0664, reg_loss: 0.0000 ||:  61%|██████    | 110/180 [04:15<02:25,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.4781, loss: 0.0665, reg_loss: 0.0000 ||:  62%|██████▏   | 111/180 [04:19<02:44,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.4766, loss: 0.0665, reg_loss: 0.0000 ||:  62%|██████▏   | 112/180 [04:21<02:37,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.4754, loss: 0.0668, reg_loss: 0.0000 ||:  63%|██████▎   | 113/180 [04:24<03:00,  2.69s/it]\u001b[A\n",
            "pearson(r): 0.4757, loss: 0.0668, reg_loss: 0.0000 ||:  63%|██████▎   | 114/180 [04:27<02:57,  2.68s/it]\u001b[A\n",
            "pearson(r): 0.4763, loss: 0.0666, reg_loss: 0.0000 ||:  64%|██████▍   | 115/180 [04:29<02:43,  2.51s/it]\u001b[A\n",
            "pearson(r): 0.4754, loss: 0.0666, reg_loss: 0.0000 ||:  64%|██████▍   | 116/180 [04:31<02:33,  2.40s/it]\u001b[A\n",
            "pearson(r): 0.4762, loss: 0.0665, reg_loss: 0.0000 ||:  65%|██████▌   | 117/180 [04:33<02:28,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.4776, loss: 0.0665, reg_loss: 0.0000 ||:  66%|██████▌   | 118/180 [04:36<02:23,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.4790, loss: 0.0662, reg_loss: 0.0000 ||:  66%|██████▌   | 119/180 [04:38<02:14,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.4792, loss: 0.0663, reg_loss: 0.0000 ||:  67%|██████▋   | 120/180 [04:40<02:10,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.4809, loss: 0.0661, reg_loss: 0.0000 ||:  67%|██████▋   | 121/180 [04:42<02:10,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.4796, loss: 0.0662, reg_loss: 0.0000 ||:  68%|██████▊   | 122/180 [04:46<02:33,  2.65s/it]\u001b[A\n",
            "pearson(r): 0.4805, loss: 0.0660, reg_loss: 0.0000 ||:  68%|██████▊   | 123/180 [04:48<02:24,  2.54s/it]\u001b[A\n",
            "pearson(r): 0.4819, loss: 0.0658, reg_loss: 0.0000 ||:  69%|██████▉   | 124/180 [04:50<02:11,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.4830, loss: 0.0658, reg_loss: 0.0000 ||:  69%|██████▉   | 125/180 [04:52<02:03,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.4829, loss: 0.0658, reg_loss: 0.0000 ||:  70%|███████   | 126/180 [04:54<01:55,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.4842, loss: 0.0659, reg_loss: 0.0000 ||:  71%|███████   | 127/180 [04:56<01:49,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.4856, loss: 0.0658, reg_loss: 0.0000 ||:  71%|███████   | 128/180 [04:58<01:51,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.4860, loss: 0.0656, reg_loss: 0.0000 ||:  72%|███████▏  | 129/180 [05:00<01:42,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.4859, loss: 0.0655, reg_loss: 0.0000 ||:  72%|███████▏  | 130/180 [05:02<01:50,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.4886, loss: 0.0653, reg_loss: 0.0000 ||:  73%|███████▎  | 131/180 [05:05<01:48,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.4888, loss: 0.0653, reg_loss: 0.0000 ||:  73%|███████▎  | 132/180 [05:06<01:40,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.4901, loss: 0.0653, reg_loss: 0.0000 ||:  74%|███████▍  | 133/180 [05:08<01:38,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.4906, loss: 0.0653, reg_loss: 0.0000 ||:  74%|███████▍  | 134/180 [05:11<01:42,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.4935, loss: 0.0651, reg_loss: 0.0000 ||:  75%|███████▌  | 135/180 [05:13<01:32,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.4933, loss: 0.0651, reg_loss: 0.0000 ||:  76%|███████▌  | 136/180 [05:14<01:27,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.4910, loss: 0.0654, reg_loss: 0.0000 ||:  76%|███████▌  | 137/180 [05:21<02:24,  3.36s/it]\u001b[A\n",
            "pearson(r): 0.4910, loss: 0.0653, reg_loss: 0.0000 ||:  77%|███████▋  | 138/180 [05:26<02:35,  3.70s/it]\u001b[A\n",
            "pearson(r): 0.4918, loss: 0.0653, reg_loss: 0.0000 ||:  77%|███████▋  | 139/180 [05:28<02:11,  3.21s/it]\u001b[A\n",
            "pearson(r): 0.4938, loss: 0.0652, reg_loss: 0.0000 ||:  78%|███████▊  | 140/180 [05:30<01:53,  2.83s/it]\u001b[A\n",
            "pearson(r): 0.4943, loss: 0.0651, reg_loss: 0.0000 ||:  78%|███████▊  | 141/180 [05:31<01:39,  2.54s/it]\u001b[A\n",
            "pearson(r): 0.4948, loss: 0.0649, reg_loss: 0.0000 ||:  79%|███████▉  | 142/180 [05:34<01:40,  2.64s/it]\u001b[A\n",
            "pearson(r): 0.4947, loss: 0.0648, reg_loss: 0.0000 ||:  79%|███████▉  | 143/180 [05:37<01:34,  2.56s/it]\u001b[A\n",
            "pearson(r): 0.4958, loss: 0.0648, reg_loss: 0.0000 ||:  80%|████████  | 144/180 [05:39<01:30,  2.52s/it]\u001b[A\n",
            "pearson(r): 0.4966, loss: 0.0647, reg_loss: 0.0000 ||:  81%|████████  | 145/180 [05:41<01:23,  2.38s/it]\u001b[A\n",
            "pearson(r): 0.4981, loss: 0.0646, reg_loss: 0.0000 ||:  81%|████████  | 146/180 [05:43<01:15,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.4996, loss: 0.0645, reg_loss: 0.0000 ||:  82%|████████▏ | 147/180 [05:45<01:11,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.5007, loss: 0.0643, reg_loss: 0.0000 ||:  82%|████████▏ | 148/180 [05:48<01:16,  2.40s/it]\u001b[A\n",
            "pearson(r): 0.5017, loss: 0.0644, reg_loss: 0.0000 ||:  83%|████████▎ | 149/180 [05:50<01:09,  2.24s/it]\u001b[A\n",
            "pearson(r): 0.5010, loss: 0.0644, reg_loss: 0.0000 ||:  83%|████████▎ | 150/180 [05:54<01:20,  2.70s/it]\u001b[A\n",
            "pearson(r): 0.5017, loss: 0.0643, reg_loss: 0.0000 ||:  84%|████████▍ | 151/180 [05:56<01:11,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.5028, loss: 0.0643, reg_loss: 0.0000 ||:  84%|████████▍ | 152/180 [05:57<01:03,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.5025, loss: 0.0643, reg_loss: 0.0000 ||:  85%|████████▌ | 153/180 [05:59<00:59,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.5033, loss: 0.0642, reg_loss: 0.0000 ||:  86%|████████▌ | 154/180 [06:01<00:55,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.5044, loss: 0.0641, reg_loss: 0.0000 ||:  86%|████████▌ | 155/180 [06:04<00:54,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.5051, loss: 0.0641, reg_loss: 0.0000 ||:  87%|████████▋ | 156/180 [06:06<00:52,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.5042, loss: 0.0643, reg_loss: 0.0000 ||:  87%|████████▋ | 157/180 [06:08<00:47,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.5039, loss: 0.0644, reg_loss: 0.0000 ||:  88%|████████▊ | 158/180 [06:11<00:52,  2.40s/it]\u001b[A\n",
            "pearson(r): 0.5036, loss: 0.0645, reg_loss: 0.0000 ||:  88%|████████▊ | 159/180 [06:13<00:47,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.5042, loss: 0.0645, reg_loss: 0.0000 ||:  89%|████████▉ | 160/180 [06:16<00:49,  2.45s/it]\u001b[A\n",
            "pearson(r): 0.5046, loss: 0.0644, reg_loss: 0.0000 ||:  89%|████████▉ | 161/180 [06:18<00:48,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.5056, loss: 0.0643, reg_loss: 0.0000 ||:  90%|█████████ | 162/180 [06:20<00:42,  2.38s/it]\u001b[A\n",
            "pearson(r): 0.5063, loss: 0.0643, reg_loss: 0.0000 ||:  91%|█████████ | 163/180 [06:22<00:37,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.5064, loss: 0.0643, reg_loss: 0.0000 ||:  91%|█████████ | 164/180 [06:25<00:39,  2.45s/it]\u001b[A\n",
            "pearson(r): 0.5072, loss: 0.0642, reg_loss: 0.0000 ||:  92%|█████████▏| 165/180 [06:28<00:38,  2.55s/it]\u001b[A\n",
            "pearson(r): 0.5076, loss: 0.0641, reg_loss: 0.0000 ||:  92%|█████████▏| 166/180 [06:30<00:32,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.5072, loss: 0.0641, reg_loss: 0.0000 ||:  93%|█████████▎| 167/180 [06:32<00:29,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.5073, loss: 0.0641, reg_loss: 0.0000 ||:  93%|█████████▎| 168/180 [06:34<00:25,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.5068, loss: 0.0641, reg_loss: 0.0000 ||:  94%|█████████▍| 169/180 [06:36<00:24,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.5062, loss: 0.0641, reg_loss: 0.0000 ||:  94%|█████████▍| 170/180 [06:38<00:21,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.5063, loss: 0.0641, reg_loss: 0.0000 ||:  95%|█████████▌| 171/180 [06:40<00:18,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.5060, loss: 0.0641, reg_loss: 0.0000 ||:  96%|█████████▌| 172/180 [06:42<00:16,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.5074, loss: 0.0640, reg_loss: 0.0000 ||:  96%|█████████▌| 173/180 [06:44<00:13,  1.94s/it]\u001b[A\n",
            "pearson(r): 0.5082, loss: 0.0640, reg_loss: 0.0000 ||:  97%|█████████▋| 174/180 [06:46<00:11,  1.92s/it]\u001b[A\n",
            "pearson(r): 0.5078, loss: 0.0642, reg_loss: 0.0000 ||:  97%|█████████▋| 175/180 [06:48<00:09,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.5074, loss: 0.0642, reg_loss: 0.0000 ||:  98%|█████████▊| 176/180 [06:50<00:08,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.5079, loss: 0.0641, reg_loss: 0.0000 ||:  98%|█████████▊| 177/180 [06:52<00:06,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.5080, loss: 0.0642, reg_loss: 0.0000 ||:  99%|█████████▉| 178/180 [06:54<00:04,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.5089, loss: 0.0640, reg_loss: 0.0000 ||:  99%|█████████▉| 179/180 [06:56<00:02,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.5097, loss: 0.0640, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [06:59<00:00,  2.33s/it]\n",
            "\n",
            "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.6962, loss: 0.0829, reg_loss: 0.0000 ||:   2%|▏         | 1/47 [00:00<00:12,  3.82it/s]\u001b[A\n",
            "pearson(r): 0.7068, loss: 0.0897, reg_loss: 0.0000 ||:   4%|▍         | 2/47 [00:00<00:12,  3.70it/s]\u001b[A\n",
            "pearson(r): 0.7239, loss: 0.0869, reg_loss: 0.0000 ||:   6%|▋         | 3/47 [00:00<00:12,  3.50it/s]\u001b[A\n",
            "pearson(r): 0.7130, loss: 0.1113, reg_loss: 0.0000 ||:   9%|▊         | 4/47 [00:01<00:12,  3.43it/s]\u001b[A\n",
            "pearson(r): 0.6903, loss: 0.1093, reg_loss: 0.0000 ||:  11%|█         | 5/47 [00:01<00:11,  3.57it/s]\u001b[A\n",
            "pearson(r): 0.6827, loss: 0.1102, reg_loss: 0.0000 ||:  13%|█▎        | 6/47 [00:01<00:11,  3.43it/s]\u001b[A\n",
            "pearson(r): 0.6639, loss: 0.1197, reg_loss: 0.0000 ||:  15%|█▍        | 7/47 [00:02<00:11,  3.38it/s]\u001b[A\n",
            "pearson(r): 0.6650, loss: 0.1253, reg_loss: 0.0000 ||:  17%|█▋        | 8/47 [00:02<00:12,  3.15it/s]\u001b[A\n",
            "pearson(r): 0.6535, loss: 0.1297, reg_loss: 0.0000 ||:  19%|█▉        | 9/47 [00:02<00:12,  2.95it/s]\u001b[A\n",
            "pearson(r): 0.6526, loss: 0.1305, reg_loss: 0.0000 ||:  21%|██▏       | 10/47 [00:03<00:13,  2.84it/s]\u001b[A\n",
            "pearson(r): 0.6492, loss: 0.1276, reg_loss: 0.0000 ||:  23%|██▎       | 11/47 [00:03<00:13,  2.67it/s]\u001b[A\n",
            "pearson(r): 0.6577, loss: 0.1246, reg_loss: 0.0000 ||:  26%|██▌       | 12/47 [00:04<00:13,  2.61it/s]\u001b[A\n",
            "pearson(r): 0.6438, loss: 0.1296, reg_loss: 0.0000 ||:  28%|██▊       | 13/47 [00:04<00:13,  2.53it/s]\u001b[A\n",
            "pearson(r): 0.6427, loss: 0.1308, reg_loss: 0.0000 ||:  30%|██▉       | 14/47 [00:04<00:13,  2.53it/s]\u001b[A\n",
            "pearson(r): 0.6226, loss: 0.1381, reg_loss: 0.0000 ||:  32%|███▏      | 15/47 [00:05<00:12,  2.48it/s]\u001b[A\n",
            "pearson(r): 0.6208, loss: 0.1405, reg_loss: 0.0000 ||:  34%|███▍      | 16/47 [00:05<00:12,  2.44it/s]\u001b[A\n",
            "pearson(r): 0.6271, loss: 0.1383, reg_loss: 0.0000 ||:  36%|███▌      | 17/47 [00:06<00:12,  2.41it/s]\u001b[A\n",
            "pearson(r): 0.6249, loss: 0.1406, reg_loss: 0.0000 ||:  38%|███▊      | 18/47 [00:06<00:11,  2.42it/s]\u001b[A\n",
            "pearson(r): 0.6280, loss: 0.1413, reg_loss: 0.0000 ||:  40%|████      | 19/47 [00:06<00:11,  2.42it/s]\u001b[A\n",
            "pearson(r): 0.6210, loss: 0.1449, reg_loss: 0.0000 ||:  43%|████▎     | 20/47 [00:07<00:12,  2.23it/s]\u001b[A\n",
            "pearson(r): 0.6105, loss: 0.1497, reg_loss: 0.0000 ||:  45%|████▍     | 21/47 [00:08<00:12,  2.09it/s]\u001b[A\n",
            "pearson(r): 0.5985, loss: 0.1539, reg_loss: 0.0000 ||:  47%|████▋     | 22/47 [00:08<00:12,  1.96it/s]\u001b[A\n",
            "pearson(r): 0.5912, loss: 0.1560, reg_loss: 0.0000 ||:  49%|████▉     | 23/47 [00:09<00:12,  1.87it/s]\u001b[A\n",
            "pearson(r): 0.5803, loss: 0.1602, reg_loss: 0.0000 ||:  51%|█████     | 24/47 [00:09<00:12,  1.79it/s]\u001b[A\n",
            "pearson(r): 0.5594, loss: 0.1665, reg_loss: 0.0000 ||:  53%|█████▎    | 25/47 [00:10<00:12,  1.77it/s]\u001b[A\n",
            "pearson(r): 0.5523, loss: 0.1674, reg_loss: 0.0000 ||:  55%|█████▌    | 26/47 [00:10<00:11,  1.81it/s]\u001b[A\n",
            "pearson(r): 0.5448, loss: 0.1700, reg_loss: 0.0000 ||:  57%|█████▋    | 27/47 [00:11<00:11,  1.82it/s]\u001b[A\n",
            "pearson(r): 0.5339, loss: 0.1732, reg_loss: 0.0000 ||:  60%|█████▉    | 28/47 [00:12<00:10,  1.76it/s]\u001b[A\n",
            "pearson(r): 0.5251, loss: 0.1779, reg_loss: 0.0000 ||:  62%|██████▏   | 29/47 [00:12<00:10,  1.79it/s]\u001b[A\n",
            "pearson(r): 0.5156, loss: 0.1820, reg_loss: 0.0000 ||:  64%|██████▍   | 30/47 [00:13<00:09,  1.79it/s]\u001b[A\n",
            "pearson(r): 0.5091, loss: 0.1853, reg_loss: 0.0000 ||:  66%|██████▌   | 31/47 [00:13<00:08,  1.83it/s]\u001b[A\n",
            "pearson(r): 0.5149, loss: 0.1837, reg_loss: 0.0000 ||:  68%|██████▊   | 32/47 [00:14<00:08,  1.72it/s]\u001b[A\n",
            "pearson(r): 0.5249, loss: 0.1803, reg_loss: 0.0000 ||:  70%|███████   | 33/47 [00:14<00:08,  1.67it/s]\u001b[A\n",
            "pearson(r): 0.5322, loss: 0.1769, reg_loss: 0.0000 ||:  72%|███████▏  | 34/47 [00:15<00:08,  1.62it/s]\u001b[A\n",
            "pearson(r): 0.5384, loss: 0.1740, reg_loss: 0.0000 ||:  74%|███████▍  | 35/47 [00:16<00:08,  1.49it/s]\u001b[A\n",
            "pearson(r): 0.5414, loss: 0.1721, reg_loss: 0.0000 ||:  77%|███████▋  | 36/47 [00:17<00:07,  1.49it/s]\u001b[A\n",
            "pearson(r): 0.5450, loss: 0.1698, reg_loss: 0.0000 ||:  79%|███████▊  | 37/47 [00:17<00:06,  1.51it/s]\u001b[A\n",
            "pearson(r): 0.5490, loss: 0.1675, reg_loss: 0.0000 ||:  81%|████████  | 38/47 [00:18<00:05,  1.50it/s]\u001b[A\n",
            "pearson(r): 0.5546, loss: 0.1653, reg_loss: 0.0000 ||:  83%|████████▎ | 39/47 [00:19<00:05,  1.47it/s]\u001b[A\n",
            "pearson(r): 0.5513, loss: 0.1652, reg_loss: 0.0000 ||:  85%|████████▌ | 40/47 [00:19<00:04,  1.67it/s]\u001b[A\n",
            "pearson(r): 0.5501, loss: 0.1641, reg_loss: 0.0000 ||:  87%|████████▋ | 41/47 [00:19<00:03,  1.92it/s]\u001b[A\n",
            "pearson(r): 0.5526, loss: 0.1637, reg_loss: 0.0000 ||:  89%|████████▉ | 42/47 [00:20<00:02,  2.20it/s]\u001b[A\n",
            "pearson(r): 0.5488, loss: 0.1653, reg_loss: 0.0000 ||:  91%|█████████▏| 43/47 [00:20<00:01,  2.40it/s]\u001b[A\n",
            "pearson(r): 0.5470, loss: 0.1652, reg_loss: 0.0000 ||:  94%|█████████▎| 44/47 [00:20<00:01,  2.54it/s]\u001b[A\n",
            "pearson(r): 0.5420, loss: 0.1665, reg_loss: 0.0000 ||:  96%|█████████▌| 45/47 [00:21<00:00,  2.70it/s]\u001b[A\n",
            "pearson(r): 0.5441, loss: 0.1679, reg_loss: 0.0000 ||:  98%|█████████▊| 46/47 [00:21<00:00,  2.71it/s]\u001b[A\n",
            "pearson(r): 0.5403, loss: 0.1686, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:21<00:00,  2.15it/s]\n",
            "\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.7793, loss: 0.0383, reg_loss: 0.0000 ||:   1%|          | 1/180 [00:01<05:09,  1.73s/it]\u001b[A\n",
            "pearson(r): 0.6392, loss: 0.0606, reg_loss: 0.0000 ||:   1%|          | 2/180 [00:03<05:20,  1.80s/it]\u001b[A\n",
            "pearson(r): 0.6819, loss: 0.0529, reg_loss: 0.0000 ||:   2%|▏         | 3/180 [00:09<08:59,  3.05s/it]\u001b[A\n",
            "pearson(r): 0.6575, loss: 0.0575, reg_loss: 0.0000 ||:   2%|▏         | 4/180 [00:12<08:21,  2.85s/it]\u001b[A\n",
            "pearson(r): 0.6489, loss: 0.0551, reg_loss: 0.0000 ||:   3%|▎         | 5/180 [00:13<07:27,  2.56s/it]\u001b[A\n",
            "pearson(r): 0.6168, loss: 0.0556, reg_loss: 0.0000 ||:   3%|▎         | 6/180 [00:16<07:05,  2.45s/it]\u001b[A\n",
            "pearson(r): 0.6144, loss: 0.0562, reg_loss: 0.0000 ||:   4%|▍         | 7/180 [00:18<07:13,  2.51s/it]\u001b[A\n",
            "pearson(r): 0.6258, loss: 0.0536, reg_loss: 0.0000 ||:   4%|▍         | 8/180 [00:21<07:09,  2.49s/it]\u001b[A\n",
            "pearson(r): 0.6114, loss: 0.0563, reg_loss: 0.0000 ||:   5%|▌         | 9/180 [00:23<07:13,  2.54s/it]\u001b[A\n",
            "pearson(r): 0.6092, loss: 0.0562, reg_loss: 0.0000 ||:   6%|▌         | 10/180 [00:26<07:27,  2.63s/it]\u001b[A\n",
            "pearson(r): 0.6304, loss: 0.0541, reg_loss: 0.0000 ||:   6%|▌         | 11/180 [00:28<06:35,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.6425, loss: 0.0527, reg_loss: 0.0000 ||:   7%|▋         | 12/180 [00:30<06:26,  2.30s/it]\u001b[A\n",
            "pearson(r): 0.6362, loss: 0.0524, reg_loss: 0.0000 ||:   7%|▋         | 13/180 [00:32<06:13,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.6298, loss: 0.0520, reg_loss: 0.0000 ||:   8%|▊         | 14/180 [00:34<05:50,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.6446, loss: 0.0522, reg_loss: 0.0000 ||:   8%|▊         | 15/180 [00:36<05:34,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.6493, loss: 0.0517, reg_loss: 0.0000 ||:   9%|▉         | 16/180 [00:37<05:13,  1.91s/it]\u001b[A\n",
            "pearson(r): 0.6479, loss: 0.0506, reg_loss: 0.0000 ||:   9%|▉         | 17/180 [00:39<05:13,  1.92s/it]\u001b[A\n",
            "pearson(r): 0.6428, loss: 0.0507, reg_loss: 0.0000 ||:  10%|█         | 18/180 [00:43<06:42,  2.48s/it]\u001b[A\n",
            "pearson(r): 0.6422, loss: 0.0510, reg_loss: 0.0000 ||:  11%|█         | 19/180 [00:45<06:16,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.6431, loss: 0.0506, reg_loss: 0.0000 ||:  11%|█         | 20/180 [00:47<05:41,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.6340, loss: 0.0520, reg_loss: 0.0000 ||:  12%|█▏        | 21/180 [00:51<07:21,  2.78s/it]\u001b[A\n",
            "pearson(r): 0.6369, loss: 0.0517, reg_loss: 0.0000 ||:  12%|█▏        | 22/180 [00:54<07:32,  2.86s/it]\u001b[A\n",
            "pearson(r): 0.6410, loss: 0.0508, reg_loss: 0.0000 ||:  13%|█▎        | 23/180 [00:56<06:56,  2.65s/it]\u001b[A\n",
            "pearson(r): 0.6459, loss: 0.0505, reg_loss: 0.0000 ||:  13%|█▎        | 24/180 [00:58<06:12,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.6485, loss: 0.0506, reg_loss: 0.0000 ||:  14%|█▍        | 25/180 [01:00<05:42,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.6558, loss: 0.0503, reg_loss: 0.0000 ||:  14%|█▍        | 26/180 [01:02<05:30,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.6594, loss: 0.0499, reg_loss: 0.0000 ||:  15%|█▌        | 27/180 [01:03<05:01,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.6589, loss: 0.0495, reg_loss: 0.0000 ||:  16%|█▌        | 28/180 [01:06<05:29,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.6602, loss: 0.0493, reg_loss: 0.0000 ||:  16%|█▌        | 29/180 [01:08<05:20,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.6655, loss: 0.0493, reg_loss: 0.0000 ||:  17%|█▋        | 30/180 [01:10<05:23,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.6623, loss: 0.0498, reg_loss: 0.0000 ||:  17%|█▋        | 31/180 [01:12<05:08,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.6585, loss: 0.0505, reg_loss: 0.0000 ||:  18%|█▊        | 32/180 [01:14<04:48,  1.95s/it]\u001b[A\n",
            "pearson(r): 0.6603, loss: 0.0505, reg_loss: 0.0000 ||:  18%|█▊        | 33/180 [01:21<08:23,  3.42s/it]\u001b[A\n",
            "pearson(r): 0.6511, loss: 0.0512, reg_loss: 0.0000 ||:  19%|█▉        | 34/180 [01:23<07:08,  2.93s/it]\u001b[A\n",
            "pearson(r): 0.6498, loss: 0.0513, reg_loss: 0.0000 ||:  19%|█▉        | 35/180 [01:25<07:05,  2.94s/it]\u001b[A\n",
            "pearson(r): 0.6520, loss: 0.0510, reg_loss: 0.0000 ||:  20%|██        | 36/180 [01:28<06:45,  2.81s/it]\u001b[A\n",
            "pearson(r): 0.6528, loss: 0.0512, reg_loss: 0.0000 ||:  21%|██        | 37/180 [01:30<05:55,  2.48s/it]\u001b[A\n",
            "pearson(r): 0.6536, loss: 0.0505, reg_loss: 0.0000 ||:  21%|██        | 38/180 [01:32<05:35,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.6549, loss: 0.0504, reg_loss: 0.0000 ||:  22%|██▏       | 39/180 [01:34<05:14,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.6530, loss: 0.0501, reg_loss: 0.0000 ||:  22%|██▏       | 40/180 [01:36<05:06,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.6532, loss: 0.0501, reg_loss: 0.0000 ||:  23%|██▎       | 41/180 [01:38<04:51,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.6575, loss: 0.0500, reg_loss: 0.0000 ||:  23%|██▎       | 42/180 [01:40<04:41,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.6546, loss: 0.0502, reg_loss: 0.0000 ||:  24%|██▍       | 43/180 [01:42<05:01,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.6528, loss: 0.0507, reg_loss: 0.0000 ||:  24%|██▍       | 44/180 [01:46<06:02,  2.67s/it]\u001b[A\n",
            "pearson(r): 0.6510, loss: 0.0508, reg_loss: 0.0000 ||:  25%|██▌       | 45/180 [01:48<05:32,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.6525, loss: 0.0505, reg_loss: 0.0000 ||:  26%|██▌       | 46/180 [01:50<05:12,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.6538, loss: 0.0499, reg_loss: 0.0000 ||:  26%|██▌       | 47/180 [01:52<04:47,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.6530, loss: 0.0498, reg_loss: 0.0000 ||:  27%|██▋       | 48/180 [01:54<04:55,  2.24s/it]\u001b[A\n",
            "pearson(r): 0.6572, loss: 0.0496, reg_loss: 0.0000 ||:  27%|██▋       | 49/180 [01:57<05:21,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.6581, loss: 0.0495, reg_loss: 0.0000 ||:  28%|██▊       | 50/180 [01:59<05:12,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.6580, loss: 0.0494, reg_loss: 0.0000 ||:  28%|██▊       | 51/180 [02:01<04:37,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.6583, loss: 0.0493, reg_loss: 0.0000 ||:  29%|██▉       | 52/180 [02:03<04:41,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.6585, loss: 0.0493, reg_loss: 0.0000 ||:  29%|██▉       | 53/180 [02:05<04:27,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.6616, loss: 0.0491, reg_loss: 0.0000 ||:  30%|███       | 54/180 [02:07<04:17,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.6628, loss: 0.0491, reg_loss: 0.0000 ||:  31%|███       | 55/180 [02:09<04:05,  1.96s/it]\u001b[A\n",
            "pearson(r): 0.6639, loss: 0.0490, reg_loss: 0.0000 ||:  31%|███       | 56/180 [02:11<04:03,  1.96s/it]\u001b[A\n",
            "pearson(r): 0.6645, loss: 0.0492, reg_loss: 0.0000 ||:  32%|███▏      | 57/180 [02:13<04:04,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.6653, loss: 0.0488, reg_loss: 0.0000 ||:  32%|███▏      | 58/180 [02:17<05:13,  2.57s/it]\u001b[A\n",
            "pearson(r): 0.6653, loss: 0.0486, reg_loss: 0.0000 ||:  33%|███▎      | 59/180 [02:19<04:54,  2.44s/it]\u001b[A\n",
            "pearson(r): 0.6655, loss: 0.0488, reg_loss: 0.0000 ||:  33%|███▎      | 60/180 [02:20<04:17,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.6647, loss: 0.0487, reg_loss: 0.0000 ||:  34%|███▍      | 61/180 [02:24<04:51,  2.45s/it]\u001b[A\n",
            "pearson(r): 0.6645, loss: 0.0488, reg_loss: 0.0000 ||:  34%|███▍      | 62/180 [02:26<04:42,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.6639, loss: 0.0489, reg_loss: 0.0000 ||:  35%|███▌      | 63/180 [02:27<04:11,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.6633, loss: 0.0488, reg_loss: 0.0000 ||:  36%|███▌      | 64/180 [02:30<04:28,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.6621, loss: 0.0487, reg_loss: 0.0000 ||:  36%|███▌      | 65/180 [02:32<04:16,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.6628, loss: 0.0486, reg_loss: 0.0000 ||:  37%|███▋      | 66/180 [02:34<04:03,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.6620, loss: 0.0488, reg_loss: 0.0000 ||:  37%|███▋      | 67/180 [02:36<04:06,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.6601, loss: 0.0489, reg_loss: 0.0000 ||:  38%|███▊      | 68/180 [02:38<03:52,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.6608, loss: 0.0490, reg_loss: 0.0000 ||:  38%|███▊      | 69/180 [02:41<04:08,  2.24s/it]\u001b[A\n",
            "pearson(r): 0.6614, loss: 0.0488, reg_loss: 0.0000 ||:  39%|███▉      | 70/180 [02:43<04:10,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.6619, loss: 0.0488, reg_loss: 0.0000 ||:  39%|███▉      | 71/180 [02:46<04:38,  2.55s/it]\u001b[A\n",
            "pearson(r): 0.6583, loss: 0.0492, reg_loss: 0.0000 ||:  40%|████      | 72/180 [02:50<05:16,  2.93s/it]\u001b[A\n",
            "pearson(r): 0.6579, loss: 0.0491, reg_loss: 0.0000 ||:  41%|████      | 73/180 [02:52<04:39,  2.62s/it]\u001b[A\n",
            "pearson(r): 0.6577, loss: 0.0490, reg_loss: 0.0000 ||:  41%|████      | 74/180 [02:54<04:24,  2.49s/it]\u001b[A\n",
            "pearson(r): 0.6568, loss: 0.0489, reg_loss: 0.0000 ||:  42%|████▏     | 75/180 [02:56<03:53,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.6586, loss: 0.0488, reg_loss: 0.0000 ||:  42%|████▏     | 76/180 [02:58<04:04,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.6567, loss: 0.0490, reg_loss: 0.0000 ||:  43%|████▎     | 77/180 [03:00<03:40,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.6594, loss: 0.0488, reg_loss: 0.0000 ||:  43%|████▎     | 78/180 [03:02<03:42,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.6593, loss: 0.0490, reg_loss: 0.0000 ||:  44%|████▍     | 79/180 [03:04<03:34,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.6592, loss: 0.0488, reg_loss: 0.0000 ||:  44%|████▍     | 80/180 [03:07<03:33,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.6570, loss: 0.0492, reg_loss: 0.0000 ||:  45%|████▌     | 81/180 [03:10<04:19,  2.62s/it]\u001b[A\n",
            "pearson(r): 0.6575, loss: 0.0491, reg_loss: 0.0000 ||:  46%|████▌     | 82/180 [03:12<03:56,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.6581, loss: 0.0490, reg_loss: 0.0000 ||:  46%|████▌     | 83/180 [03:14<03:36,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.6566, loss: 0.0491, reg_loss: 0.0000 ||:  47%|████▋     | 84/180 [03:16<03:27,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.6580, loss: 0.0490, reg_loss: 0.0000 ||:  47%|████▋     | 85/180 [03:18<03:16,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.6579, loss: 0.0490, reg_loss: 0.0000 ||:  48%|████▊     | 86/180 [03:20<03:20,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.6580, loss: 0.0488, reg_loss: 0.0000 ||:  48%|████▊     | 87/180 [03:22<03:12,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.6577, loss: 0.0488, reg_loss: 0.0000 ||:  49%|████▉     | 88/180 [03:24<03:11,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.6573, loss: 0.0489, reg_loss: 0.0000 ||:  49%|████▉     | 89/180 [03:26<03:13,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.6570, loss: 0.0489, reg_loss: 0.0000 ||:  50%|█████     | 90/180 [03:29<03:16,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.6555, loss: 0.0489, reg_loss: 0.0000 ||:  51%|█████     | 91/180 [03:31<03:13,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.6560, loss: 0.0489, reg_loss: 0.0000 ||:  51%|█████     | 92/180 [03:33<03:09,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.6568, loss: 0.0487, reg_loss: 0.0000 ||:  52%|█████▏    | 93/180 [03:35<03:07,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.6573, loss: 0.0487, reg_loss: 0.0000 ||:  52%|█████▏    | 94/180 [03:37<03:08,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.6566, loss: 0.0486, reg_loss: 0.0000 ||:  53%|█████▎    | 95/180 [03:39<03:00,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.6553, loss: 0.0487, reg_loss: 0.0000 ||:  53%|█████▎    | 96/180 [03:41<02:57,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.6558, loss: 0.0485, reg_loss: 0.0000 ||:  54%|█████▍    | 97/180 [03:44<02:56,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.6568, loss: 0.0484, reg_loss: 0.0000 ||:  54%|█████▍    | 98/180 [03:46<02:52,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.6571, loss: 0.0484, reg_loss: 0.0000 ||:  55%|█████▌    | 99/180 [03:48<02:53,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.6567, loss: 0.0485, reg_loss: 0.0000 ||:  56%|█████▌    | 100/180 [03:50<02:54,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.6578, loss: 0.0484, reg_loss: 0.0000 ||:  56%|█████▌    | 101/180 [03:52<02:47,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.6584, loss: 0.0484, reg_loss: 0.0000 ||:  57%|█████▋    | 102/180 [03:54<02:33,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.6587, loss: 0.0483, reg_loss: 0.0000 ||:  57%|█████▋    | 103/180 [03:56<02:27,  1.92s/it]\u001b[A\n",
            "pearson(r): 0.6602, loss: 0.0483, reg_loss: 0.0000 ||:  58%|█████▊    | 104/180 [03:58<02:26,  1.92s/it]\u001b[A\n",
            "pearson(r): 0.6613, loss: 0.0482, reg_loss: 0.0000 ||:  58%|█████▊    | 105/180 [04:00<02:28,  1.98s/it]\u001b[A\n",
            "pearson(r): 0.6607, loss: 0.0481, reg_loss: 0.0000 ||:  59%|█████▉    | 106/180 [04:01<02:22,  1.92s/it]\u001b[A\n",
            "pearson(r): 0.6609, loss: 0.0481, reg_loss: 0.0000 ||:  59%|█████▉    | 107/180 [04:04<02:26,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.6593, loss: 0.0481, reg_loss: 0.0000 ||:  60%|██████    | 108/180 [04:10<04:08,  3.45s/it]\u001b[A\n",
            "pearson(r): 0.6576, loss: 0.0483, reg_loss: 0.0000 ||:  61%|██████    | 109/180 [04:17<05:10,  4.37s/it]\u001b[A\n",
            "pearson(r): 0.6585, loss: 0.0482, reg_loss: 0.0000 ||:  61%|██████    | 110/180 [04:19<04:11,  3.60s/it]\u001b[A\n",
            "pearson(r): 0.6582, loss: 0.0482, reg_loss: 0.0000 ||:  62%|██████▏   | 111/180 [04:21<03:30,  3.06s/it]\u001b[A\n",
            "pearson(r): 0.6586, loss: 0.0482, reg_loss: 0.0000 ||:  62%|██████▏   | 112/180 [04:22<02:59,  2.64s/it]\u001b[A\n",
            "pearson(r): 0.6566, loss: 0.0484, reg_loss: 0.0000 ||:  63%|██████▎   | 113/180 [04:24<02:43,  2.44s/it]\u001b[A\n",
            "pearson(r): 0.6583, loss: 0.0483, reg_loss: 0.0000 ||:  63%|██████▎   | 114/180 [04:26<02:35,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.6565, loss: 0.0484, reg_loss: 0.0000 ||:  64%|██████▍   | 115/180 [04:28<02:22,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.6557, loss: 0.0485, reg_loss: 0.0000 ||:  64%|██████▍   | 116/180 [04:30<02:12,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.6554, loss: 0.0485, reg_loss: 0.0000 ||:  65%|██████▌   | 117/180 [04:32<02:13,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.6543, loss: 0.0485, reg_loss: 0.0000 ||:  66%|██████▌   | 118/180 [04:36<02:40,  2.59s/it]\u001b[A\n",
            "pearson(r): 0.6529, loss: 0.0488, reg_loss: 0.0000 ||:  66%|██████▌   | 119/180 [04:42<03:50,  3.78s/it]\u001b[A\n",
            "pearson(r): 0.6539, loss: 0.0487, reg_loss: 0.0000 ||:  67%|██████▋   | 120/180 [04:45<03:20,  3.34s/it]\u001b[A\n",
            "pearson(r): 0.6531, loss: 0.0487, reg_loss: 0.0000 ||:  67%|██████▋   | 121/180 [04:47<02:59,  3.04s/it]\u001b[A\n",
            "pearson(r): 0.6538, loss: 0.0486, reg_loss: 0.0000 ||:  68%|██████▊   | 122/180 [04:49<02:36,  2.69s/it]\u001b[A\n",
            "pearson(r): 0.6550, loss: 0.0485, reg_loss: 0.0000 ||:  68%|██████▊   | 123/180 [04:51<02:24,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.6555, loss: 0.0484, reg_loss: 0.0000 ||:  69%|██████▉   | 124/180 [04:53<02:15,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.6563, loss: 0.0483, reg_loss: 0.0000 ||:  69%|██████▉   | 125/180 [04:56<02:14,  2.44s/it]\u001b[A\n",
            "pearson(r): 0.6556, loss: 0.0484, reg_loss: 0.0000 ||:  70%|███████   | 126/180 [04:58<02:09,  2.40s/it]\u001b[A\n",
            "pearson(r): 0.6544, loss: 0.0484, reg_loss: 0.0000 ||:  71%|███████   | 127/180 [05:02<02:26,  2.77s/it]\u001b[A\n",
            "pearson(r): 0.6553, loss: 0.0483, reg_loss: 0.0000 ||:  71%|███████   | 128/180 [05:04<02:14,  2.58s/it]\u001b[A\n",
            "pearson(r): 0.6568, loss: 0.0482, reg_loss: 0.0000 ||:  72%|███████▏  | 129/180 [05:06<02:08,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.6562, loss: 0.0482, reg_loss: 0.0000 ||:  72%|███████▏  | 130/180 [05:08<02:00,  2.40s/it]\u001b[A\n",
            "pearson(r): 0.6547, loss: 0.0485, reg_loss: 0.0000 ||:  73%|███████▎  | 131/180 [05:10<01:52,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.6548, loss: 0.0485, reg_loss: 0.0000 ||:  73%|███████▎  | 132/180 [05:13<01:47,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.6545, loss: 0.0485, reg_loss: 0.0000 ||:  74%|███████▍  | 133/180 [05:15<01:53,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.6554, loss: 0.0485, reg_loss: 0.0000 ||:  74%|███████▍  | 134/180 [05:18<01:48,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.6553, loss: 0.0485, reg_loss: 0.0000 ||:  75%|███████▌  | 135/180 [05:19<01:40,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.6555, loss: 0.0484, reg_loss: 0.0000 ||:  76%|███████▌  | 136/180 [05:22<01:37,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.6564, loss: 0.0484, reg_loss: 0.0000 ||:  76%|███████▌  | 137/180 [05:24<01:38,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.6558, loss: 0.0484, reg_loss: 0.0000 ||:  77%|███████▋  | 138/180 [05:26<01:25,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.6565, loss: 0.0485, reg_loss: 0.0000 ||:  77%|███████▋  | 139/180 [05:28<01:23,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.6567, loss: 0.0485, reg_loss: 0.0000 ||:  78%|███████▊  | 140/180 [05:30<01:30,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.6567, loss: 0.0485, reg_loss: 0.0000 ||:  78%|███████▊  | 141/180 [05:32<01:19,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.6568, loss: 0.0485, reg_loss: 0.0000 ||:  79%|███████▉  | 142/180 [05:35<01:26,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.6566, loss: 0.0485, reg_loss: 0.0000 ||:  79%|███████▉  | 143/180 [05:37<01:19,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.6560, loss: 0.0486, reg_loss: 0.0000 ||:  80%|████████  | 144/180 [05:39<01:16,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.6554, loss: 0.0486, reg_loss: 0.0000 ||:  81%|████████  | 145/180 [05:41<01:12,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.6560, loss: 0.0486, reg_loss: 0.0000 ||:  81%|████████  | 146/180 [05:42<01:03,  1.87s/it]\u001b[A\n",
            "pearson(r): 0.6559, loss: 0.0485, reg_loss: 0.0000 ||:  82%|████████▏ | 147/180 [05:45<01:08,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.6560, loss: 0.0484, reg_loss: 0.0000 ||:  82%|████████▏ | 148/180 [05:47<01:13,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.6551, loss: 0.0485, reg_loss: 0.0000 ||:  83%|████████▎ | 149/180 [05:50<01:09,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.6546, loss: 0.0486, reg_loss: 0.0000 ||:  83%|████████▎ | 150/180 [05:52<01:06,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.6547, loss: 0.0486, reg_loss: 0.0000 ||:  84%|████████▍ | 151/180 [05:53<00:56,  1.95s/it]\u001b[A\n",
            "pearson(r): 0.6544, loss: 0.0486, reg_loss: 0.0000 ||:  84%|████████▍ | 152/180 [05:55<00:54,  1.96s/it]\u001b[A\n",
            "pearson(r): 0.6541, loss: 0.0487, reg_loss: 0.0000 ||:  85%|████████▌ | 153/180 [05:57<00:52,  1.94s/it]\u001b[A\n",
            "pearson(r): 0.6541, loss: 0.0489, reg_loss: 0.0000 ||:  86%|████████▌ | 154/180 [06:00<00:59,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.6526, loss: 0.0491, reg_loss: 0.0000 ||:  86%|████████▌ | 155/180 [06:02<00:55,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.6522, loss: 0.0491, reg_loss: 0.0000 ||:  87%|████████▋ | 156/180 [06:06<01:06,  2.79s/it]\u001b[A\n",
            "pearson(r): 0.6530, loss: 0.0490, reg_loss: 0.0000 ||:  87%|████████▋ | 157/180 [06:08<00:55,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.6523, loss: 0.0492, reg_loss: 0.0000 ||:  88%|████████▊ | 158/180 [06:09<00:48,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.6523, loss: 0.0491, reg_loss: 0.0000 ||:  88%|████████▊ | 159/180 [06:11<00:44,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.6529, loss: 0.0491, reg_loss: 0.0000 ||:  89%|████████▉ | 160/180 [06:13<00:39,  1.95s/it]\u001b[A\n",
            "pearson(r): 0.6529, loss: 0.0491, reg_loss: 0.0000 ||:  89%|████████▉ | 161/180 [06:16<00:42,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.6523, loss: 0.0491, reg_loss: 0.0000 ||:  90%|█████████ | 162/180 [06:18<00:38,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.6524, loss: 0.0492, reg_loss: 0.0000 ||:  91%|█████████ | 163/180 [06:20<00:35,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.6516, loss: 0.0493, reg_loss: 0.0000 ||:  91%|█████████ | 164/180 [06:22<00:33,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.6515, loss: 0.0494, reg_loss: 0.0000 ||:  92%|█████████▏| 165/180 [06:24<00:33,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.6509, loss: 0.0493, reg_loss: 0.0000 ||:  92%|█████████▏| 166/180 [06:26<00:30,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.6514, loss: 0.0494, reg_loss: 0.0000 ||:  93%|█████████▎| 167/180 [06:29<00:28,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.6511, loss: 0.0494, reg_loss: 0.0000 ||:  93%|█████████▎| 168/180 [06:31<00:27,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.6519, loss: 0.0495, reg_loss: 0.0000 ||:  94%|█████████▍| 169/180 [06:33<00:24,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.6520, loss: 0.0495, reg_loss: 0.0000 ||:  94%|█████████▍| 170/180 [06:35<00:20,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.6517, loss: 0.0495, reg_loss: 0.0000 ||:  95%|█████████▌| 171/180 [06:37<00:18,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.6518, loss: 0.0495, reg_loss: 0.0000 ||:  96%|█████████▌| 172/180 [06:39<00:15,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.6516, loss: 0.0495, reg_loss: 0.0000 ||:  96%|█████████▌| 173/180 [06:41<00:13,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.6525, loss: 0.0495, reg_loss: 0.0000 ||:  97%|█████████▋| 174/180 [06:43<00:11,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.6535, loss: 0.0495, reg_loss: 0.0000 ||:  97%|█████████▋| 175/180 [06:45<00:09,  1.98s/it]\u001b[A\n",
            "pearson(r): 0.6537, loss: 0.0495, reg_loss: 0.0000 ||:  98%|█████████▊| 176/180 [06:47<00:08,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.6533, loss: 0.0495, reg_loss: 0.0000 ||:  98%|█████████▊| 177/180 [06:50<00:07,  2.40s/it]\u001b[A\n",
            "pearson(r): 0.6528, loss: 0.0495, reg_loss: 0.0000 ||:  99%|█████████▉| 178/180 [06:53<00:05,  2.51s/it]\u001b[A\n",
            "pearson(r): 0.6538, loss: 0.0495, reg_loss: 0.0000 ||:  99%|█████████▉| 179/180 [06:55<00:02,  2.52s/it]\u001b[A\n",
            "pearson(r): 0.6539, loss: 0.0494, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [06:57<00:00,  2.32s/it]\n",
            "\n",
            "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.6707, loss: 0.0790, reg_loss: 0.0000 ||:   2%|▏         | 1/47 [00:00<00:12,  3.64it/s]\u001b[A\n",
            "pearson(r): 0.6922, loss: 0.0863, reg_loss: 0.0000 ||:   4%|▍         | 2/47 [00:00<00:12,  3.58it/s]\u001b[A\n",
            "pearson(r): 0.7038, loss: 0.0809, reg_loss: 0.0000 ||:   6%|▋         | 3/47 [00:00<00:12,  3.40it/s]\u001b[A\n",
            "pearson(r): 0.7072, loss: 0.1000, reg_loss: 0.0000 ||:   9%|▊         | 4/47 [00:01<00:12,  3.35it/s]\u001b[A\n",
            "pearson(r): 0.7079, loss: 0.0961, reg_loss: 0.0000 ||:  11%|█         | 5/47 [00:01<00:12,  3.48it/s]\u001b[A\n",
            "pearson(r): 0.7038, loss: 0.0947, reg_loss: 0.0000 ||:  13%|█▎        | 6/47 [00:01<00:12,  3.36it/s]\u001b[A\n",
            "pearson(r): 0.6976, loss: 0.1008, reg_loss: 0.0000 ||:  15%|█▍        | 7/47 [00:02<00:12,  3.33it/s]\u001b[A\n",
            "pearson(r): 0.6960, loss: 0.1055, reg_loss: 0.0000 ||:  17%|█▋        | 8/47 [00:02<00:12,  3.12it/s]\u001b[A\n",
            "pearson(r): 0.6888, loss: 0.1059, reg_loss: 0.0000 ||:  19%|█▉        | 9/47 [00:02<00:12,  2.92it/s]\u001b[A\n",
            "pearson(r): 0.6823, loss: 0.1058, reg_loss: 0.0000 ||:  21%|██▏       | 10/47 [00:03<00:13,  2.82it/s]\u001b[A\n",
            "pearson(r): 0.6804, loss: 0.1040, reg_loss: 0.0000 ||:  23%|██▎       | 11/47 [00:03<00:13,  2.64it/s]\u001b[A\n",
            "pearson(r): 0.6873, loss: 0.1021, reg_loss: 0.0000 ||:  26%|██▌       | 12/47 [00:04<00:13,  2.58it/s]\u001b[A\n",
            "pearson(r): 0.6786, loss: 0.1064, reg_loss: 0.0000 ||:  28%|██▊       | 13/47 [00:04<00:13,  2.51it/s]\u001b[A\n",
            "pearson(r): 0.6722, loss: 0.1086, reg_loss: 0.0000 ||:  30%|██▉       | 14/47 [00:04<00:13,  2.52it/s]\u001b[A\n",
            "pearson(r): 0.6589, loss: 0.1151, reg_loss: 0.0000 ||:  32%|███▏      | 15/47 [00:05<00:12,  2.48it/s]\u001b[A\n",
            "pearson(r): 0.6531, loss: 0.1183, reg_loss: 0.0000 ||:  34%|███▍      | 16/47 [00:05<00:12,  2.42it/s]\u001b[A\n",
            "pearson(r): 0.6560, loss: 0.1171, reg_loss: 0.0000 ||:  36%|███▌      | 17/47 [00:06<00:12,  2.38it/s]\u001b[A\n",
            "pearson(r): 0.6537, loss: 0.1188, reg_loss: 0.0000 ||:  38%|███▊      | 18/47 [00:06<00:12,  2.40it/s]\u001b[A\n",
            "pearson(r): 0.6561, loss: 0.1190, reg_loss: 0.0000 ||:  40%|████      | 19/47 [00:07<00:11,  2.39it/s]\u001b[A\n",
            "pearson(r): 0.6498, loss: 0.1208, reg_loss: 0.0000 ||:  43%|████▎     | 20/47 [00:07<00:12,  2.21it/s]\u001b[A\n",
            "pearson(r): 0.6408, loss: 0.1231, reg_loss: 0.0000 ||:  45%|████▍     | 21/47 [00:08<00:12,  2.08it/s]\u001b[A\n",
            "pearson(r): 0.6283, loss: 0.1259, reg_loss: 0.0000 ||:  47%|████▋     | 22/47 [00:08<00:12,  1.96it/s]\u001b[A\n",
            "pearson(r): 0.6210, loss: 0.1263, reg_loss: 0.0000 ||:  49%|████▉     | 23/47 [00:09<00:12,  1.89it/s]\u001b[A\n",
            "pearson(r): 0.6078, loss: 0.1299, reg_loss: 0.0000 ||:  51%|█████     | 24/47 [00:09<00:12,  1.81it/s]\u001b[A\n",
            "pearson(r): 0.5941, loss: 0.1336, reg_loss: 0.0000 ||:  53%|█████▎    | 25/47 [00:10<00:12,  1.79it/s]\u001b[A\n",
            "pearson(r): 0.5893, loss: 0.1336, reg_loss: 0.0000 ||:  55%|█████▌    | 26/47 [00:10<00:11,  1.81it/s]\u001b[A\n",
            "pearson(r): 0.5786, loss: 0.1364, reg_loss: 0.0000 ||:  57%|█████▋    | 27/47 [00:11<00:11,  1.81it/s]\u001b[A\n",
            "pearson(r): 0.5682, loss: 0.1383, reg_loss: 0.0000 ||:  60%|█████▉    | 28/47 [00:12<00:10,  1.76it/s]\u001b[A\n",
            "pearson(r): 0.5631, loss: 0.1411, reg_loss: 0.0000 ||:  62%|██████▏   | 29/47 [00:12<00:10,  1.78it/s]\u001b[A\n",
            "pearson(r): 0.5508, loss: 0.1449, reg_loss: 0.0000 ||:  64%|██████▍   | 30/47 [00:13<00:09,  1.80it/s]\u001b[A\n",
            "pearson(r): 0.5434, loss: 0.1473, reg_loss: 0.0000 ||:  66%|██████▌   | 31/47 [00:13<00:08,  1.82it/s]\u001b[A\n",
            "pearson(r): 0.5467, loss: 0.1461, reg_loss: 0.0000 ||:  68%|██████▊   | 32/47 [00:14<00:08,  1.71it/s]\u001b[A\n",
            "pearson(r): 0.5553, loss: 0.1433, reg_loss: 0.0000 ||:  70%|███████   | 33/47 [00:15<00:08,  1.66it/s]\u001b[A\n",
            "pearson(r): 0.5611, loss: 0.1405, reg_loss: 0.0000 ||:  72%|███████▏  | 34/47 [00:15<00:08,  1.60it/s]\u001b[A\n",
            "pearson(r): 0.5666, loss: 0.1382, reg_loss: 0.0000 ||:  74%|███████▍  | 35/47 [00:16<00:08,  1.48it/s]\u001b[A\n",
            "pearson(r): 0.5673, loss: 0.1367, reg_loss: 0.0000 ||:  77%|███████▋  | 36/47 [00:17<00:07,  1.47it/s]\u001b[A\n",
            "pearson(r): 0.5694, loss: 0.1352, reg_loss: 0.0000 ||:  79%|███████▊  | 37/47 [00:17<00:06,  1.49it/s]\u001b[A\n",
            "pearson(r): 0.5729, loss: 0.1333, reg_loss: 0.0000 ||:  81%|████████  | 38/47 [00:18<00:06,  1.49it/s]\u001b[A\n",
            "pearson(r): 0.5775, loss: 0.1313, reg_loss: 0.0000 ||:  83%|████████▎ | 39/47 [00:19<00:05,  1.46it/s]\u001b[A\n",
            "pearson(r): 0.5759, loss: 0.1310, reg_loss: 0.0000 ||:  85%|████████▌ | 40/47 [00:19<00:04,  1.66it/s]\u001b[A\n",
            "pearson(r): 0.5755, loss: 0.1301, reg_loss: 0.0000 ||:  87%|████████▋ | 41/47 [00:20<00:03,  1.91it/s]\u001b[A\n",
            "pearson(r): 0.5771, loss: 0.1299, reg_loss: 0.0000 ||:  89%|████████▉ | 42/47 [00:20<00:02,  2.19it/s]\u001b[A\n",
            "pearson(r): 0.5764, loss: 0.1304, reg_loss: 0.0000 ||:  91%|█████████▏| 43/47 [00:20<00:01,  2.37it/s]\u001b[A\n",
            "pearson(r): 0.5759, loss: 0.1297, reg_loss: 0.0000 ||:  94%|█████████▎| 44/47 [00:20<00:01,  2.52it/s]\u001b[A\n",
            "pearson(r): 0.5693, loss: 0.1311, reg_loss: 0.0000 ||:  96%|█████████▌| 45/47 [00:21<00:00,  2.71it/s]\u001b[A\n",
            "pearson(r): 0.5736, loss: 0.1312, reg_loss: 0.0000 ||:  98%|█████████▊| 46/47 [00:21<00:00,  2.73it/s]\u001b[A\n",
            "pearson(r): 0.5679, loss: 0.1321, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:21<00:00,  2.14it/s]\n",
            "\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.6295, loss: 0.0430, reg_loss: 0.0000 ||:   1%|          | 1/180 [00:02<07:29,  2.51s/it]\u001b[A\n",
            "pearson(r): 0.6873, loss: 0.0430, reg_loss: 0.0000 ||:   1%|          | 2/180 [00:04<07:00,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.6693, loss: 0.0463, reg_loss: 0.0000 ||:   2%|▏         | 3/180 [00:06<06:21,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.6931, loss: 0.0427, reg_loss: 0.0000 ||:   2%|▏         | 4/180 [00:08<06:18,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.7153, loss: 0.0442, reg_loss: 0.0000 ||:   3%|▎         | 5/180 [00:13<08:45,  3.00s/it]\u001b[A\n",
            "pearson(r): 0.7226, loss: 0.0431, reg_loss: 0.0000 ||:   3%|▎         | 6/180 [00:15<07:35,  2.62s/it]\u001b[A\n",
            "pearson(r): 0.7157, loss: 0.0447, reg_loss: 0.0000 ||:   4%|▍         | 7/180 [00:16<06:52,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.7190, loss: 0.0433, reg_loss: 0.0000 ||:   4%|▍         | 8/180 [00:19<06:46,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.7327, loss: 0.0416, reg_loss: 0.0000 ||:   5%|▌         | 9/180 [00:21<06:20,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.7324, loss: 0.0418, reg_loss: 0.0000 ||:   6%|▌         | 10/180 [00:23<06:16,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.7477, loss: 0.0398, reg_loss: 0.0000 ||:   6%|▌         | 11/180 [00:25<05:54,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.7422, loss: 0.0397, reg_loss: 0.0000 ||:   7%|▋         | 12/180 [00:27<05:49,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.7287, loss: 0.0406, reg_loss: 0.0000 ||:   7%|▋         | 13/180 [00:29<05:44,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.7323, loss: 0.0410, reg_loss: 0.0000 ||:   8%|▊         | 14/180 [00:31<05:40,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.7230, loss: 0.0418, reg_loss: 0.0000 ||:   8%|▊         | 15/180 [00:35<07:07,  2.59s/it]\u001b[A\n",
            "pearson(r): 0.7210, loss: 0.0417, reg_loss: 0.0000 ||:   9%|▉         | 16/180 [00:37<06:37,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.7288, loss: 0.0411, reg_loss: 0.0000 ||:   9%|▉         | 17/180 [00:40<07:01,  2.59s/it]\u001b[A\n",
            "pearson(r): 0.7284, loss: 0.0412, reg_loss: 0.0000 ||:  10%|█         | 18/180 [00:41<06:11,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.7371, loss: 0.0411, reg_loss: 0.0000 ||:  11%|█         | 19/180 [00:43<05:47,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.7432, loss: 0.0410, reg_loss: 0.0000 ||:  11%|█         | 20/180 [00:45<05:20,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.7466, loss: 0.0409, reg_loss: 0.0000 ||:  12%|█▏        | 21/180 [00:47<05:48,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.7491, loss: 0.0407, reg_loss: 0.0000 ||:  12%|█▏        | 22/180 [00:49<05:31,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.7456, loss: 0.0408, reg_loss: 0.0000 ||:  13%|█▎        | 23/180 [00:51<05:31,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.7428, loss: 0.0409, reg_loss: 0.0000 ||:  13%|█▎        | 24/180 [00:54<05:33,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.7364, loss: 0.0412, reg_loss: 0.0000 ||:  14%|█▍        | 25/180 [00:55<05:21,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.7361, loss: 0.0414, reg_loss: 0.0000 ||:  14%|█▍        | 26/180 [00:58<05:22,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.7365, loss: 0.0409, reg_loss: 0.0000 ||:  15%|█▌        | 27/180 [01:00<05:18,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.7331, loss: 0.0413, reg_loss: 0.0000 ||:  16%|█▌        | 28/180 [01:02<05:37,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.7323, loss: 0.0418, reg_loss: 0.0000 ||:  16%|█▌        | 29/180 [01:04<05:14,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.7324, loss: 0.0418, reg_loss: 0.0000 ||:  17%|█▋        | 30/180 [01:06<05:34,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.7333, loss: 0.0416, reg_loss: 0.0000 ||:  17%|█▋        | 31/180 [01:08<05:18,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.7339, loss: 0.0420, reg_loss: 0.0000 ||:  18%|█▊        | 32/180 [01:10<05:11,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.7343, loss: 0.0418, reg_loss: 0.0000 ||:  18%|█▊        | 33/180 [01:13<05:08,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.7334, loss: 0.0417, reg_loss: 0.0000 ||:  19%|█▉        | 34/180 [01:15<05:13,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.7297, loss: 0.0420, reg_loss: 0.0000 ||:  19%|█▉        | 35/180 [01:17<05:12,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.7316, loss: 0.0415, reg_loss: 0.0000 ||:  20%|██        | 36/180 [01:19<04:46,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.7339, loss: 0.0412, reg_loss: 0.0000 ||:  21%|██        | 37/180 [01:21<04:52,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.7317, loss: 0.0414, reg_loss: 0.0000 ||:  21%|██        | 38/180 [01:24<05:42,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.7290, loss: 0.0419, reg_loss: 0.0000 ||:  22%|██▏       | 39/180 [01:26<05:28,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.7278, loss: 0.0420, reg_loss: 0.0000 ||:  22%|██▏       | 40/180 [01:28<05:05,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.7256, loss: 0.0424, reg_loss: 0.0000 ||:  23%|██▎       | 41/180 [01:30<05:03,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.7262, loss: 0.0423, reg_loss: 0.0000 ||:  23%|██▎       | 42/180 [01:33<05:31,  2.40s/it]\u001b[A\n",
            "pearson(r): 0.7216, loss: 0.0427, reg_loss: 0.0000 ||:  24%|██▍       | 43/180 [01:37<06:20,  2.78s/it]\u001b[A\n",
            "pearson(r): 0.7218, loss: 0.0426, reg_loss: 0.0000 ||:  24%|██▍       | 44/180 [01:40<06:34,  2.90s/it]\u001b[A\n",
            "pearson(r): 0.7207, loss: 0.0424, reg_loss: 0.0000 ||:  25%|██▌       | 45/180 [01:42<05:51,  2.60s/it]\u001b[A\n",
            "pearson(r): 0.7173, loss: 0.0430, reg_loss: 0.0000 ||:  26%|██▌       | 46/180 [01:44<05:18,  2.38s/it]\u001b[A\n",
            "pearson(r): 0.7186, loss: 0.0429, reg_loss: 0.0000 ||:  26%|██▌       | 47/180 [01:46<05:02,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.7176, loss: 0.0428, reg_loss: 0.0000 ||:  27%|██▋       | 48/180 [01:48<04:40,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.7171, loss: 0.0429, reg_loss: 0.0000 ||:  27%|██▋       | 49/180 [01:50<04:35,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.7147, loss: 0.0429, reg_loss: 0.0000 ||:  28%|██▊       | 50/180 [01:52<05:00,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.7132, loss: 0.0430, reg_loss: 0.0000 ||:  28%|██▊       | 51/180 [01:55<05:11,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.7128, loss: 0.0431, reg_loss: 0.0000 ||:  29%|██▉       | 52/180 [01:57<04:50,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.7111, loss: 0.0431, reg_loss: 0.0000 ||:  29%|██▉       | 53/180 [01:59<04:33,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.7127, loss: 0.0429, reg_loss: 0.0000 ||:  30%|███       | 54/180 [02:01<04:19,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.7103, loss: 0.0431, reg_loss: 0.0000 ||:  31%|███       | 55/180 [02:03<04:32,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.7110, loss: 0.0429, reg_loss: 0.0000 ||:  31%|███       | 56/180 [02:06<04:43,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.7141, loss: 0.0428, reg_loss: 0.0000 ||:  32%|███▏      | 57/180 [02:07<04:19,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.7157, loss: 0.0425, reg_loss: 0.0000 ||:  32%|███▏      | 58/180 [02:10<04:25,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.7143, loss: 0.0425, reg_loss: 0.0000 ||:  33%|███▎      | 59/180 [02:11<04:04,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.7142, loss: 0.0427, reg_loss: 0.0000 ||:  33%|███▎      | 60/180 [02:13<03:56,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.7166, loss: 0.0426, reg_loss: 0.0000 ||:  34%|███▍      | 61/180 [02:16<04:08,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.7140, loss: 0.0426, reg_loss: 0.0000 ||:  34%|███▍      | 62/180 [02:18<04:03,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.7129, loss: 0.0427, reg_loss: 0.0000 ||:  35%|███▌      | 63/180 [02:20<03:56,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.7125, loss: 0.0426, reg_loss: 0.0000 ||:  36%|███▌      | 64/180 [02:21<03:52,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.7135, loss: 0.0426, reg_loss: 0.0000 ||:  36%|███▌      | 65/180 [02:24<04:25,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.7140, loss: 0.0426, reg_loss: 0.0000 ||:  37%|███▋      | 66/180 [02:26<04:12,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.7133, loss: 0.0427, reg_loss: 0.0000 ||:  37%|███▋      | 67/180 [02:29<04:05,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.7120, loss: 0.0427, reg_loss: 0.0000 ||:  38%|███▊      | 68/180 [02:32<04:31,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.7139, loss: 0.0427, reg_loss: 0.0000 ||:  38%|███▊      | 69/180 [02:34<04:22,  2.37s/it]\u001b[A\n",
            "pearson(r): 0.7141, loss: 0.0427, reg_loss: 0.0000 ||:  39%|███▉      | 70/180 [02:36<04:02,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.7128, loss: 0.0429, reg_loss: 0.0000 ||:  39%|███▉      | 71/180 [02:38<03:54,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.7127, loss: 0.0430, reg_loss: 0.0000 ||:  40%|████      | 72/180 [02:40<04:04,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.7123, loss: 0.0432, reg_loss: 0.0000 ||:  41%|████      | 73/180 [02:42<03:44,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.7101, loss: 0.0433, reg_loss: 0.0000 ||:  41%|████      | 74/180 [02:44<03:42,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.7105, loss: 0.0432, reg_loss: 0.0000 ||:  42%|████▏     | 75/180 [02:47<04:01,  2.30s/it]\u001b[A\n",
            "pearson(r): 0.7106, loss: 0.0433, reg_loss: 0.0000 ||:  42%|████▏     | 76/180 [02:49<03:51,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.7105, loss: 0.0434, reg_loss: 0.0000 ||:  43%|████▎     | 77/180 [02:52<04:10,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.7093, loss: 0.0434, reg_loss: 0.0000 ||:  43%|████▎     | 78/180 [02:54<03:56,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.7097, loss: 0.0433, reg_loss: 0.0000 ||:  44%|████▍     | 79/180 [02:56<03:54,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.7104, loss: 0.0432, reg_loss: 0.0000 ||:  44%|████▍     | 80/180 [02:59<04:01,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.7116, loss: 0.0431, reg_loss: 0.0000 ||:  45%|████▌     | 81/180 [03:01<04:02,  2.45s/it]\u001b[A\n",
            "pearson(r): 0.7121, loss: 0.0431, reg_loss: 0.0000 ||:  46%|████▌     | 82/180 [03:04<04:08,  2.54s/it]\u001b[A\n",
            "pearson(r): 0.7114, loss: 0.0433, reg_loss: 0.0000 ||:  46%|████▌     | 83/180 [03:06<03:48,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.7113, loss: 0.0432, reg_loss: 0.0000 ||:  47%|████▋     | 84/180 [03:13<05:49,  3.64s/it]\u001b[A\n",
            "pearson(r): 0.7117, loss: 0.0432, reg_loss: 0.0000 ||:  47%|████▋     | 85/180 [03:15<05:07,  3.24s/it]\u001b[A\n",
            "pearson(r): 0.7119, loss: 0.0432, reg_loss: 0.0000 ||:  48%|████▊     | 86/180 [03:18<04:53,  3.12s/it]\u001b[A\n",
            "pearson(r): 0.7115, loss: 0.0431, reg_loss: 0.0000 ||:  48%|████▊     | 87/180 [03:20<04:24,  2.84s/it]\u001b[A\n",
            "pearson(r): 0.7119, loss: 0.0431, reg_loss: 0.0000 ||:  49%|████▉     | 88/180 [03:22<03:50,  2.51s/it]\u001b[A\n",
            "pearson(r): 0.7119, loss: 0.0430, reg_loss: 0.0000 ||:  49%|████▉     | 89/180 [03:24<03:37,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.7115, loss: 0.0429, reg_loss: 0.0000 ||:  50%|█████     | 90/180 [03:26<03:24,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.7102, loss: 0.0429, reg_loss: 0.0000 ||:  51%|█████     | 91/180 [03:28<03:22,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.7102, loss: 0.0429, reg_loss: 0.0000 ||:  51%|█████     | 92/180 [03:30<03:08,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.7113, loss: 0.0428, reg_loss: 0.0000 ||:  52%|█████▏    | 93/180 [03:32<03:03,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.7124, loss: 0.0428, reg_loss: 0.0000 ||:  52%|█████▏    | 94/180 [03:34<03:08,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.7120, loss: 0.0428, reg_loss: 0.0000 ||:  53%|█████▎    | 95/180 [03:36<02:46,  1.96s/it]\u001b[A\n",
            "pearson(r): 0.7121, loss: 0.0426, reg_loss: 0.0000 ||:  53%|█████▎    | 96/180 [03:37<02:40,  1.91s/it]\u001b[A\n",
            "pearson(r): 0.7120, loss: 0.0427, reg_loss: 0.0000 ||:  54%|█████▍    | 97/180 [03:40<02:47,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.7125, loss: 0.0426, reg_loss: 0.0000 ||:  54%|█████▍    | 98/180 [03:42<02:43,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.7121, loss: 0.0425, reg_loss: 0.0000 ||:  55%|█████▌    | 99/180 [03:44<02:48,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.7124, loss: 0.0425, reg_loss: 0.0000 ||:  56%|█████▌    | 100/180 [03:51<04:34,  3.44s/it]\u001b[A\n",
            "pearson(r): 0.7131, loss: 0.0424, reg_loss: 0.0000 ||:  56%|█████▌    | 101/180 [03:53<03:56,  2.99s/it]\u001b[A\n",
            "pearson(r): 0.7139, loss: 0.0424, reg_loss: 0.0000 ||:  57%|█████▋    | 102/180 [03:54<03:27,  2.66s/it]\u001b[A\n",
            "pearson(r): 0.7138, loss: 0.0425, reg_loss: 0.0000 ||:  57%|█████▋    | 103/180 [03:58<03:36,  2.81s/it]\u001b[A\n",
            "pearson(r): 0.7142, loss: 0.0424, reg_loss: 0.0000 ||:  58%|█████▊    | 104/180 [04:00<03:19,  2.62s/it]\u001b[A\n",
            "pearson(r): 0.7139, loss: 0.0424, reg_loss: 0.0000 ||:  58%|█████▊    | 105/180 [04:02<03:00,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.7140, loss: 0.0422, reg_loss: 0.0000 ||:  59%|█████▉    | 106/180 [04:04<02:47,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.7150, loss: 0.0422, reg_loss: 0.0000 ||:  59%|█████▉    | 107/180 [04:06<02:48,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.7157, loss: 0.0422, reg_loss: 0.0000 ||:  60%|██████    | 108/180 [04:08<02:32,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.7154, loss: 0.0422, reg_loss: 0.0000 ||:  61%|██████    | 109/180 [04:10<02:33,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.7117, loss: 0.0426, reg_loss: 0.0000 ||:  61%|██████    | 110/180 [04:18<04:32,  3.89s/it]\u001b[A\n",
            "pearson(r): 0.7109, loss: 0.0427, reg_loss: 0.0000 ||:  62%|██████▏   | 111/180 [04:21<04:06,  3.57s/it]\u001b[A\n",
            "pearson(r): 0.7104, loss: 0.0428, reg_loss: 0.0000 ||:  62%|██████▏   | 112/180 [04:23<03:38,  3.21s/it]\u001b[A\n",
            "pearson(r): 0.7115, loss: 0.0427, reg_loss: 0.0000 ||:  63%|██████▎   | 113/180 [04:25<03:15,  2.92s/it]\u001b[A\n",
            "pearson(r): 0.7106, loss: 0.0427, reg_loss: 0.0000 ||:  63%|██████▎   | 114/180 [04:27<02:49,  2.57s/it]\u001b[A\n",
            "pearson(r): 0.7107, loss: 0.0426, reg_loss: 0.0000 ||:  64%|██████▍   | 115/180 [04:29<02:32,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.7110, loss: 0.0426, reg_loss: 0.0000 ||:  64%|██████▍   | 116/180 [04:31<02:27,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.7118, loss: 0.0426, reg_loss: 0.0000 ||:  65%|██████▌   | 117/180 [04:33<02:20,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.7104, loss: 0.0427, reg_loss: 0.0000 ||:  66%|██████▌   | 118/180 [04:37<02:48,  2.71s/it]\u001b[A\n",
            "pearson(r): 0.7104, loss: 0.0426, reg_loss: 0.0000 ||:  66%|██████▌   | 119/180 [04:39<02:31,  2.48s/it]\u001b[A\n",
            "pearson(r): 0.7113, loss: 0.0425, reg_loss: 0.0000 ||:  67%|██████▋   | 120/180 [04:41<02:17,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.7114, loss: 0.0425, reg_loss: 0.0000 ||:  67%|██████▋   | 121/180 [04:44<02:38,  2.68s/it]\u001b[A\n",
            "pearson(r): 0.7119, loss: 0.0425, reg_loss: 0.0000 ||:  68%|██████▊   | 122/180 [04:46<02:24,  2.48s/it]\u001b[A\n",
            "pearson(r): 0.7111, loss: 0.0425, reg_loss: 0.0000 ||:  68%|██████▊   | 123/180 [04:49<02:16,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.7125, loss: 0.0424, reg_loss: 0.0000 ||:  69%|██████▉   | 124/180 [04:50<01:59,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.7130, loss: 0.0425, reg_loss: 0.0000 ||:  69%|██████▉   | 125/180 [04:52<01:48,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.7130, loss: 0.0425, reg_loss: 0.0000 ||:  70%|███████   | 126/180 [04:54<01:58,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.7133, loss: 0.0425, reg_loss: 0.0000 ||:  71%|███████   | 127/180 [04:56<01:50,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.7146, loss: 0.0424, reg_loss: 0.0000 ||:  71%|███████   | 128/180 [04:58<01:43,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.7150, loss: 0.0424, reg_loss: 0.0000 ||:  72%|███████▏  | 129/180 [05:00<01:44,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.7145, loss: 0.0424, reg_loss: 0.0000 ||:  72%|███████▏  | 130/180 [05:02<01:43,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.7149, loss: 0.0424, reg_loss: 0.0000 ||:  73%|███████▎  | 131/180 [05:04<01:40,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.7145, loss: 0.0424, reg_loss: 0.0000 ||:  73%|███████▎  | 132/180 [05:08<01:56,  2.42s/it]\u001b[A\n",
            "pearson(r): 0.7140, loss: 0.0426, reg_loss: 0.0000 ||:  74%|███████▍  | 133/180 [05:09<01:46,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.7146, loss: 0.0426, reg_loss: 0.0000 ||:  74%|███████▍  | 134/180 [05:11<01:38,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.7145, loss: 0.0426, reg_loss: 0.0000 ||:  75%|███████▌  | 135/180 [05:13<01:31,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.7156, loss: 0.0425, reg_loss: 0.0000 ||:  76%|███████▌  | 136/180 [05:15<01:26,  1.96s/it]\u001b[A\n",
            "pearson(r): 0.7147, loss: 0.0426, reg_loss: 0.0000 ||:  76%|███████▌  | 137/180 [05:17<01:32,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.7154, loss: 0.0425, reg_loss: 0.0000 ||:  77%|███████▋  | 138/180 [05:20<01:30,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.7157, loss: 0.0426, reg_loss: 0.0000 ||:  77%|███████▋  | 139/180 [05:21<01:22,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.7161, loss: 0.0425, reg_loss: 0.0000 ||:  78%|███████▊  | 140/180 [05:24<01:30,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.7163, loss: 0.0425, reg_loss: 0.0000 ||:  78%|███████▊  | 141/180 [05:26<01:26,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.7164, loss: 0.0425, reg_loss: 0.0000 ||:  79%|███████▉  | 142/180 [05:29<01:25,  2.24s/it]\u001b[A\n",
            "pearson(r): 0.7165, loss: 0.0425, reg_loss: 0.0000 ||:  79%|███████▉  | 143/180 [05:31<01:19,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.7179, loss: 0.0425, reg_loss: 0.0000 ||:  80%|████████  | 144/180 [05:33<01:16,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.7181, loss: 0.0424, reg_loss: 0.0000 ||:  81%|████████  | 145/180 [05:35<01:13,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.7184, loss: 0.0424, reg_loss: 0.0000 ||:  81%|████████  | 146/180 [05:37<01:10,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.7180, loss: 0.0424, reg_loss: 0.0000 ||:  82%|████████▏ | 147/180 [05:39<01:15,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.7161, loss: 0.0426, reg_loss: 0.0000 ||:  82%|████████▏ | 148/180 [05:43<01:25,  2.67s/it]\u001b[A\n",
            "pearson(r): 0.7160, loss: 0.0425, reg_loss: 0.0000 ||:  83%|████████▎ | 149/180 [05:45<01:16,  2.47s/it]\u001b[A\n",
            "pearson(r): 0.7159, loss: 0.0425, reg_loss: 0.0000 ||:  83%|████████▎ | 150/180 [05:47<01:10,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.7151, loss: 0.0426, reg_loss: 0.0000 ||:  84%|████████▍ | 151/180 [05:49<01:06,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.7137, loss: 0.0428, reg_loss: 0.0000 ||:  84%|████████▍ | 152/180 [05:51<01:02,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.7136, loss: 0.0428, reg_loss: 0.0000 ||:  85%|████████▌ | 153/180 [05:53<00:57,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.7142, loss: 0.0427, reg_loss: 0.0000 ||:  86%|████████▌ | 154/180 [05:55<00:54,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.7147, loss: 0.0427, reg_loss: 0.0000 ||:  86%|████████▌ | 155/180 [05:57<00:49,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.7142, loss: 0.0428, reg_loss: 0.0000 ||:  87%|████████▋ | 156/180 [05:59<00:46,  1.93s/it]\u001b[A\n",
            "pearson(r): 0.7148, loss: 0.0426, reg_loss: 0.0000 ||:  87%|████████▋ | 157/180 [06:01<00:45,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.7152, loss: 0.0426, reg_loss: 0.0000 ||:  88%|████████▊ | 158/180 [06:03<00:43,  1.98s/it]\u001b[A\n",
            "pearson(r): 0.7150, loss: 0.0426, reg_loss: 0.0000 ||:  88%|████████▊ | 159/180 [06:07<00:56,  2.70s/it]\u001b[A\n",
            "pearson(r): 0.7139, loss: 0.0426, reg_loss: 0.0000 ||:  89%|████████▉ | 160/180 [06:09<00:49,  2.49s/it]\u001b[A\n",
            "pearson(r): 0.7146, loss: 0.0426, reg_loss: 0.0000 ||:  89%|████████▉ | 161/180 [06:11<00:46,  2.44s/it]\u001b[A\n",
            "pearson(r): 0.7144, loss: 0.0426, reg_loss: 0.0000 ||:  90%|█████████ | 162/180 [06:13<00:41,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.7142, loss: 0.0427, reg_loss: 0.0000 ||:  91%|█████████ | 163/180 [06:18<00:48,  2.87s/it]\u001b[A\n",
            "pearson(r): 0.7143, loss: 0.0427, reg_loss: 0.0000 ||:  91%|█████████ | 164/180 [06:20<00:41,  2.61s/it]\u001b[A\n",
            "pearson(r): 0.7136, loss: 0.0428, reg_loss: 0.0000 ||:  92%|█████████▏| 165/180 [06:22<00:36,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.7145, loss: 0.0428, reg_loss: 0.0000 ||:  92%|█████████▏| 166/180 [06:24<00:32,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.7143, loss: 0.0428, reg_loss: 0.0000 ||:  93%|█████████▎| 167/180 [06:26<00:31,  2.45s/it]\u001b[A\n",
            "pearson(r): 0.7144, loss: 0.0428, reg_loss: 0.0000 ||:  93%|█████████▎| 168/180 [06:28<00:27,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.7139, loss: 0.0428, reg_loss: 0.0000 ||:  94%|█████████▍| 169/180 [06:31<00:25,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.7136, loss: 0.0428, reg_loss: 0.0000 ||:  94%|█████████▍| 170/180 [06:32<00:20,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.7125, loss: 0.0430, reg_loss: 0.0000 ||:  95%|█████████▌| 171/180 [06:34<00:18,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.7129, loss: 0.0430, reg_loss: 0.0000 ||:  96%|█████████▌| 172/180 [06:37<00:18,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.7132, loss: 0.0429, reg_loss: 0.0000 ||:  96%|█████████▌| 173/180 [06:40<00:16,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.7141, loss: 0.0429, reg_loss: 0.0000 ||:  97%|█████████▋| 174/180 [06:41<00:13,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.7145, loss: 0.0428, reg_loss: 0.0000 ||:  97%|█████████▋| 175/180 [06:43<00:10,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.7141, loss: 0.0428, reg_loss: 0.0000 ||:  98%|█████████▊| 176/180 [06:45<00:08,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.7136, loss: 0.0429, reg_loss: 0.0000 ||:  98%|█████████▊| 177/180 [06:49<00:07,  2.50s/it]\u001b[A\n",
            "pearson(r): 0.7146, loss: 0.0429, reg_loss: 0.0000 ||:  99%|█████████▉| 178/180 [06:51<00:04,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.7141, loss: 0.0429, reg_loss: 0.0000 ||:  99%|█████████▉| 179/180 [06:52<00:02,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.7139, loss: 0.0429, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [06:54<00:00,  2.30s/it]\n",
            "\n",
            "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.6052, loss: 0.0957, reg_loss: 0.0000 ||:   2%|▏         | 1/47 [00:00<00:12,  3.71it/s]\u001b[A\n",
            "pearson(r): 0.7019, loss: 0.0892, reg_loss: 0.0000 ||:   4%|▍         | 2/47 [00:00<00:12,  3.62it/s]\u001b[A\n",
            "pearson(r): 0.7364, loss: 0.0814, reg_loss: 0.0000 ||:   6%|▋         | 3/47 [00:00<00:12,  3.42it/s]\u001b[A\n",
            "pearson(r): 0.7323, loss: 0.1031, reg_loss: 0.0000 ||:   9%|▊         | 4/47 [00:01<00:12,  3.34it/s]\u001b[A\n",
            "pearson(r): 0.7349, loss: 0.0980, reg_loss: 0.0000 ||:  11%|█         | 5/47 [00:01<00:12,  3.48it/s]\u001b[A\n",
            "pearson(r): 0.7349, loss: 0.0941, reg_loss: 0.0000 ||:  13%|█▎        | 6/47 [00:01<00:12,  3.40it/s]\u001b[A\n",
            "pearson(r): 0.7251, loss: 0.1027, reg_loss: 0.0000 ||:  15%|█▍        | 7/47 [00:02<00:11,  3.35it/s]\u001b[A\n",
            "pearson(r): 0.7194, loss: 0.1087, reg_loss: 0.0000 ||:  17%|█▋        | 8/47 [00:02<00:12,  3.15it/s]\u001b[A\n",
            "pearson(r): 0.7111, loss: 0.1096, reg_loss: 0.0000 ||:  19%|█▉        | 9/47 [00:02<00:12,  2.96it/s]\u001b[A\n",
            "pearson(r): 0.7024, loss: 0.1111, reg_loss: 0.0000 ||:  21%|██▏       | 10/47 [00:03<00:12,  2.86it/s]\u001b[A\n",
            "pearson(r): 0.7020, loss: 0.1090, reg_loss: 0.0000 ||:  23%|██▎       | 11/47 [00:03<00:13,  2.68it/s]\u001b[A\n",
            "pearson(r): 0.7043, loss: 0.1088, reg_loss: 0.0000 ||:  26%|██▌       | 12/47 [00:04<00:13,  2.61it/s]\u001b[A\n",
            "pearson(r): 0.6925, loss: 0.1129, reg_loss: 0.0000 ||:  28%|██▊       | 13/47 [00:04<00:13,  2.53it/s]\u001b[A\n",
            "pearson(r): 0.6913, loss: 0.1136, reg_loss: 0.0000 ||:  30%|██▉       | 14/47 [00:04<00:13,  2.53it/s]\u001b[A\n",
            "pearson(r): 0.6769, loss: 0.1205, reg_loss: 0.0000 ||:  32%|███▏      | 15/47 [00:05<00:12,  2.49it/s]\u001b[A\n",
            "pearson(r): 0.6669, loss: 0.1244, reg_loss: 0.0000 ||:  34%|███▍      | 16/47 [00:05<00:12,  2.44it/s]\u001b[A\n",
            "pearson(r): 0.6697, loss: 0.1229, reg_loss: 0.0000 ||:  36%|███▌      | 17/47 [00:06<00:12,  2.39it/s]\u001b[A\n",
            "pearson(r): 0.6646, loss: 0.1258, reg_loss: 0.0000 ||:  38%|███▊      | 18/47 [00:06<00:12,  2.38it/s]\u001b[A\n",
            "pearson(r): 0.6669, loss: 0.1262, reg_loss: 0.0000 ||:  40%|████      | 19/47 [00:06<00:11,  2.38it/s]\u001b[A\n",
            "pearson(r): 0.6550, loss: 0.1302, reg_loss: 0.0000 ||:  43%|████▎     | 20/47 [00:07<00:12,  2.19it/s]\u001b[A\n",
            "pearson(r): 0.6430, loss: 0.1349, reg_loss: 0.0000 ||:  45%|████▍     | 21/47 [00:08<00:12,  2.04it/s]\u001b[A\n",
            "pearson(r): 0.6294, loss: 0.1387, reg_loss: 0.0000 ||:  47%|████▋     | 22/47 [00:08<00:12,  1.95it/s]\u001b[A\n",
            "pearson(r): 0.6236, loss: 0.1403, reg_loss: 0.0000 ||:  49%|████▉     | 23/47 [00:09<00:12,  1.87it/s]\u001b[A\n",
            "pearson(r): 0.6094, loss: 0.1446, reg_loss: 0.0000 ||:  51%|█████     | 24/47 [00:09<00:12,  1.79it/s]\u001b[A\n",
            "pearson(r): 0.5917, loss: 0.1497, reg_loss: 0.0000 ||:  53%|█████▎    | 25/47 [00:10<00:12,  1.76it/s]\u001b[A\n",
            "pearson(r): 0.5848, loss: 0.1510, reg_loss: 0.0000 ||:  55%|█████▌    | 26/47 [00:10<00:11,  1.80it/s]\u001b[A\n",
            "pearson(r): 0.5722, loss: 0.1545, reg_loss: 0.0000 ||:  57%|█████▋    | 27/47 [00:11<00:11,  1.80it/s]\u001b[A\n",
            "pearson(r): 0.5635, loss: 0.1562, reg_loss: 0.0000 ||:  60%|█████▉    | 28/47 [00:12<00:10,  1.76it/s]\u001b[A\n",
            "pearson(r): 0.5514, loss: 0.1617, reg_loss: 0.0000 ||:  62%|██████▏   | 29/47 [00:12<00:10,  1.79it/s]\u001b[A\n",
            "pearson(r): 0.5419, loss: 0.1650, reg_loss: 0.0000 ||:  64%|██████▍   | 30/47 [00:13<00:09,  1.80it/s]\u001b[A\n",
            "pearson(r): 0.5360, loss: 0.1671, reg_loss: 0.0000 ||:  66%|██████▌   | 31/47 [00:13<00:08,  1.82it/s]\u001b[A\n",
            "pearson(r): 0.5396, loss: 0.1656, reg_loss: 0.0000 ||:  68%|██████▊   | 32/47 [00:14<00:08,  1.71it/s]\u001b[A\n",
            "pearson(r): 0.5476, loss: 0.1624, reg_loss: 0.0000 ||:  70%|███████   | 33/47 [00:15<00:08,  1.67it/s]\u001b[A\n",
            "pearson(r): 0.5538, loss: 0.1591, reg_loss: 0.0000 ||:  72%|███████▏  | 34/47 [00:15<00:08,  1.60it/s]\u001b[A\n",
            "pearson(r): 0.5591, loss: 0.1566, reg_loss: 0.0000 ||:  74%|███████▍  | 35/47 [00:16<00:08,  1.48it/s]\u001b[A\n",
            "pearson(r): 0.5605, loss: 0.1545, reg_loss: 0.0000 ||:  77%|███████▋  | 36/47 [00:17<00:07,  1.47it/s]\u001b[A\n",
            "pearson(r): 0.5635, loss: 0.1527, reg_loss: 0.0000 ||:  79%|███████▊  | 37/47 [00:17<00:06,  1.49it/s]\u001b[A\n",
            "pearson(r): 0.5667, loss: 0.1504, reg_loss: 0.0000 ||:  81%|████████  | 38/47 [00:18<00:06,  1.49it/s]\u001b[A\n",
            "pearson(r): 0.5713, loss: 0.1481, reg_loss: 0.0000 ||:  83%|████████▎ | 39/47 [00:19<00:05,  1.45it/s]\u001b[A\n",
            "pearson(r): 0.5693, loss: 0.1479, reg_loss: 0.0000 ||:  85%|████████▌ | 40/47 [00:19<00:04,  1.65it/s]\u001b[A\n",
            "pearson(r): 0.5691, loss: 0.1465, reg_loss: 0.0000 ||:  87%|████████▋ | 41/47 [00:20<00:03,  1.89it/s]\u001b[A\n",
            "pearson(r): 0.5717, loss: 0.1459, reg_loss: 0.0000 ||:  89%|████████▉ | 42/47 [00:20<00:02,  2.18it/s]\u001b[A\n",
            "pearson(r): 0.5723, loss: 0.1463, reg_loss: 0.0000 ||:  91%|█████████▏| 43/47 [00:20<00:01,  2.36it/s]\u001b[A\n",
            "pearson(r): 0.5723, loss: 0.1456, reg_loss: 0.0000 ||:  94%|█████████▎| 44/47 [00:21<00:01,  2.51it/s]\u001b[A\n",
            "pearson(r): 0.5660, loss: 0.1468, reg_loss: 0.0000 ||:  96%|█████████▌| 45/47 [00:21<00:00,  2.69it/s]\u001b[A\n",
            "pearson(r): 0.5706, loss: 0.1473, reg_loss: 0.0000 ||:  98%|█████████▊| 46/47 [00:21<00:00,  2.72it/s]\u001b[A\n",
            "pearson(r): 0.5645, loss: 0.1480, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:22<00:00,  2.14it/s]\n",
            "\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.8414, loss: 0.0306, reg_loss: 0.0000 ||:   1%|          | 1/180 [00:02<06:16,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.8105, loss: 0.0395, reg_loss: 0.0000 ||:   1%|          | 2/180 [00:04<06:14,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.8308, loss: 0.0351, reg_loss: 0.0000 ||:   2%|▏         | 3/180 [00:06<06:08,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.8286, loss: 0.0345, reg_loss: 0.0000 ||:   2%|▏         | 4/180 [00:08<06:12,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.8206, loss: 0.0339, reg_loss: 0.0000 ||:   3%|▎         | 5/180 [00:10<06:16,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.8235, loss: 0.0325, reg_loss: 0.0000 ||:   3%|▎         | 6/180 [00:13<06:47,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.8172, loss: 0.0327, reg_loss: 0.0000 ||:   4%|▍         | 7/180 [00:15<06:34,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.8219, loss: 0.0316, reg_loss: 0.0000 ||:   4%|▍         | 8/180 [00:17<06:06,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.8136, loss: 0.0329, reg_loss: 0.0000 ||:   5%|▌         | 9/180 [00:19<05:42,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.8106, loss: 0.0350, reg_loss: 0.0000 ||:   6%|▌         | 10/180 [00:21<05:48,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.8049, loss: 0.0351, reg_loss: 0.0000 ||:   6%|▌         | 11/180 [00:23<05:46,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.8030, loss: 0.0349, reg_loss: 0.0000 ||:   7%|▋         | 12/180 [00:25<05:45,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.8076, loss: 0.0338, reg_loss: 0.0000 ||:   7%|▋         | 13/180 [00:28<06:27,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.8037, loss: 0.0345, reg_loss: 0.0000 ||:   8%|▊         | 14/180 [00:30<06:17,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.7990, loss: 0.0351, reg_loss: 0.0000 ||:   8%|▊         | 15/180 [00:32<05:47,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.7999, loss: 0.0346, reg_loss: 0.0000 ||:   9%|▉         | 16/180 [00:34<05:35,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.7964, loss: 0.0343, reg_loss: 0.0000 ||:   9%|▉         | 17/180 [00:36<05:39,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.7952, loss: 0.0341, reg_loss: 0.0000 ||:  10%|█         | 18/180 [00:38<05:28,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.7993, loss: 0.0335, reg_loss: 0.0000 ||:  11%|█         | 19/180 [00:40<05:53,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.8015, loss: 0.0337, reg_loss: 0.0000 ||:  11%|█         | 20/180 [00:42<05:29,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.8054, loss: 0.0335, reg_loss: 0.0000 ||:  12%|█▏        | 21/180 [00:45<05:53,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.8045, loss: 0.0341, reg_loss: 0.0000 ||:  12%|█▏        | 22/180 [00:47<06:11,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.8033, loss: 0.0339, reg_loss: 0.0000 ||:  13%|█▎        | 23/180 [00:50<06:09,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.8034, loss: 0.0337, reg_loss: 0.0000 ||:  13%|█▎        | 24/180 [00:51<05:45,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.8043, loss: 0.0338, reg_loss: 0.0000 ||:  14%|█▍        | 25/180 [00:54<05:56,  2.30s/it]\u001b[A\n",
            "pearson(r): 0.8015, loss: 0.0339, reg_loss: 0.0000 ||:  14%|█▍        | 26/180 [00:58<06:57,  2.71s/it]\u001b[A\n",
            "pearson(r): 0.7954, loss: 0.0345, reg_loss: 0.0000 ||:  15%|█▌        | 27/180 [00:59<06:03,  2.38s/it]\u001b[A\n",
            "pearson(r): 0.7941, loss: 0.0346, reg_loss: 0.0000 ||:  16%|█▌        | 28/180 [01:01<05:51,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.7937, loss: 0.0344, reg_loss: 0.0000 ||:  16%|█▌        | 29/180 [01:03<05:38,  2.24s/it]\u001b[A\n",
            "pearson(r): 0.7946, loss: 0.0339, reg_loss: 0.0000 ||:  17%|█▋        | 30/180 [01:06<05:29,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.7938, loss: 0.0338, reg_loss: 0.0000 ||:  17%|█▋        | 31/180 [01:09<06:43,  2.71s/it]\u001b[A\n",
            "pearson(r): 0.7896, loss: 0.0342, reg_loss: 0.0000 ||:  18%|█▊        | 32/180 [01:11<06:08,  2.49s/it]\u001b[A\n",
            "pearson(r): 0.7878, loss: 0.0345, reg_loss: 0.0000 ||:  18%|█▊        | 33/180 [01:14<05:48,  2.37s/it]\u001b[A\n",
            "pearson(r): 0.7833, loss: 0.0351, reg_loss: 0.0000 ||:  19%|█▉        | 34/180 [01:17<06:48,  2.80s/it]\u001b[A\n",
            "pearson(r): 0.7816, loss: 0.0355, reg_loss: 0.0000 ||:  19%|█▉        | 35/180 [01:20<06:19,  2.61s/it]\u001b[A\n",
            "pearson(r): 0.7821, loss: 0.0354, reg_loss: 0.0000 ||:  20%|██        | 36/180 [01:21<05:46,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.7826, loss: 0.0356, reg_loss: 0.0000 ||:  21%|██        | 37/180 [01:23<05:25,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.7847, loss: 0.0353, reg_loss: 0.0000 ||:  21%|██        | 38/180 [01:25<04:56,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.7817, loss: 0.0358, reg_loss: 0.0000 ||:  22%|██▏       | 39/180 [01:27<04:49,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.7814, loss: 0.0357, reg_loss: 0.0000 ||:  22%|██▏       | 40/180 [01:29<05:02,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.7811, loss: 0.0360, reg_loss: 0.0000 ||:  23%|██▎       | 41/180 [01:32<04:56,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.7805, loss: 0.0362, reg_loss: 0.0000 ||:  23%|██▎       | 42/180 [01:34<05:25,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.7811, loss: 0.0363, reg_loss: 0.0000 ||:  24%|██▍       | 43/180 [01:36<05:02,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.7811, loss: 0.0363, reg_loss: 0.0000 ||:  24%|██▍       | 44/180 [01:38<04:49,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.7809, loss: 0.0362, reg_loss: 0.0000 ||:  25%|██▌       | 45/180 [01:40<04:44,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.7802, loss: 0.0359, reg_loss: 0.0000 ||:  26%|██▌       | 46/180 [01:42<04:28,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.7778, loss: 0.0363, reg_loss: 0.0000 ||:  26%|██▌       | 47/180 [01:44<04:33,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.7775, loss: 0.0362, reg_loss: 0.0000 ||:  27%|██▋       | 48/180 [01:46<04:32,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.7761, loss: 0.0360, reg_loss: 0.0000 ||:  27%|██▋       | 49/180 [01:48<04:27,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.7756, loss: 0.0360, reg_loss: 0.0000 ||:  28%|██▊       | 50/180 [01:50<04:20,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.7723, loss: 0.0364, reg_loss: 0.0000 ||:  28%|██▊       | 51/180 [01:52<04:12,  1.96s/it]\u001b[A\n",
            "pearson(r): 0.7690, loss: 0.0369, reg_loss: 0.0000 ||:  29%|██▉       | 52/180 [01:54<04:08,  1.94s/it]\u001b[A\n",
            "pearson(r): 0.7678, loss: 0.0368, reg_loss: 0.0000 ||:  29%|██▉       | 53/180 [01:56<04:21,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.7663, loss: 0.0369, reg_loss: 0.0000 ||:  30%|███       | 54/180 [01:58<04:06,  1.95s/it]\u001b[A\n",
            "pearson(r): 0.7661, loss: 0.0371, reg_loss: 0.0000 ||:  31%|███       | 55/180 [02:02<05:32,  2.66s/it]\u001b[A\n",
            "pearson(r): 0.7675, loss: 0.0370, reg_loss: 0.0000 ||:  31%|███       | 56/180 [02:04<05:03,  2.45s/it]\u001b[A\n",
            "pearson(r): 0.7660, loss: 0.0371, reg_loss: 0.0000 ||:  32%|███▏      | 57/180 [02:07<04:56,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.7664, loss: 0.0369, reg_loss: 0.0000 ||:  32%|███▏      | 58/180 [02:08<04:31,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.7663, loss: 0.0371, reg_loss: 0.0000 ||:  33%|███▎      | 59/180 [02:10<04:25,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.7664, loss: 0.0370, reg_loss: 0.0000 ||:  33%|███▎      | 60/180 [02:12<04:01,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.7658, loss: 0.0369, reg_loss: 0.0000 ||:  34%|███▍      | 61/180 [02:15<04:38,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.7671, loss: 0.0368, reg_loss: 0.0000 ||:  34%|███▍      | 62/180 [02:17<04:18,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.7664, loss: 0.0369, reg_loss: 0.0000 ||:  35%|███▌      | 63/180 [02:20<04:27,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.7662, loss: 0.0369, reg_loss: 0.0000 ||:  36%|███▌      | 64/180 [02:21<04:06,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.7655, loss: 0.0368, reg_loss: 0.0000 ||:  36%|███▌      | 65/180 [02:24<04:23,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.7656, loss: 0.0368, reg_loss: 0.0000 ||:  37%|███▋      | 66/180 [02:26<04:22,  2.30s/it]\u001b[A\n",
            "pearson(r): 0.7674, loss: 0.0366, reg_loss: 0.0000 ||:  37%|███▋      | 67/180 [02:28<04:09,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.7667, loss: 0.0367, reg_loss: 0.0000 ||:  38%|███▊      | 68/180 [02:30<03:44,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.7665, loss: 0.0365, reg_loss: 0.0000 ||:  38%|███▊      | 69/180 [02:32<03:51,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.7663, loss: 0.0366, reg_loss: 0.0000 ||:  39%|███▉      | 70/180 [02:35<04:04,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.7666, loss: 0.0366, reg_loss: 0.0000 ||:  39%|███▉      | 71/180 [02:36<03:50,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.7677, loss: 0.0365, reg_loss: 0.0000 ||:  40%|████      | 72/180 [02:38<03:43,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.7680, loss: 0.0364, reg_loss: 0.0000 ||:  41%|████      | 73/180 [02:41<03:48,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.7674, loss: 0.0363, reg_loss: 0.0000 ||:  41%|████      | 74/180 [02:44<04:12,  2.38s/it]\u001b[A\n",
            "pearson(r): 0.7668, loss: 0.0364, reg_loss: 0.0000 ||:  42%|████▏     | 75/180 [02:46<04:02,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.7661, loss: 0.0363, reg_loss: 0.0000 ||:  42%|████▏     | 76/180 [02:48<03:45,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.7670, loss: 0.0364, reg_loss: 0.0000 ||:  43%|████▎     | 77/180 [02:49<03:28,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.7671, loss: 0.0362, reg_loss: 0.0000 ||:  43%|████▎     | 78/180 [02:51<03:25,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.7667, loss: 0.0361, reg_loss: 0.0000 ||:  44%|████▍     | 79/180 [02:53<03:19,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.7673, loss: 0.0362, reg_loss: 0.0000 ||:  44%|████▍     | 80/180 [02:55<03:16,  1.96s/it]\u001b[A\n",
            "pearson(r): 0.7676, loss: 0.0362, reg_loss: 0.0000 ||:  45%|████▌     | 81/180 [02:57<03:12,  1.94s/it]\u001b[A\n",
            "pearson(r): 0.7670, loss: 0.0363, reg_loss: 0.0000 ||:  46%|████▌     | 82/180 [02:59<03:24,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.7646, loss: 0.0367, reg_loss: 0.0000 ||:  46%|████▌     | 83/180 [03:06<05:33,  3.44s/it]\u001b[A\n",
            "pearson(r): 0.7652, loss: 0.0365, reg_loss: 0.0000 ||:  47%|████▋     | 84/180 [03:08<04:52,  3.04s/it]\u001b[A\n",
            "pearson(r): 0.7655, loss: 0.0365, reg_loss: 0.0000 ||:  47%|████▋     | 85/180 [03:10<04:20,  2.74s/it]\u001b[A\n",
            "pearson(r): 0.7657, loss: 0.0365, reg_loss: 0.0000 ||:  48%|████▊     | 86/180 [03:12<04:02,  2.58s/it]\u001b[A\n",
            "pearson(r): 0.7659, loss: 0.0366, reg_loss: 0.0000 ||:  48%|████▊     | 87/180 [03:14<03:46,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.7674, loss: 0.0365, reg_loss: 0.0000 ||:  49%|████▉     | 88/180 [03:17<03:49,  2.49s/it]\u001b[A\n",
            "pearson(r): 0.7680, loss: 0.0365, reg_loss: 0.0000 ||:  49%|████▉     | 89/180 [03:19<03:32,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.7674, loss: 0.0365, reg_loss: 0.0000 ||:  50%|█████     | 90/180 [03:21<03:17,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.7676, loss: 0.0365, reg_loss: 0.0000 ||:  51%|█████     | 91/180 [03:24<03:32,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.7670, loss: 0.0364, reg_loss: 0.0000 ||:  51%|█████     | 92/180 [03:26<03:26,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.7680, loss: 0.0364, reg_loss: 0.0000 ||:  52%|█████▏    | 93/180 [03:28<03:10,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.7688, loss: 0.0363, reg_loss: 0.0000 ||:  52%|█████▏    | 94/180 [03:31<03:20,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.7694, loss: 0.0362, reg_loss: 0.0000 ||:  53%|█████▎    | 95/180 [03:33<03:12,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.7691, loss: 0.0363, reg_loss: 0.0000 ||:  53%|█████▎    | 96/180 [03:35<03:07,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.7697, loss: 0.0362, reg_loss: 0.0000 ||:  54%|█████▍    | 97/180 [03:37<03:14,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.7700, loss: 0.0362, reg_loss: 0.0000 ||:  54%|█████▍    | 98/180 [03:39<02:49,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.7695, loss: 0.0361, reg_loss: 0.0000 ||:  55%|█████▌    | 99/180 [03:41<02:59,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.7680, loss: 0.0364, reg_loss: 0.0000 ||:  56%|█████▌    | 100/180 [03:45<03:20,  2.51s/it]\u001b[A\n",
            "pearson(r): 0.7685, loss: 0.0363, reg_loss: 0.0000 ||:  56%|█████▌    | 101/180 [03:47<03:14,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.7684, loss: 0.0364, reg_loss: 0.0000 ||:  57%|█████▋    | 102/180 [03:49<02:55,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.7674, loss: 0.0364, reg_loss: 0.0000 ||:  57%|█████▋    | 103/180 [03:51<02:50,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.7666, loss: 0.0365, reg_loss: 0.0000 ||:  58%|█████▊    | 104/180 [03:54<02:59,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.7661, loss: 0.0364, reg_loss: 0.0000 ||:  58%|█████▊    | 105/180 [03:56<02:50,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.7670, loss: 0.0364, reg_loss: 0.0000 ||:  59%|█████▉    | 106/180 [03:58<02:41,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.7672, loss: 0.0363, reg_loss: 0.0000 ||:  59%|█████▉    | 107/180 [04:00<02:36,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.7668, loss: 0.0363, reg_loss: 0.0000 ||:  60%|██████    | 108/180 [04:03<02:52,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.7671, loss: 0.0363, reg_loss: 0.0000 ||:  61%|██████    | 109/180 [04:05<02:41,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.7670, loss: 0.0363, reg_loss: 0.0000 ||:  61%|██████    | 110/180 [04:07<02:37,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.7664, loss: 0.0363, reg_loss: 0.0000 ||:  62%|██████▏   | 111/180 [04:09<02:28,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.7664, loss: 0.0363, reg_loss: 0.0000 ||:  62%|██████▏   | 112/180 [04:11<02:30,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.7665, loss: 0.0364, reg_loss: 0.0000 ||:  63%|██████▎   | 113/180 [04:13<02:28,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.7675, loss: 0.0363, reg_loss: 0.0000 ||:  63%|██████▎   | 114/180 [04:16<02:27,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.7682, loss: 0.0362, reg_loss: 0.0000 ||:  64%|██████▍   | 115/180 [04:18<02:23,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.7682, loss: 0.0362, reg_loss: 0.0000 ||:  64%|██████▍   | 116/180 [04:20<02:19,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.7693, loss: 0.0361, reg_loss: 0.0000 ||:  65%|██████▌   | 117/180 [04:23<02:29,  2.38s/it]\u001b[A\n",
            "pearson(r): 0.7688, loss: 0.0360, reg_loss: 0.0000 ||:  66%|██████▌   | 118/180 [04:25<02:31,  2.44s/it]\u001b[A\n",
            "pearson(r): 0.7687, loss: 0.0361, reg_loss: 0.0000 ||:  66%|██████▌   | 119/180 [04:28<02:33,  2.51s/it]\u001b[A\n",
            "pearson(r): 0.7688, loss: 0.0362, reg_loss: 0.0000 ||:  67%|██████▋   | 120/180 [04:30<02:20,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.7680, loss: 0.0363, reg_loss: 0.0000 ||:  67%|██████▋   | 121/180 [04:34<02:41,  2.74s/it]\u001b[A\n",
            "pearson(r): 0.7687, loss: 0.0363, reg_loss: 0.0000 ||:  68%|██████▊   | 122/180 [04:36<02:26,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.7684, loss: 0.0363, reg_loss: 0.0000 ||:  68%|██████▊   | 123/180 [04:38<02:16,  2.40s/it]\u001b[A\n",
            "pearson(r): 0.7685, loss: 0.0363, reg_loss: 0.0000 ||:  69%|██████▉   | 124/180 [04:40<02:21,  2.52s/it]\u001b[A\n",
            "pearson(r): 0.7678, loss: 0.0363, reg_loss: 0.0000 ||:  69%|██████▉   | 125/180 [04:42<02:07,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.7674, loss: 0.0363, reg_loss: 0.0000 ||:  70%|███████   | 126/180 [04:44<01:59,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.7659, loss: 0.0365, reg_loss: 0.0000 ||:  71%|███████   | 127/180 [04:49<02:36,  2.96s/it]\u001b[A\n",
            "pearson(r): 0.7663, loss: 0.0365, reg_loss: 0.0000 ||:  71%|███████   | 128/180 [04:51<02:17,  2.65s/it]\u001b[A\n",
            "pearson(r): 0.7664, loss: 0.0364, reg_loss: 0.0000 ||:  72%|███████▏  | 129/180 [04:53<02:05,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.7663, loss: 0.0365, reg_loss: 0.0000 ||:  72%|███████▏  | 130/180 [04:55<01:51,  2.24s/it]\u001b[A\n",
            "pearson(r): 0.7662, loss: 0.0365, reg_loss: 0.0000 ||:  73%|███████▎  | 131/180 [04:58<02:03,  2.52s/it]\u001b[A\n",
            "pearson(r): 0.7663, loss: 0.0365, reg_loss: 0.0000 ||:  73%|███████▎  | 132/180 [05:00<01:57,  2.45s/it]\u001b[A\n",
            "pearson(r): 0.7655, loss: 0.0366, reg_loss: 0.0000 ||:  74%|███████▍  | 133/180 [05:02<01:48,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.7644, loss: 0.0368, reg_loss: 0.0000 ||:  74%|███████▍  | 134/180 [05:04<01:41,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.7642, loss: 0.0368, reg_loss: 0.0000 ||:  75%|███████▌  | 135/180 [05:06<01:35,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.7644, loss: 0.0368, reg_loss: 0.0000 ||:  76%|███████▌  | 136/180 [05:10<01:58,  2.70s/it]\u001b[A\n",
            "pearson(r): 0.7644, loss: 0.0368, reg_loss: 0.0000 ||:  76%|███████▌  | 137/180 [05:12<01:44,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.7646, loss: 0.0369, reg_loss: 0.0000 ||:  77%|███████▋  | 138/180 [05:14<01:35,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.7644, loss: 0.0369, reg_loss: 0.0000 ||:  77%|███████▋  | 139/180 [05:16<01:29,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.7640, loss: 0.0370, reg_loss: 0.0000 ||:  78%|███████▊  | 140/180 [05:17<01:21,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.7633, loss: 0.0370, reg_loss: 0.0000 ||:  78%|███████▊  | 141/180 [05:19<01:20,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.7637, loss: 0.0369, reg_loss: 0.0000 ||:  79%|███████▉  | 142/180 [05:22<01:22,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.7640, loss: 0.0370, reg_loss: 0.0000 ||:  79%|███████▉  | 143/180 [05:24<01:19,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.7637, loss: 0.0370, reg_loss: 0.0000 ||:  80%|████████  | 144/180 [05:26<01:17,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.7634, loss: 0.0371, reg_loss: 0.0000 ||:  81%|████████  | 145/180 [05:28<01:14,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.7631, loss: 0.0372, reg_loss: 0.0000 ||:  81%|████████  | 146/180 [05:30<01:05,  1.92s/it]\u001b[A\n",
            "pearson(r): 0.7625, loss: 0.0372, reg_loss: 0.0000 ||:  82%|████████▏ | 147/180 [05:32<01:03,  1.92s/it]\u001b[A\n",
            "pearson(r): 0.7626, loss: 0.0373, reg_loss: 0.0000 ||:  82%|████████▏ | 148/180 [05:33<00:59,  1.85s/it]\u001b[A\n",
            "pearson(r): 0.7627, loss: 0.0374, reg_loss: 0.0000 ||:  83%|████████▎ | 149/180 [05:36<01:00,  1.96s/it]\u001b[A\n",
            "pearson(r): 0.7619, loss: 0.0375, reg_loss: 0.0000 ||:  83%|████████▎ | 150/180 [05:38<01:06,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.7620, loss: 0.0375, reg_loss: 0.0000 ||:  84%|████████▍ | 151/180 [05:40<00:59,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.7620, loss: 0.0375, reg_loss: 0.0000 ||:  84%|████████▍ | 152/180 [05:47<01:35,  3.43s/it]\u001b[A\n",
            "pearson(r): 0.7619, loss: 0.0375, reg_loss: 0.0000 ||:  85%|████████▌ | 153/180 [05:49<01:20,  2.98s/it]\u001b[A\n",
            "pearson(r): 0.7615, loss: 0.0375, reg_loss: 0.0000 ||:  86%|████████▌ | 154/180 [05:52<01:22,  3.19s/it]\u001b[A\n",
            "pearson(r): 0.7622, loss: 0.0375, reg_loss: 0.0000 ||:  86%|████████▌ | 155/180 [05:55<01:13,  2.92s/it]\u001b[A\n",
            "pearson(r): 0.7627, loss: 0.0375, reg_loss: 0.0000 ||:  87%|████████▋ | 156/180 [05:57<01:03,  2.67s/it]\u001b[A\n",
            "pearson(r): 0.7629, loss: 0.0374, reg_loss: 0.0000 ||:  87%|████████▋ | 157/180 [05:59<01:00,  2.62s/it]\u001b[A\n",
            "pearson(r): 0.7624, loss: 0.0374, reg_loss: 0.0000 ||:  88%|████████▊ | 158/180 [06:01<00:52,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.7606, loss: 0.0376, reg_loss: 0.0000 ||:  88%|████████▊ | 159/180 [06:08<01:16,  3.65s/it]\u001b[A\n",
            "pearson(r): 0.7602, loss: 0.0377, reg_loss: 0.0000 ||:  89%|████████▉ | 160/180 [06:10<01:04,  3.23s/it]\u001b[A\n",
            "pearson(r): 0.7596, loss: 0.0378, reg_loss: 0.0000 ||:  89%|████████▉ | 161/180 [06:12<00:53,  2.83s/it]\u001b[A\n",
            "pearson(r): 0.7596, loss: 0.0378, reg_loss: 0.0000 ||:  90%|█████████ | 162/180 [06:18<01:11,  3.97s/it]\u001b[A\n",
            "pearson(r): 0.7593, loss: 0.0378, reg_loss: 0.0000 ||:  91%|█████████ | 163/180 [06:20<00:57,  3.36s/it]\u001b[A\n",
            "pearson(r): 0.7593, loss: 0.0378, reg_loss: 0.0000 ||:  91%|█████████ | 164/180 [06:22<00:45,  2.85s/it]\u001b[A\n",
            "pearson(r): 0.7586, loss: 0.0378, reg_loss: 0.0000 ||:  92%|█████████▏| 165/180 [06:24<00:40,  2.67s/it]\u001b[A\n",
            "pearson(r): 0.7589, loss: 0.0378, reg_loss: 0.0000 ||:  92%|█████████▏| 166/180 [06:28<00:40,  2.90s/it]\u001b[A\n",
            "pearson(r): 0.7582, loss: 0.0378, reg_loss: 0.0000 ||:  93%|█████████▎| 167/180 [06:30<00:34,  2.67s/it]\u001b[A\n",
            "pearson(r): 0.7578, loss: 0.0378, reg_loss: 0.0000 ||:  93%|█████████▎| 168/180 [06:32<00:29,  2.45s/it]\u001b[A\n",
            "pearson(r): 0.7577, loss: 0.0378, reg_loss: 0.0000 ||:  94%|█████████▍| 169/180 [06:34<00:25,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.7579, loss: 0.0378, reg_loss: 0.0000 ||:  94%|█████████▍| 170/180 [06:36<00:22,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.7580, loss: 0.0378, reg_loss: 0.0000 ||:  95%|█████████▌| 171/180 [06:39<00:22,  2.50s/it]\u001b[A\n",
            "pearson(r): 0.7578, loss: 0.0378, reg_loss: 0.0000 ||:  96%|█████████▌| 172/180 [06:41<00:20,  2.55s/it]\u001b[A\n",
            "pearson(r): 0.7582, loss: 0.0378, reg_loss: 0.0000 ||:  96%|█████████▌| 173/180 [06:43<00:16,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.7578, loss: 0.0378, reg_loss: 0.0000 ||:  97%|█████████▋| 174/180 [06:45<00:12,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.7577, loss: 0.0378, reg_loss: 0.0000 ||:  97%|█████████▋| 175/180 [06:47<00:10,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.7579, loss: 0.0377, reg_loss: 0.0000 ||:  98%|█████████▊| 176/180 [06:49<00:08,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.7571, loss: 0.0378, reg_loss: 0.0000 ||:  98%|█████████▊| 177/180 [06:51<00:06,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.7575, loss: 0.0377, reg_loss: 0.0000 ||:  99%|█████████▉| 178/180 [06:54<00:04,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.7564, loss: 0.0379, reg_loss: 0.0000 ||:  99%|█████████▉| 179/180 [06:58<00:02,  2.74s/it]\u001b[A\n",
            "pearson(r): 0.7560, loss: 0.0379, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [07:00<00:00,  2.33s/it]\n",
            "\n",
            "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.7400, loss: 0.0774, reg_loss: 0.0000 ||:   2%|▏         | 1/47 [00:00<00:12,  3.54it/s]\u001b[A\n",
            "pearson(r): 0.7657, loss: 0.0788, reg_loss: 0.0000 ||:   4%|▍         | 2/47 [00:00<00:12,  3.48it/s]\u001b[A\n",
            "pearson(r): 0.7691, loss: 0.0739, reg_loss: 0.0000 ||:   6%|▋         | 3/47 [00:00<00:13,  3.31it/s]\u001b[A\n",
            "pearson(r): 0.7584, loss: 0.0897, reg_loss: 0.0000 ||:   9%|▊         | 4/47 [00:01<00:13,  3.28it/s]\u001b[A\n",
            "pearson(r): 0.7586, loss: 0.0854, reg_loss: 0.0000 ||:  11%|█         | 5/47 [00:01<00:12,  3.41it/s]\u001b[A\n",
            "pearson(r): 0.7462, loss: 0.0862, reg_loss: 0.0000 ||:  13%|█▎        | 6/47 [00:01<00:12,  3.30it/s]\u001b[A\n",
            "pearson(r): 0.7406, loss: 0.0917, reg_loss: 0.0000 ||:  15%|█▍        | 7/47 [00:02<00:12,  3.26it/s]\u001b[A\n",
            "pearson(r): 0.7388, loss: 0.0968, reg_loss: 0.0000 ||:  17%|█▋        | 8/47 [00:02<00:12,  3.07it/s]\u001b[A\n",
            "pearson(r): 0.7303, loss: 0.0991, reg_loss: 0.0000 ||:  19%|█▉        | 9/47 [00:02<00:13,  2.88it/s]\u001b[A\n",
            "pearson(r): 0.7177, loss: 0.1036, reg_loss: 0.0000 ||:  21%|██▏       | 10/47 [00:03<00:13,  2.77it/s]\u001b[A\n",
            "pearson(r): 0.7181, loss: 0.1017, reg_loss: 0.0000 ||:  23%|██▎       | 11/47 [00:03<00:13,  2.59it/s]\u001b[A\n",
            "pearson(r): 0.7197, loss: 0.1015, reg_loss: 0.0000 ||:  26%|██▌       | 12/47 [00:04<00:13,  2.54it/s]\u001b[A\n",
            "pearson(r): 0.7052, loss: 0.1067, reg_loss: 0.0000 ||:  28%|██▊       | 13/47 [00:04<00:13,  2.49it/s]\u001b[A\n",
            "pearson(r): 0.7038, loss: 0.1075, reg_loss: 0.0000 ||:  30%|██▉       | 14/47 [00:04<00:13,  2.49it/s]\u001b[A\n",
            "pearson(r): 0.6897, loss: 0.1139, reg_loss: 0.0000 ||:  32%|███▏      | 15/47 [00:05<00:13,  2.45it/s]\u001b[A\n",
            "pearson(r): 0.6778, loss: 0.1184, reg_loss: 0.0000 ||:  34%|███▍      | 16/47 [00:05<00:12,  2.39it/s]\u001b[A\n",
            "pearson(r): 0.6816, loss: 0.1165, reg_loss: 0.0000 ||:  36%|███▌      | 17/47 [00:06<00:12,  2.35it/s]\u001b[A\n",
            "pearson(r): 0.6769, loss: 0.1181, reg_loss: 0.0000 ||:  38%|███▊      | 18/47 [00:06<00:12,  2.36it/s]\u001b[A\n",
            "pearson(r): 0.6813, loss: 0.1174, reg_loss: 0.0000 ||:  40%|████      | 19/47 [00:07<00:11,  2.36it/s]\u001b[A\n",
            "pearson(r): 0.6678, loss: 0.1207, reg_loss: 0.0000 ||:  43%|████▎     | 20/47 [00:07<00:12,  2.19it/s]\u001b[A\n",
            "pearson(r): 0.6605, loss: 0.1237, reg_loss: 0.0000 ||:  45%|████▍     | 21/47 [00:08<00:12,  2.04it/s]\u001b[A\n",
            "pearson(r): 0.6437, loss: 0.1284, reg_loss: 0.0000 ||:  47%|████▋     | 22/47 [00:08<00:12,  1.93it/s]\u001b[A\n",
            "pearson(r): 0.6353, loss: 0.1297, reg_loss: 0.0000 ||:  49%|████▉     | 23/47 [00:09<00:12,  1.86it/s]\u001b[A\n",
            "pearson(r): 0.6174, loss: 0.1341, reg_loss: 0.0000 ||:  51%|█████     | 24/47 [00:10<00:12,  1.77it/s]\u001b[A\n",
            "pearson(r): 0.5990, loss: 0.1390, reg_loss: 0.0000 ||:  53%|█████▎    | 25/47 [00:10<00:12,  1.74it/s]\u001b[A\n",
            "pearson(r): 0.5923, loss: 0.1398, reg_loss: 0.0000 ||:  55%|█████▌    | 26/47 [00:11<00:11,  1.78it/s]\u001b[A\n",
            "pearson(r): 0.5791, loss: 0.1429, reg_loss: 0.0000 ||:  57%|█████▋    | 27/47 [00:11<00:11,  1.77it/s]\u001b[A\n",
            "pearson(r): 0.5711, loss: 0.1435, reg_loss: 0.0000 ||:  60%|█████▉    | 28/47 [00:12<00:10,  1.74it/s]\u001b[A\n",
            "pearson(r): 0.5614, loss: 0.1480, reg_loss: 0.0000 ||:  62%|██████▏   | 29/47 [00:12<00:10,  1.77it/s]\u001b[A\n",
            "pearson(r): 0.5546, loss: 0.1503, reg_loss: 0.0000 ||:  64%|██████▍   | 30/47 [00:13<00:09,  1.78it/s]\u001b[A\n",
            "pearson(r): 0.5472, loss: 0.1525, reg_loss: 0.0000 ||:  66%|██████▌   | 31/47 [00:13<00:08,  1.80it/s]\u001b[A\n",
            "pearson(r): 0.5522, loss: 0.1513, reg_loss: 0.0000 ||:  68%|██████▊   | 32/47 [00:14<00:08,  1.69it/s]\u001b[A\n",
            "pearson(r): 0.5619, loss: 0.1484, reg_loss: 0.0000 ||:  70%|███████   | 33/47 [00:15<00:08,  1.65it/s]\u001b[A\n",
            "pearson(r): 0.5686, loss: 0.1454, reg_loss: 0.0000 ||:  72%|███████▏  | 34/47 [00:15<00:08,  1.59it/s]\u001b[A\n",
            "pearson(r): 0.5731, loss: 0.1432, reg_loss: 0.0000 ||:  74%|███████▍  | 35/47 [00:16<00:08,  1.48it/s]\u001b[A\n",
            "pearson(r): 0.5748, loss: 0.1416, reg_loss: 0.0000 ||:  77%|███████▋  | 36/47 [00:17<00:07,  1.47it/s]\u001b[A\n",
            "pearson(r): 0.5767, loss: 0.1401, reg_loss: 0.0000 ||:  79%|███████▊  | 37/47 [00:18<00:06,  1.48it/s]\u001b[A\n",
            "pearson(r): 0.5801, loss: 0.1382, reg_loss: 0.0000 ||:  81%|████████  | 38/47 [00:18<00:06,  1.49it/s]\u001b[A\n",
            "pearson(r): 0.5844, loss: 0.1362, reg_loss: 0.0000 ||:  83%|████████▎ | 39/47 [00:19<00:05,  1.46it/s]\u001b[A\n",
            "pearson(r): 0.5822, loss: 0.1364, reg_loss: 0.0000 ||:  85%|████████▌ | 40/47 [00:19<00:04,  1.65it/s]\u001b[A\n",
            "pearson(r): 0.5798, loss: 0.1352, reg_loss: 0.0000 ||:  87%|████████▋ | 41/47 [00:20<00:03,  1.89it/s]\u001b[A\n",
            "pearson(r): 0.5819, loss: 0.1351, reg_loss: 0.0000 ||:  89%|████████▉ | 42/47 [00:20<00:02,  2.16it/s]\u001b[A\n",
            "pearson(r): 0.5833, loss: 0.1353, reg_loss: 0.0000 ||:  91%|█████████▏| 43/47 [00:20<00:01,  2.33it/s]\u001b[A\n",
            "pearson(r): 0.5813, loss: 0.1356, reg_loss: 0.0000 ||:  94%|█████████▎| 44/47 [00:21<00:01,  2.48it/s]\u001b[A\n",
            "pearson(r): 0.5755, loss: 0.1372, reg_loss: 0.0000 ||:  96%|█████████▌| 45/47 [00:21<00:00,  2.67it/s]\u001b[A\n",
            "pearson(r): 0.5760, loss: 0.1381, reg_loss: 0.0000 ||:  98%|█████████▊| 46/47 [00:21<00:00,  2.70it/s]\u001b[A\n",
            "pearson(r): 0.5702, loss: 0.1390, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:22<00:00,  2.11it/s]\n",
            "\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.7960, loss: 0.0410, reg_loss: 0.0000 ||:   1%|          | 1/180 [00:02<07:20,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.8358, loss: 0.0329, reg_loss: 0.0000 ||:   1%|          | 2/180 [00:04<06:54,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.8281, loss: 0.0319, reg_loss: 0.0000 ||:   2%|▏         | 3/180 [00:07<07:18,  2.48s/it]\u001b[A\n",
            "pearson(r): 0.8207, loss: 0.0311, reg_loss: 0.0000 ||:   2%|▏         | 4/180 [00:10<07:28,  2.55s/it]\u001b[A\n",
            "pearson(r): 0.8353, loss: 0.0303, reg_loss: 0.0000 ||:   3%|▎         | 5/180 [00:12<07:21,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.8279, loss: 0.0313, reg_loss: 0.0000 ||:   3%|▎         | 6/180 [00:14<06:52,  2.37s/it]\u001b[A\n",
            "pearson(r): 0.8227, loss: 0.0311, reg_loss: 0.0000 ||:   4%|▍         | 7/180 [00:16<06:35,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.8079, loss: 0.0327, reg_loss: 0.0000 ||:   4%|▍         | 8/180 [00:18<06:09,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.8018, loss: 0.0336, reg_loss: 0.0000 ||:   5%|▌         | 9/180 [00:21<06:54,  2.42s/it]\u001b[A\n",
            "pearson(r): 0.8002, loss: 0.0339, reg_loss: 0.0000 ||:   6%|▌         | 10/180 [00:23<06:31,  2.30s/it]\u001b[A\n",
            "pearson(r): 0.7922, loss: 0.0345, reg_loss: 0.0000 ||:   6%|▌         | 11/180 [00:25<06:11,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.8025, loss: 0.0346, reg_loss: 0.0000 ||:   7%|▋         | 12/180 [00:27<05:51,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.8072, loss: 0.0339, reg_loss: 0.0000 ||:   7%|▋         | 13/180 [00:29<05:42,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.8055, loss: 0.0336, reg_loss: 0.0000 ||:   8%|▊         | 14/180 [00:31<05:54,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.8068, loss: 0.0335, reg_loss: 0.0000 ||:   8%|▊         | 15/180 [00:33<05:29,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.7997, loss: 0.0340, reg_loss: 0.0000 ||:   9%|▉         | 16/180 [00:35<05:16,  1.93s/it]\u001b[A\n",
            "pearson(r): 0.8014, loss: 0.0329, reg_loss: 0.0000 ||:   9%|▉         | 17/180 [00:37<06:04,  2.24s/it]\u001b[A\n",
            "pearson(r): 0.8025, loss: 0.0325, reg_loss: 0.0000 ||:  10%|█         | 18/180 [00:39<05:45,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.8001, loss: 0.0330, reg_loss: 0.0000 ||:  11%|█         | 19/180 [00:42<06:12,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.8012, loss: 0.0337, reg_loss: 0.0000 ||:  11%|█         | 20/180 [00:46<07:18,  2.74s/it]\u001b[A\n",
            "pearson(r): 0.8059, loss: 0.0335, reg_loss: 0.0000 ||:  12%|█▏        | 21/180 [00:48<06:59,  2.64s/it]\u001b[A\n",
            "pearson(r): 0.8086, loss: 0.0331, reg_loss: 0.0000 ||:  12%|█▏        | 22/180 [00:50<06:29,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.8132, loss: 0.0326, reg_loss: 0.0000 ||:  13%|█▎        | 23/180 [00:53<06:58,  2.67s/it]\u001b[A\n",
            "pearson(r): 0.8148, loss: 0.0325, reg_loss: 0.0000 ||:  13%|█▎        | 24/180 [00:56<06:35,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.8156, loss: 0.0324, reg_loss: 0.0000 ||:  14%|█▍        | 25/180 [00:58<06:17,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.8165, loss: 0.0324, reg_loss: 0.0000 ||:  14%|█▍        | 26/180 [01:01<06:32,  2.55s/it]\u001b[A\n",
            "pearson(r): 0.8165, loss: 0.0324, reg_loss: 0.0000 ||:  15%|█▌        | 27/180 [01:03<06:06,  2.40s/it]\u001b[A\n",
            "pearson(r): 0.8173, loss: 0.0321, reg_loss: 0.0000 ||:  16%|█▌        | 28/180 [01:05<06:18,  2.49s/it]\u001b[A\n",
            "pearson(r): 0.8181, loss: 0.0320, reg_loss: 0.0000 ||:  16%|█▌        | 29/180 [01:08<05:59,  2.38s/it]\u001b[A\n",
            "pearson(r): 0.8195, loss: 0.0318, reg_loss: 0.0000 ||:  17%|█▋        | 30/180 [01:10<05:53,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.8201, loss: 0.0316, reg_loss: 0.0000 ||:  17%|█▋        | 31/180 [01:12<05:28,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.8183, loss: 0.0316, reg_loss: 0.0000 ||:  18%|█▊        | 32/180 [01:14<05:42,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.8177, loss: 0.0315, reg_loss: 0.0000 ||:  18%|█▊        | 33/180 [01:17<05:38,  2.30s/it]\u001b[A\n",
            "pearson(r): 0.8171, loss: 0.0320, reg_loss: 0.0000 ||:  19%|█▉        | 34/180 [01:19<05:19,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.8170, loss: 0.0319, reg_loss: 0.0000 ||:  19%|█▉        | 35/180 [01:21<05:19,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.8167, loss: 0.0318, reg_loss: 0.0000 ||:  20%|██        | 36/180 [01:23<05:12,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.8189, loss: 0.0316, reg_loss: 0.0000 ||:  21%|██        | 37/180 [01:25<05:10,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.8193, loss: 0.0314, reg_loss: 0.0000 ||:  21%|██        | 38/180 [01:27<05:07,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.8182, loss: 0.0315, reg_loss: 0.0000 ||:  22%|██▏       | 39/180 [01:30<05:17,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.8175, loss: 0.0313, reg_loss: 0.0000 ||:  22%|██▏       | 40/180 [01:32<05:07,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.8173, loss: 0.0315, reg_loss: 0.0000 ||:  23%|██▎       | 41/180 [01:33<04:45,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.8178, loss: 0.0314, reg_loss: 0.0000 ||:  23%|██▎       | 42/180 [01:36<04:57,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.8194, loss: 0.0310, reg_loss: 0.0000 ||:  24%|██▍       | 43/180 [01:39<05:21,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.8219, loss: 0.0308, reg_loss: 0.0000 ||:  24%|██▍       | 44/180 [01:40<04:54,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.8212, loss: 0.0306, reg_loss: 0.0000 ||:  25%|██▌       | 45/180 [01:43<04:55,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.8202, loss: 0.0308, reg_loss: 0.0000 ||:  26%|██▌       | 46/180 [01:45<04:49,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.8197, loss: 0.0309, reg_loss: 0.0000 ||:  26%|██▌       | 47/180 [01:49<06:12,  2.80s/it]\u001b[A\n",
            "pearson(r): 0.8203, loss: 0.0306, reg_loss: 0.0000 ||:  27%|██▋       | 48/180 [01:51<05:37,  2.56s/it]\u001b[A\n",
            "pearson(r): 0.8202, loss: 0.0305, reg_loss: 0.0000 ||:  27%|██▋       | 49/180 [01:53<05:12,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.8209, loss: 0.0304, reg_loss: 0.0000 ||:  28%|██▊       | 50/180 [01:55<05:04,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.8216, loss: 0.0303, reg_loss: 0.0000 ||:  28%|██▊       | 51/180 [01:57<04:48,  2.24s/it]\u001b[A\n",
            "pearson(r): 0.8199, loss: 0.0304, reg_loss: 0.0000 ||:  29%|██▉       | 52/180 [02:00<04:52,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.8191, loss: 0.0304, reg_loss: 0.0000 ||:  29%|██▉       | 53/180 [02:01<04:36,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.8174, loss: 0.0308, reg_loss: 0.0000 ||:  30%|███       | 54/180 [02:03<04:24,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.8196, loss: 0.0306, reg_loss: 0.0000 ||:  31%|███       | 55/180 [02:05<04:20,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.8186, loss: 0.0306, reg_loss: 0.0000 ||:  31%|███       | 56/180 [02:08<04:47,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.8178, loss: 0.0306, reg_loss: 0.0000 ||:  32%|███▏      | 57/180 [02:12<05:37,  2.74s/it]\u001b[A\n",
            "pearson(r): 0.8163, loss: 0.0307, reg_loss: 0.0000 ||:  32%|███▏      | 58/180 [02:14<04:53,  2.40s/it]\u001b[A\n",
            "pearson(r): 0.8164, loss: 0.0306, reg_loss: 0.0000 ||:  33%|███▎      | 59/180 [02:15<04:24,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.8131, loss: 0.0312, reg_loss: 0.0000 ||:  33%|███▎      | 60/180 [02:22<06:56,  3.47s/it]\u001b[A\n",
            "pearson(r): 0.8129, loss: 0.0313, reg_loss: 0.0000 ||:  34%|███▍      | 61/180 [02:24<06:15,  3.15s/it]\u001b[A\n",
            "pearson(r): 0.8123, loss: 0.0314, reg_loss: 0.0000 ||:  34%|███▍      | 62/180 [02:26<05:11,  2.64s/it]\u001b[A\n",
            "pearson(r): 0.8120, loss: 0.0314, reg_loss: 0.0000 ||:  35%|███▌      | 63/180 [02:32<07:30,  3.85s/it]\u001b[A\n",
            "pearson(r): 0.8123, loss: 0.0316, reg_loss: 0.0000 ||:  36%|███▌      | 64/180 [02:35<06:51,  3.54s/it]\u001b[A\n",
            "pearson(r): 0.8114, loss: 0.0316, reg_loss: 0.0000 ||:  36%|███▌      | 65/180 [02:37<05:48,  3.03s/it]\u001b[A\n",
            "pearson(r): 0.8120, loss: 0.0315, reg_loss: 0.0000 ||:  37%|███▋      | 66/180 [02:39<05:11,  2.74s/it]\u001b[A\n",
            "pearson(r): 0.8120, loss: 0.0315, reg_loss: 0.0000 ||:  37%|███▋      | 67/180 [02:46<07:20,  3.90s/it]\u001b[A\n",
            "pearson(r): 0.8120, loss: 0.0315, reg_loss: 0.0000 ||:  38%|███▊      | 68/180 [02:48<06:31,  3.49s/it]\u001b[A\n",
            "pearson(r): 0.8113, loss: 0.0316, reg_loss: 0.0000 ||:  38%|███▊      | 69/180 [02:52<06:40,  3.61s/it]\u001b[A\n",
            "pearson(r): 0.8112, loss: 0.0317, reg_loss: 0.0000 ||:  39%|███▉      | 70/180 [02:54<05:32,  3.02s/it]\u001b[A\n",
            "pearson(r): 0.8107, loss: 0.0318, reg_loss: 0.0000 ||:  39%|███▉      | 71/180 [02:57<05:23,  2.97s/it]\u001b[A\n",
            "pearson(r): 0.8098, loss: 0.0318, reg_loss: 0.0000 ||:  40%|████      | 72/180 [02:59<04:52,  2.71s/it]\u001b[A\n",
            "pearson(r): 0.8090, loss: 0.0320, reg_loss: 0.0000 ||:  41%|████      | 73/180 [03:00<04:19,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.8079, loss: 0.0321, reg_loss: 0.0000 ||:  41%|████      | 74/180 [03:02<03:57,  2.24s/it]\u001b[A\n",
            "pearson(r): 0.8082, loss: 0.0321, reg_loss: 0.0000 ||:  42%|████▏     | 75/180 [03:04<03:52,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.8103, loss: 0.0319, reg_loss: 0.0000 ||:  42%|████▏     | 76/180 [03:06<03:30,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.8101, loss: 0.0319, reg_loss: 0.0000 ||:  43%|████▎     | 77/180 [03:08<03:25,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.8102, loss: 0.0320, reg_loss: 0.0000 ||:  43%|████▎     | 78/180 [03:10<03:31,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.8098, loss: 0.0319, reg_loss: 0.0000 ||:  44%|████▍     | 79/180 [03:12<03:28,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.8102, loss: 0.0318, reg_loss: 0.0000 ||:  44%|████▍     | 80/180 [03:14<03:32,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.8109, loss: 0.0317, reg_loss: 0.0000 ||:  45%|████▌     | 81/180 [03:17<03:29,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.8111, loss: 0.0316, reg_loss: 0.0000 ||:  46%|████▌     | 82/180 [03:19<03:26,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.8117, loss: 0.0316, reg_loss: 0.0000 ||:  46%|████▌     | 83/180 [03:20<03:13,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.8107, loss: 0.0317, reg_loss: 0.0000 ||:  47%|████▋     | 84/180 [03:22<03:13,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.8109, loss: 0.0317, reg_loss: 0.0000 ||:  47%|████▋     | 85/180 [03:24<03:06,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.8111, loss: 0.0318, reg_loss: 0.0000 ||:  48%|████▊     | 86/180 [03:27<03:16,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.8108, loss: 0.0318, reg_loss: 0.0000 ||:  48%|████▊     | 87/180 [03:29<03:11,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.8105, loss: 0.0319, reg_loss: 0.0000 ||:  49%|████▉     | 88/180 [03:31<03:07,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.8102, loss: 0.0319, reg_loss: 0.0000 ||:  49%|████▉     | 89/180 [03:33<03:03,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.8108, loss: 0.0318, reg_loss: 0.0000 ||:  50%|█████     | 90/180 [03:35<03:06,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.8104, loss: 0.0318, reg_loss: 0.0000 ||:  51%|█████     | 91/180 [03:37<02:57,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.8111, loss: 0.0318, reg_loss: 0.0000 ||:  51%|█████     | 92/180 [03:39<02:54,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.8099, loss: 0.0319, reg_loss: 0.0000 ||:  52%|█████▏    | 93/180 [03:40<02:49,  1.95s/it]\u001b[A\n",
            "pearson(r): 0.8092, loss: 0.0320, reg_loss: 0.0000 ||:  52%|█████▏    | 94/180 [03:42<02:37,  1.84s/it]\u001b[A\n",
            "pearson(r): 0.8068, loss: 0.0322, reg_loss: 0.0000 ||:  53%|█████▎    | 95/180 [03:46<03:28,  2.45s/it]\u001b[A\n",
            "pearson(r): 0.8071, loss: 0.0321, reg_loss: 0.0000 ||:  53%|█████▎    | 96/180 [03:48<03:12,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.8069, loss: 0.0321, reg_loss: 0.0000 ||:  54%|█████▍    | 97/180 [03:50<03:08,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.8070, loss: 0.0321, reg_loss: 0.0000 ||:  54%|█████▍    | 98/180 [03:52<02:57,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.8063, loss: 0.0322, reg_loss: 0.0000 ||:  55%|█████▌    | 99/180 [03:54<02:49,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.8064, loss: 0.0321, reg_loss: 0.0000 ||:  56%|█████▌    | 100/180 [03:56<02:40,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.8064, loss: 0.0321, reg_loss: 0.0000 ||:  56%|█████▌    | 101/180 [03:58<02:37,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.8066, loss: 0.0320, reg_loss: 0.0000 ||:  57%|█████▋    | 102/180 [04:00<02:33,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.8064, loss: 0.0321, reg_loss: 0.0000 ||:  57%|█████▋    | 103/180 [04:02<02:34,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.8062, loss: 0.0321, reg_loss: 0.0000 ||:  58%|█████▊    | 104/180 [04:03<02:25,  1.91s/it]\u001b[A\n",
            "pearson(r): 0.8062, loss: 0.0321, reg_loss: 0.0000 ||:  58%|█████▊    | 105/180 [04:06<02:31,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.8060, loss: 0.0322, reg_loss: 0.0000 ||:  59%|█████▉    | 106/180 [04:08<02:26,  1.98s/it]\u001b[A\n",
            "pearson(r): 0.8059, loss: 0.0321, reg_loss: 0.0000 ||:  59%|█████▉    | 107/180 [04:09<02:23,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.8056, loss: 0.0321, reg_loss: 0.0000 ||:  60%|██████    | 108/180 [04:11<02:21,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.8048, loss: 0.0321, reg_loss: 0.0000 ||:  61%|██████    | 109/180 [04:13<02:21,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.8052, loss: 0.0321, reg_loss: 0.0000 ||:  61%|██████    | 110/180 [04:15<02:14,  1.92s/it]\u001b[A\n",
            "pearson(r): 0.8053, loss: 0.0321, reg_loss: 0.0000 ||:  62%|██████▏   | 111/180 [04:17<02:14,  1.95s/it]\u001b[A\n",
            "pearson(r): 0.8047, loss: 0.0322, reg_loss: 0.0000 ||:  62%|██████▏   | 112/180 [04:19<02:13,  1.96s/it]\u001b[A\n",
            "pearson(r): 0.8039, loss: 0.0324, reg_loss: 0.0000 ||:  63%|██████▎   | 113/180 [04:24<03:02,  2.72s/it]\u001b[A\n",
            "pearson(r): 0.8034, loss: 0.0324, reg_loss: 0.0000 ||:  63%|██████▎   | 114/180 [04:26<02:48,  2.55s/it]\u001b[A\n",
            "pearson(r): 0.8026, loss: 0.0325, reg_loss: 0.0000 ||:  64%|██████▍   | 115/180 [04:28<02:28,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.8028, loss: 0.0325, reg_loss: 0.0000 ||:  64%|██████▍   | 116/180 [04:30<02:27,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.8017, loss: 0.0326, reg_loss: 0.0000 ||:  65%|██████▌   | 117/180 [04:32<02:17,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.8014, loss: 0.0326, reg_loss: 0.0000 ||:  66%|██████▌   | 118/180 [04:34<02:15,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.8010, loss: 0.0326, reg_loss: 0.0000 ||:  66%|██████▌   | 119/180 [04:36<02:11,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.8004, loss: 0.0326, reg_loss: 0.0000 ||:  67%|██████▋   | 120/180 [04:40<02:37,  2.62s/it]\u001b[A\n",
            "pearson(r): 0.8008, loss: 0.0326, reg_loss: 0.0000 ||:  67%|██████▋   | 121/180 [04:42<02:29,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.8000, loss: 0.0326, reg_loss: 0.0000 ||:  68%|██████▊   | 122/180 [04:47<02:59,  3.09s/it]\u001b[A\n",
            "pearson(r): 0.7992, loss: 0.0328, reg_loss: 0.0000 ||:  68%|██████▊   | 123/180 [04:49<02:40,  2.82s/it]\u001b[A\n",
            "pearson(r): 0.7986, loss: 0.0328, reg_loss: 0.0000 ||:  69%|██████▉   | 124/180 [04:51<02:27,  2.63s/it]\u001b[A\n",
            "pearson(r): 0.7977, loss: 0.0328, reg_loss: 0.0000 ||:  69%|██████▉   | 125/180 [04:53<02:11,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.7972, loss: 0.0329, reg_loss: 0.0000 ||:  70%|███████   | 126/180 [04:55<02:02,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.7969, loss: 0.0329, reg_loss: 0.0000 ||:  71%|███████   | 127/180 [04:57<02:03,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.7960, loss: 0.0330, reg_loss: 0.0000 ||:  71%|███████   | 128/180 [04:59<02:00,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.7949, loss: 0.0331, reg_loss: 0.0000 ||:  72%|███████▏  | 129/180 [05:03<02:21,  2.77s/it]\u001b[A\n",
            "pearson(r): 0.7941, loss: 0.0332, reg_loss: 0.0000 ||:  72%|███████▏  | 130/180 [05:06<02:19,  2.78s/it]\u001b[A\n",
            "pearson(r): 0.7944, loss: 0.0331, reg_loss: 0.0000 ||:  73%|███████▎  | 131/180 [05:08<02:05,  2.57s/it]\u001b[A\n",
            "pearson(r): 0.7945, loss: 0.0331, reg_loss: 0.0000 ||:  73%|███████▎  | 132/180 [05:10<01:53,  2.37s/it]\u001b[A\n",
            "pearson(r): 0.7938, loss: 0.0332, reg_loss: 0.0000 ||:  74%|███████▍  | 133/180 [05:13<01:54,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.7936, loss: 0.0332, reg_loss: 0.0000 ||:  74%|███████▍  | 134/180 [05:14<01:38,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.7924, loss: 0.0333, reg_loss: 0.0000 ||:  75%|███████▌  | 135/180 [05:21<02:35,  3.46s/it]\u001b[A\n",
            "pearson(r): 0.7926, loss: 0.0333, reg_loss: 0.0000 ||:  76%|███████▌  | 136/180 [05:22<02:09,  2.94s/it]\u001b[A\n",
            "pearson(r): 0.7922, loss: 0.0333, reg_loss: 0.0000 ||:  76%|███████▌  | 137/180 [05:25<02:07,  2.96s/it]\u001b[A\n",
            "pearson(r): 0.7915, loss: 0.0334, reg_loss: 0.0000 ||:  77%|███████▋  | 138/180 [05:27<01:51,  2.65s/it]\u001b[A\n",
            "pearson(r): 0.7912, loss: 0.0334, reg_loss: 0.0000 ||:  77%|███████▋  | 139/180 [05:29<01:39,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.7916, loss: 0.0334, reg_loss: 0.0000 ||:  78%|███████▊  | 140/180 [05:31<01:29,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.7920, loss: 0.0334, reg_loss: 0.0000 ||:  78%|███████▊  | 141/180 [05:32<01:16,  1.96s/it]\u001b[A\n",
            "pearson(r): 0.7924, loss: 0.0334, reg_loss: 0.0000 ||:  79%|███████▉  | 142/180 [05:34<01:14,  1.96s/it]\u001b[A\n",
            "pearson(r): 0.7915, loss: 0.0335, reg_loss: 0.0000 ||:  79%|███████▉  | 143/180 [05:36<01:12,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.7913, loss: 0.0336, reg_loss: 0.0000 ||:  80%|████████  | 144/180 [05:38<01:13,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.7914, loss: 0.0335, reg_loss: 0.0000 ||:  81%|████████  | 145/180 [05:41<01:12,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.7910, loss: 0.0335, reg_loss: 0.0000 ||:  81%|████████  | 146/180 [05:43<01:15,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.7910, loss: 0.0335, reg_loss: 0.0000 ||:  82%|████████▏ | 147/180 [05:45<01:11,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.7907, loss: 0.0335, reg_loss: 0.0000 ||:  82%|████████▏ | 148/180 [05:48<01:12,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.7911, loss: 0.0335, reg_loss: 0.0000 ||:  83%|████████▎ | 149/180 [05:51<01:19,  2.58s/it]\u001b[A\n",
            "pearson(r): 0.7908, loss: 0.0336, reg_loss: 0.0000 ||:  83%|████████▎ | 150/180 [05:54<01:21,  2.72s/it]\u001b[A\n",
            "pearson(r): 0.7904, loss: 0.0336, reg_loss: 0.0000 ||:  84%|████████▍ | 151/180 [05:56<01:15,  2.59s/it]\u001b[A\n",
            "pearson(r): 0.7895, loss: 0.0336, reg_loss: 0.0000 ||:  84%|████████▍ | 152/180 [05:58<01:08,  2.45s/it]\u001b[A\n",
            "pearson(r): 0.7895, loss: 0.0336, reg_loss: 0.0000 ||:  85%|████████▌ | 153/180 [06:01<01:08,  2.54s/it]\u001b[A\n",
            "pearson(r): 0.7893, loss: 0.0336, reg_loss: 0.0000 ||:  86%|████████▌ | 154/180 [06:03<01:00,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.7887, loss: 0.0337, reg_loss: 0.0000 ||:  86%|████████▌ | 155/180 [06:05<00:58,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.7881, loss: 0.0338, reg_loss: 0.0000 ||:  87%|████████▋ | 156/180 [06:07<00:53,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.7880, loss: 0.0338, reg_loss: 0.0000 ||:  87%|████████▋ | 157/180 [06:09<00:49,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.7880, loss: 0.0337, reg_loss: 0.0000 ||:  88%|████████▊ | 158/180 [06:11<00:46,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.7880, loss: 0.0338, reg_loss: 0.0000 ||:  88%|████████▊ | 159/180 [06:14<00:48,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.7874, loss: 0.0338, reg_loss: 0.0000 ||:  89%|████████▉ | 160/180 [06:16<00:45,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.7873, loss: 0.0339, reg_loss: 0.0000 ||:  89%|████████▉ | 161/180 [06:18<00:38,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.7869, loss: 0.0339, reg_loss: 0.0000 ||:  90%|█████████ | 162/180 [06:20<00:36,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.7865, loss: 0.0340, reg_loss: 0.0000 ||:  91%|█████████ | 163/180 [06:22<00:35,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.7857, loss: 0.0340, reg_loss: 0.0000 ||:  91%|█████████ | 164/180 [06:25<00:35,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.7856, loss: 0.0340, reg_loss: 0.0000 ||:  92%|█████████▏| 165/180 [06:28<00:39,  2.66s/it]\u001b[A\n",
            "pearson(r): 0.7859, loss: 0.0340, reg_loss: 0.0000 ||:  92%|█████████▏| 166/180 [06:31<00:35,  2.55s/it]\u001b[A\n",
            "pearson(r): 0.7853, loss: 0.0340, reg_loss: 0.0000 ||:  93%|█████████▎| 167/180 [06:33<00:32,  2.47s/it]\u001b[A\n",
            "pearson(r): 0.7851, loss: 0.0340, reg_loss: 0.0000 ||:  93%|█████████▎| 168/180 [06:35<00:28,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.7851, loss: 0.0340, reg_loss: 0.0000 ||:  94%|█████████▍| 169/180 [06:37<00:25,  2.30s/it]\u001b[A\n",
            "pearson(r): 0.7852, loss: 0.0341, reg_loss: 0.0000 ||:  94%|█████████▍| 170/180 [06:39<00:21,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.7848, loss: 0.0342, reg_loss: 0.0000 ||:  95%|█████████▌| 171/180 [06:41<00:18,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.7847, loss: 0.0342, reg_loss: 0.0000 ||:  96%|█████████▌| 172/180 [06:45<00:20,  2.56s/it]\u001b[A\n",
            "pearson(r): 0.7846, loss: 0.0342, reg_loss: 0.0000 ||:  96%|█████████▌| 173/180 [06:46<00:16,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.7845, loss: 0.0342, reg_loss: 0.0000 ||:  97%|█████████▋| 174/180 [06:48<00:13,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.7849, loss: 0.0342, reg_loss: 0.0000 ||:  97%|█████████▋| 175/180 [06:50<00:10,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.7847, loss: 0.0342, reg_loss: 0.0000 ||:  98%|█████████▊| 176/180 [06:52<00:08,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.7849, loss: 0.0341, reg_loss: 0.0000 ||:  98%|█████████▊| 177/180 [06:54<00:06,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.7850, loss: 0.0341, reg_loss: 0.0000 ||:  99%|█████████▉| 178/180 [06:57<00:04,  2.30s/it]\u001b[A\n",
            "pearson(r): 0.7847, loss: 0.0342, reg_loss: 0.0000 ||:  99%|█████████▉| 179/180 [06:59<00:02,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.7847, loss: 0.0342, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [07:01<00:00,  2.34s/it]\n",
            "\n",
            "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.7597, loss: 0.0690, reg_loss: 0.0000 ||:   2%|▏         | 1/47 [00:00<00:13,  3.52it/s]\u001b[A\n",
            "pearson(r): 0.7631, loss: 0.0752, reg_loss: 0.0000 ||:   4%|▍         | 2/47 [00:00<00:12,  3.48it/s]\u001b[A\n",
            "pearson(r): 0.7688, loss: 0.0694, reg_loss: 0.0000 ||:   6%|▋         | 3/47 [00:00<00:13,  3.31it/s]\u001b[A\n",
            "pearson(r): 0.7372, loss: 0.0915, reg_loss: 0.0000 ||:   9%|▊         | 4/47 [00:01<00:13,  3.27it/s]\u001b[A\n",
            "pearson(r): 0.7447, loss: 0.0846, reg_loss: 0.0000 ||:  11%|█         | 5/47 [00:01<00:12,  3.40it/s]\u001b[A\n",
            "pearson(r): 0.7439, loss: 0.0828, reg_loss: 0.0000 ||:  13%|█▎        | 6/47 [00:01<00:12,  3.31it/s]\u001b[A\n",
            "pearson(r): 0.7430, loss: 0.0875, reg_loss: 0.0000 ||:  15%|█▍        | 7/47 [00:02<00:12,  3.26it/s]\u001b[A\n",
            "pearson(r): 0.7376, loss: 0.0931, reg_loss: 0.0000 ||:  17%|█▋        | 8/47 [00:02<00:12,  3.06it/s]\u001b[A\n",
            "pearson(r): 0.7238, loss: 0.0953, reg_loss: 0.0000 ||:  19%|█▉        | 9/47 [00:02<00:13,  2.89it/s]\u001b[A\n",
            "pearson(r): 0.7110, loss: 0.0996, reg_loss: 0.0000 ||:  21%|██▏       | 10/47 [00:03<00:13,  2.79it/s]\u001b[A\n",
            "pearson(r): 0.7120, loss: 0.0977, reg_loss: 0.0000 ||:  23%|██▎       | 11/47 [00:03<00:13,  2.60it/s]\u001b[A\n",
            "pearson(r): 0.7095, loss: 0.0990, reg_loss: 0.0000 ||:  26%|██▌       | 12/47 [00:04<00:13,  2.53it/s]\u001b[A\n",
            "pearson(r): 0.6987, loss: 0.1027, reg_loss: 0.0000 ||:  28%|██▊       | 13/47 [00:04<00:13,  2.46it/s]\u001b[A\n",
            "pearson(r): 0.7018, loss: 0.1019, reg_loss: 0.0000 ||:  30%|██▉       | 14/47 [00:04<00:13,  2.47it/s]\u001b[A\n",
            "pearson(r): 0.6868, loss: 0.1079, reg_loss: 0.0000 ||:  32%|███▏      | 15/47 [00:05<00:13,  2.43it/s]\u001b[A\n",
            "pearson(r): 0.6741, loss: 0.1132, reg_loss: 0.0000 ||:  34%|███▍      | 16/47 [00:05<00:13,  2.38it/s]\u001b[A\n",
            "pearson(r): 0.6780, loss: 0.1115, reg_loss: 0.0000 ||:  36%|███▌      | 17/47 [00:06<00:12,  2.32it/s]\u001b[A\n",
            "pearson(r): 0.6721, loss: 0.1140, reg_loss: 0.0000 ||:  38%|███▊      | 18/47 [00:06<00:12,  2.34it/s]\u001b[A\n",
            "pearson(r): 0.6702, loss: 0.1151, reg_loss: 0.0000 ||:  40%|████      | 19/47 [00:07<00:11,  2.35it/s]\u001b[A\n",
            "pearson(r): 0.6517, loss: 0.1198, reg_loss: 0.0000 ||:  43%|████▎     | 20/47 [00:07<00:12,  2.18it/s]\u001b[A\n",
            "pearson(r): 0.6407, loss: 0.1239, reg_loss: 0.0000 ||:  45%|████▍     | 21/47 [00:08<00:12,  2.03it/s]\u001b[A\n",
            "pearson(r): 0.6235, loss: 0.1290, reg_loss: 0.0000 ||:  47%|████▋     | 22/47 [00:08<00:12,  1.93it/s]\u001b[A\n",
            "pearson(r): 0.6143, loss: 0.1312, reg_loss: 0.0000 ||:  49%|████▉     | 23/47 [00:09<00:13,  1.85it/s]\u001b[A\n",
            "pearson(r): 0.5990, loss: 0.1362, reg_loss: 0.0000 ||:  51%|█████     | 24/47 [00:10<00:13,  1.76it/s]\u001b[A\n",
            "pearson(r): 0.5774, loss: 0.1426, reg_loss: 0.0000 ||:  53%|█████▎    | 25/47 [00:10<00:12,  1.74it/s]\u001b[A\n",
            "pearson(r): 0.5719, loss: 0.1433, reg_loss: 0.0000 ||:  55%|█████▌    | 26/47 [00:11<00:11,  1.78it/s]\u001b[A\n",
            "pearson(r): 0.5577, loss: 0.1468, reg_loss: 0.0000 ||:  57%|█████▋    | 27/47 [00:11<00:11,  1.78it/s]\u001b[A\n",
            "pearson(r): 0.5512, loss: 0.1476, reg_loss: 0.0000 ||:  60%|█████▉    | 28/47 [00:12<00:10,  1.73it/s]\u001b[A\n",
            "pearson(r): 0.5444, loss: 0.1515, reg_loss: 0.0000 ||:  62%|██████▏   | 29/47 [00:12<00:10,  1.77it/s]\u001b[A\n",
            "pearson(r): 0.5345, loss: 0.1548, reg_loss: 0.0000 ||:  64%|██████▍   | 30/47 [00:13<00:09,  1.78it/s]\u001b[A\n",
            "pearson(r): 0.5247, loss: 0.1582, reg_loss: 0.0000 ||:  66%|██████▌   | 31/47 [00:13<00:08,  1.81it/s]\u001b[A\n",
            "pearson(r): 0.5313, loss: 0.1564, reg_loss: 0.0000 ||:  68%|██████▊   | 32/47 [00:14<00:08,  1.70it/s]\u001b[A\n",
            "pearson(r): 0.5408, loss: 0.1535, reg_loss: 0.0000 ||:  70%|███████   | 33/47 [00:15<00:08,  1.65it/s]\u001b[A\n",
            "pearson(r): 0.5471, loss: 0.1505, reg_loss: 0.0000 ||:  72%|███████▏  | 34/47 [00:15<00:08,  1.58it/s]\u001b[A\n",
            "pearson(r): 0.5520, loss: 0.1481, reg_loss: 0.0000 ||:  74%|███████▍  | 35/47 [00:16<00:08,  1.47it/s]\u001b[A\n",
            "pearson(r): 0.5557, loss: 0.1463, reg_loss: 0.0000 ||:  77%|███████▋  | 36/47 [00:17<00:07,  1.45it/s]\u001b[A\n",
            "pearson(r): 0.5593, loss: 0.1447, reg_loss: 0.0000 ||:  79%|███████▊  | 37/47 [00:18<00:06,  1.46it/s]\u001b[A\n",
            "pearson(r): 0.5625, loss: 0.1427, reg_loss: 0.0000 ||:  81%|████████  | 38/47 [00:18<00:06,  1.47it/s]\u001b[A\n",
            "pearson(r): 0.5666, loss: 0.1406, reg_loss: 0.0000 ||:  83%|████████▎ | 39/47 [00:19<00:05,  1.44it/s]\u001b[A\n",
            "pearson(r): 0.5641, loss: 0.1411, reg_loss: 0.0000 ||:  85%|████████▌ | 40/47 [00:19<00:04,  1.64it/s]\u001b[A\n",
            "pearson(r): 0.5655, loss: 0.1402, reg_loss: 0.0000 ||:  87%|████████▋ | 41/47 [00:20<00:03,  1.87it/s]\u001b[A\n",
            "pearson(r): 0.5668, loss: 0.1401, reg_loss: 0.0000 ||:  89%|████████▉ | 42/47 [00:20<00:02,  2.14it/s]\u001b[A\n",
            "pearson(r): 0.5669, loss: 0.1408, reg_loss: 0.0000 ||:  91%|█████████▏| 43/47 [00:20<00:01,  2.32it/s]\u001b[A\n",
            "pearson(r): 0.5669, loss: 0.1403, reg_loss: 0.0000 ||:  94%|█████████▎| 44/47 [00:21<00:01,  2.46it/s]\u001b[A\n",
            "pearson(r): 0.5634, loss: 0.1414, reg_loss: 0.0000 ||:  96%|█████████▌| 45/47 [00:21<00:00,  2.63it/s]\u001b[A\n",
            "pearson(r): 0.5651, loss: 0.1424, reg_loss: 0.0000 ||:  98%|█████████▊| 46/47 [00:22<00:00,  2.67it/s]\u001b[A\n",
            "pearson(r): 0.5586, loss: 0.1434, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:22<00:00,  2.10it/s]\n",
            "\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.8468, loss: 0.0328, reg_loss: 0.0000 ||:   1%|          | 1/180 [00:01<04:27,  1.50s/it]\u001b[A\n",
            "pearson(r): 0.8491, loss: 0.0304, reg_loss: 0.0000 ||:   1%|          | 2/180 [00:03<04:45,  1.60s/it]\u001b[A\n",
            "pearson(r): 0.8615, loss: 0.0274, reg_loss: 0.0000 ||:   2%|▏         | 3/180 [00:05<05:15,  1.78s/it]\u001b[A\n",
            "pearson(r): 0.8339, loss: 0.0281, reg_loss: 0.0000 ||:   2%|▏         | 4/180 [00:08<06:26,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.8278, loss: 0.0280, reg_loss: 0.0000 ||:   3%|▎         | 5/180 [00:11<06:56,  2.38s/it]\u001b[A\n",
            "pearson(r): 0.8375, loss: 0.0269, reg_loss: 0.0000 ||:   3%|▎         | 6/180 [00:13<06:40,  2.30s/it]\u001b[A\n",
            "pearson(r): 0.8230, loss: 0.0278, reg_loss: 0.0000 ||:   4%|▍         | 7/180 [00:16<06:49,  2.37s/it]\u001b[A\n",
            "pearson(r): 0.8229, loss: 0.0279, reg_loss: 0.0000 ||:   4%|▍         | 8/180 [00:18<06:41,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.8311, loss: 0.0277, reg_loss: 0.0000 ||:   5%|▌         | 9/180 [00:20<06:18,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.8367, loss: 0.0264, reg_loss: 0.0000 ||:   6%|▌         | 10/180 [00:22<06:15,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.8436, loss: 0.0255, reg_loss: 0.0000 ||:   6%|▌         | 11/180 [00:24<06:03,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.8445, loss: 0.0250, reg_loss: 0.0000 ||:   7%|▋         | 12/180 [00:26<06:12,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.8427, loss: 0.0257, reg_loss: 0.0000 ||:   7%|▋         | 13/180 [00:29<06:12,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.8430, loss: 0.0259, reg_loss: 0.0000 ||:   8%|▊         | 14/180 [00:31<06:15,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.8409, loss: 0.0259, reg_loss: 0.0000 ||:   8%|▊         | 15/180 [00:33<06:00,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.8415, loss: 0.0266, reg_loss: 0.0000 ||:   9%|▉         | 16/180 [00:36<06:18,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.8410, loss: 0.0264, reg_loss: 0.0000 ||:   9%|▉         | 17/180 [00:39<06:59,  2.57s/it]\u001b[A\n",
            "pearson(r): 0.8377, loss: 0.0265, reg_loss: 0.0000 ||:  10%|█         | 18/180 [00:41<06:57,  2.58s/it]\u001b[A\n",
            "pearson(r): 0.8380, loss: 0.0265, reg_loss: 0.0000 ||:  11%|█         | 19/180 [00:44<06:38,  2.48s/it]\u001b[A\n",
            "pearson(r): 0.8366, loss: 0.0267, reg_loss: 0.0000 ||:  11%|█         | 20/180 [00:46<06:21,  2.38s/it]\u001b[A\n",
            "pearson(r): 0.8367, loss: 0.0265, reg_loss: 0.0000 ||:  12%|█▏        | 21/180 [00:50<07:46,  2.93s/it]\u001b[A\n",
            "pearson(r): 0.8393, loss: 0.0261, reg_loss: 0.0000 ||:  12%|█▏        | 22/180 [00:52<07:06,  2.70s/it]\u001b[A\n",
            "pearson(r): 0.8379, loss: 0.0262, reg_loss: 0.0000 ||:  13%|█▎        | 23/180 [00:54<06:39,  2.54s/it]\u001b[A\n",
            "pearson(r): 0.8380, loss: 0.0262, reg_loss: 0.0000 ||:  13%|█▎        | 24/180 [00:56<06:13,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.8384, loss: 0.0262, reg_loss: 0.0000 ||:  14%|█▍        | 25/180 [00:59<06:04,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.8395, loss: 0.0265, reg_loss: 0.0000 ||:  14%|█▍        | 26/180 [01:01<05:46,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.8392, loss: 0.0267, reg_loss: 0.0000 ||:  15%|█▌        | 27/180 [01:03<05:32,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.8369, loss: 0.0269, reg_loss: 0.0000 ||:  16%|█▌        | 28/180 [01:05<05:26,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.8376, loss: 0.0270, reg_loss: 0.0000 ||:  16%|█▌        | 29/180 [01:06<04:51,  1.93s/it]\u001b[A\n",
            "pearson(r): 0.8381, loss: 0.0270, reg_loss: 0.0000 ||:  17%|█▋        | 30/180 [01:09<05:16,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.8350, loss: 0.0272, reg_loss: 0.0000 ||:  17%|█▋        | 31/180 [01:16<09:01,  3.63s/it]\u001b[A\n",
            "pearson(r): 0.8368, loss: 0.0272, reg_loss: 0.0000 ||:  18%|█▊        | 32/180 [01:18<07:43,  3.13s/it]\u001b[A\n",
            "pearson(r): 0.8365, loss: 0.0273, reg_loss: 0.0000 ||:  18%|█▊        | 33/180 [01:19<06:27,  2.64s/it]\u001b[A\n",
            "pearson(r): 0.8351, loss: 0.0273, reg_loss: 0.0000 ||:  19%|█▉        | 34/180 [01:21<06:00,  2.47s/it]\u001b[A\n",
            "pearson(r): 0.8348, loss: 0.0272, reg_loss: 0.0000 ||:  19%|█▉        | 35/180 [01:24<05:58,  2.47s/it]\u001b[A\n",
            "pearson(r): 0.8331, loss: 0.0275, reg_loss: 0.0000 ||:  20%|██        | 36/180 [01:26<05:54,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.8318, loss: 0.0277, reg_loss: 0.0000 ||:  21%|██        | 37/180 [01:29<05:51,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.8325, loss: 0.0276, reg_loss: 0.0000 ||:  21%|██        | 38/180 [01:31<05:28,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.8320, loss: 0.0275, reg_loss: 0.0000 ||:  22%|██▏       | 39/180 [01:33<05:14,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.8294, loss: 0.0279, reg_loss: 0.0000 ||:  22%|██▏       | 40/180 [01:36<05:45,  2.47s/it]\u001b[A\n",
            "pearson(r): 0.8264, loss: 0.0282, reg_loss: 0.0000 ||:  23%|██▎       | 41/180 [01:38<05:22,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.8256, loss: 0.0285, reg_loss: 0.0000 ||:  23%|██▎       | 42/180 [01:40<05:24,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.8261, loss: 0.0285, reg_loss: 0.0000 ||:  24%|██▍       | 43/180 [01:42<05:16,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.8250, loss: 0.0286, reg_loss: 0.0000 ||:  24%|██▍       | 44/180 [01:45<05:04,  2.24s/it]\u001b[A\n",
            "pearson(r): 0.8235, loss: 0.0288, reg_loss: 0.0000 ||:  25%|██▌       | 45/180 [01:48<05:33,  2.47s/it]\u001b[A\n",
            "pearson(r): 0.8236, loss: 0.0289, reg_loss: 0.0000 ||:  26%|██▌       | 46/180 [01:50<05:18,  2.38s/it]\u001b[A\n",
            "pearson(r): 0.8231, loss: 0.0289, reg_loss: 0.0000 ||:  26%|██▌       | 47/180 [01:52<05:13,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.8230, loss: 0.0289, reg_loss: 0.0000 ||:  27%|██▋       | 48/180 [01:55<05:30,  2.50s/it]\u001b[A\n",
            "pearson(r): 0.8225, loss: 0.0290, reg_loss: 0.0000 ||:  27%|██▋       | 49/180 [01:57<05:15,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.8221, loss: 0.0288, reg_loss: 0.0000 ||:  28%|██▊       | 50/180 [02:00<05:24,  2.50s/it]\u001b[A\n",
            "pearson(r): 0.8239, loss: 0.0287, reg_loss: 0.0000 ||:  28%|██▊       | 51/180 [02:02<05:05,  2.37s/it]\u001b[A\n",
            "pearson(r): 0.8232, loss: 0.0288, reg_loss: 0.0000 ||:  29%|██▉       | 52/180 [02:04<04:56,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.8241, loss: 0.0290, reg_loss: 0.0000 ||:  29%|██▉       | 53/180 [02:06<04:45,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.8251, loss: 0.0290, reg_loss: 0.0000 ||:  30%|███       | 54/180 [02:08<04:27,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.8257, loss: 0.0288, reg_loss: 0.0000 ||:  31%|███       | 55/180 [02:10<04:09,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.8239, loss: 0.0292, reg_loss: 0.0000 ||:  31%|███       | 56/180 [02:13<05:11,  2.51s/it]\u001b[A\n",
            "pearson(r): 0.8234, loss: 0.0292, reg_loss: 0.0000 ||:  32%|███▏      | 57/180 [02:16<05:14,  2.56s/it]\u001b[A\n",
            "pearson(r): 0.8243, loss: 0.0291, reg_loss: 0.0000 ||:  32%|███▏      | 58/180 [02:19<05:29,  2.70s/it]\u001b[A\n",
            "pearson(r): 0.8242, loss: 0.0291, reg_loss: 0.0000 ||:  33%|███▎      | 59/180 [02:21<05:07,  2.54s/it]\u001b[A\n",
            "pearson(r): 0.8250, loss: 0.0290, reg_loss: 0.0000 ||:  33%|███▎      | 60/180 [02:23<04:28,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.8243, loss: 0.0290, reg_loss: 0.0000 ||:  34%|███▍      | 61/180 [02:27<05:46,  2.91s/it]\u001b[A\n",
            "pearson(r): 0.8250, loss: 0.0289, reg_loss: 0.0000 ||:  34%|███▍      | 62/180 [02:29<05:08,  2.62s/it]\u001b[A\n",
            "pearson(r): 0.8261, loss: 0.0288, reg_loss: 0.0000 ||:  35%|███▌      | 63/180 [02:31<04:45,  2.44s/it]\u001b[A\n",
            "pearson(r): 0.8252, loss: 0.0287, reg_loss: 0.0000 ||:  36%|███▌      | 64/180 [02:34<04:39,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.8255, loss: 0.0287, reg_loss: 0.0000 ||:  36%|███▌      | 65/180 [02:35<04:21,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.8259, loss: 0.0287, reg_loss: 0.0000 ||:  37%|███▋      | 66/180 [02:37<04:02,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.8273, loss: 0.0288, reg_loss: 0.0000 ||:  37%|███▋      | 67/180 [02:39<03:38,  1.93s/it]\u001b[A\n",
            "pearson(r): 0.8272, loss: 0.0287, reg_loss: 0.0000 ||:  38%|███▊      | 68/180 [02:41<03:43,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.8270, loss: 0.0288, reg_loss: 0.0000 ||:  38%|███▊      | 69/180 [02:43<03:44,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.8272, loss: 0.0287, reg_loss: 0.0000 ||:  39%|███▉      | 70/180 [02:46<04:04,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.8265, loss: 0.0288, reg_loss: 0.0000 ||:  39%|███▉      | 71/180 [02:48<03:52,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.8249, loss: 0.0290, reg_loss: 0.0000 ||:  40%|████      | 72/180 [02:50<03:45,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.8247, loss: 0.0290, reg_loss: 0.0000 ||:  41%|████      | 73/180 [02:51<03:38,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.8244, loss: 0.0288, reg_loss: 0.0000 ||:  41%|████      | 74/180 [02:54<03:56,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.8223, loss: 0.0290, reg_loss: 0.0000 ||:  42%|████▏     | 75/180 [02:58<04:37,  2.65s/it]\u001b[A\n",
            "pearson(r): 0.8217, loss: 0.0290, reg_loss: 0.0000 ||:  42%|████▏     | 76/180 [03:01<04:45,  2.74s/it]\u001b[A\n",
            "pearson(r): 0.8206, loss: 0.0291, reg_loss: 0.0000 ||:  43%|████▎     | 77/180 [03:02<04:10,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.8208, loss: 0.0290, reg_loss: 0.0000 ||:  43%|████▎     | 78/180 [03:06<04:34,  2.70s/it]\u001b[A\n",
            "pearson(r): 0.8208, loss: 0.0290, reg_loss: 0.0000 ||:  44%|████▍     | 79/180 [03:08<04:09,  2.47s/it]\u001b[A\n",
            "pearson(r): 0.8207, loss: 0.0291, reg_loss: 0.0000 ||:  44%|████▍     | 80/180 [03:09<03:43,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.8176, loss: 0.0295, reg_loss: 0.0000 ||:  45%|████▌     | 81/180 [03:16<06:04,  3.68s/it]\u001b[A\n",
            "pearson(r): 0.8182, loss: 0.0293, reg_loss: 0.0000 ||:  46%|████▌     | 82/180 [03:18<05:09,  3.16s/it]\u001b[A\n",
            "pearson(r): 0.8183, loss: 0.0292, reg_loss: 0.0000 ||:  46%|████▌     | 83/180 [03:20<04:28,  2.77s/it]\u001b[A\n",
            "pearson(r): 0.8180, loss: 0.0293, reg_loss: 0.0000 ||:  47%|████▋     | 84/180 [03:22<03:53,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.8180, loss: 0.0293, reg_loss: 0.0000 ||:  47%|████▋     | 85/180 [03:24<03:34,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.8185, loss: 0.0293, reg_loss: 0.0000 ||:  48%|████▊     | 86/180 [03:26<03:21,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.8185, loss: 0.0293, reg_loss: 0.0000 ||:  48%|████▊     | 87/180 [03:27<03:04,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.8180, loss: 0.0293, reg_loss: 0.0000 ||:  49%|████▉     | 88/180 [03:29<02:52,  1.87s/it]\u001b[A\n",
            "pearson(r): 0.8179, loss: 0.0293, reg_loss: 0.0000 ||:  49%|████▉     | 89/180 [03:33<03:45,  2.47s/it]\u001b[A\n",
            "pearson(r): 0.8177, loss: 0.0294, reg_loss: 0.0000 ||:  50%|█████     | 90/180 [03:35<03:33,  2.37s/it]\u001b[A\n",
            "pearson(r): 0.8183, loss: 0.0293, reg_loss: 0.0000 ||:  51%|█████     | 91/180 [03:37<03:15,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.8184, loss: 0.0294, reg_loss: 0.0000 ||:  51%|█████     | 92/180 [03:39<03:08,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.8165, loss: 0.0296, reg_loss: 0.0000 ||:  52%|█████▏    | 93/180 [03:41<02:58,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.8164, loss: 0.0296, reg_loss: 0.0000 ||:  52%|█████▏    | 94/180 [03:43<03:06,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.8178, loss: 0.0296, reg_loss: 0.0000 ||:  53%|█████▎    | 95/180 [03:45<03:11,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.8174, loss: 0.0296, reg_loss: 0.0000 ||:  53%|█████▎    | 96/180 [03:47<03:04,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.8171, loss: 0.0297, reg_loss: 0.0000 ||:  54%|█████▍    | 97/180 [03:49<02:49,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.8165, loss: 0.0298, reg_loss: 0.0000 ||:  54%|█████▍    | 98/180 [03:51<02:45,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.8166, loss: 0.0297, reg_loss: 0.0000 ||:  55%|█████▌    | 99/180 [03:53<02:45,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.8165, loss: 0.0297, reg_loss: 0.0000 ||:  56%|█████▌    | 100/180 [03:55<02:46,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.8159, loss: 0.0297, reg_loss: 0.0000 ||:  56%|█████▌    | 101/180 [03:57<02:40,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.8155, loss: 0.0297, reg_loss: 0.0000 ||:  57%|█████▋    | 102/180 [03:59<02:41,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.8157, loss: 0.0297, reg_loss: 0.0000 ||:  57%|█████▋    | 103/180 [04:01<02:35,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.8154, loss: 0.0298, reg_loss: 0.0000 ||:  58%|█████▊    | 104/180 [04:04<02:42,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.8157, loss: 0.0297, reg_loss: 0.0000 ||:  58%|█████▊    | 105/180 [04:06<02:38,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.8160, loss: 0.0297, reg_loss: 0.0000 ||:  59%|█████▉    | 106/180 [04:08<02:36,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.8156, loss: 0.0297, reg_loss: 0.0000 ||:  59%|█████▉    | 107/180 [04:15<04:11,  3.45s/it]\u001b[A\n",
            "pearson(r): 0.8159, loss: 0.0298, reg_loss: 0.0000 ||:  60%|██████    | 108/180 [04:16<03:34,  2.97s/it]\u001b[A\n",
            "pearson(r): 0.8161, loss: 0.0297, reg_loss: 0.0000 ||:  61%|██████    | 109/180 [04:19<03:23,  2.86s/it]\u001b[A\n",
            "pearson(r): 0.8166, loss: 0.0297, reg_loss: 0.0000 ||:  61%|██████    | 110/180 [04:21<03:02,  2.61s/it]\u001b[A\n",
            "pearson(r): 0.8172, loss: 0.0296, reg_loss: 0.0000 ||:  62%|██████▏   | 111/180 [04:23<02:49,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.8183, loss: 0.0295, reg_loss: 0.0000 ||:  62%|██████▏   | 112/180 [04:25<02:31,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.8186, loss: 0.0295, reg_loss: 0.0000 ||:  63%|██████▎   | 113/180 [04:27<02:26,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.8192, loss: 0.0294, reg_loss: 0.0000 ||:  63%|██████▎   | 114/180 [04:29<02:15,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.8190, loss: 0.0294, reg_loss: 0.0000 ||:  64%|██████▍   | 115/180 [04:31<02:14,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.8187, loss: 0.0295, reg_loss: 0.0000 ||:  64%|██████▍   | 116/180 [04:33<02:09,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.8185, loss: 0.0296, reg_loss: 0.0000 ||:  65%|██████▌   | 117/180 [04:35<02:11,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.8187, loss: 0.0296, reg_loss: 0.0000 ||:  66%|██████▌   | 118/180 [04:37<02:03,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.8194, loss: 0.0296, reg_loss: 0.0000 ||:  66%|██████▌   | 119/180 [04:39<02:02,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.8189, loss: 0.0296, reg_loss: 0.0000 ||:  67%|██████▋   | 120/180 [04:41<01:59,  1.98s/it]\u001b[A\n",
            "pearson(r): 0.8191, loss: 0.0296, reg_loss: 0.0000 ||:  67%|██████▋   | 121/180 [04:42<01:45,  1.78s/it]\u001b[A\n",
            "pearson(r): 0.8185, loss: 0.0297, reg_loss: 0.0000 ||:  68%|██████▊   | 122/180 [04:44<01:45,  1.82s/it]\u001b[A\n",
            "pearson(r): 0.8184, loss: 0.0298, reg_loss: 0.0000 ||:  68%|██████▊   | 123/180 [04:46<01:51,  1.95s/it]\u001b[A\n",
            "pearson(r): 0.8183, loss: 0.0298, reg_loss: 0.0000 ||:  69%|██████▉   | 124/180 [04:48<01:48,  1.93s/it]\u001b[A\n",
            "pearson(r): 0.8178, loss: 0.0299, reg_loss: 0.0000 ||:  69%|██████▉   | 125/180 [04:50<01:49,  2.00s/it]\u001b[A\n",
            "pearson(r): 0.8170, loss: 0.0300, reg_loss: 0.0000 ||:  70%|███████   | 126/180 [04:52<01:45,  1.96s/it]\u001b[A\n",
            "pearson(r): 0.8168, loss: 0.0300, reg_loss: 0.0000 ||:  71%|███████   | 127/180 [04:54<01:50,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.8165, loss: 0.0300, reg_loss: 0.0000 ||:  71%|███████   | 128/180 [04:57<01:57,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.8164, loss: 0.0300, reg_loss: 0.0000 ||:  72%|███████▏  | 129/180 [04:59<01:50,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.8155, loss: 0.0302, reg_loss: 0.0000 ||:  72%|███████▏  | 130/180 [05:01<01:38,  1.98s/it]\u001b[A\n",
            "pearson(r): 0.8156, loss: 0.0301, reg_loss: 0.0000 ||:  73%|███████▎  | 131/180 [05:03<01:41,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.8152, loss: 0.0302, reg_loss: 0.0000 ||:  73%|███████▎  | 132/180 [05:05<01:39,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.8160, loss: 0.0301, reg_loss: 0.0000 ||:  74%|███████▍  | 133/180 [05:07<01:39,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.8146, loss: 0.0303, reg_loss: 0.0000 ||:  74%|███████▍  | 134/180 [05:14<02:39,  3.48s/it]\u001b[A\n",
            "pearson(r): 0.8148, loss: 0.0302, reg_loss: 0.0000 ||:  75%|███████▌  | 135/180 [05:16<02:25,  3.24s/it]\u001b[A\n",
            "pearson(r): 0.8150, loss: 0.0302, reg_loss: 0.0000 ||:  76%|███████▌  | 136/180 [05:19<02:08,  2.93s/it]\u001b[A\n",
            "pearson(r): 0.8148, loss: 0.0302, reg_loss: 0.0000 ||:  76%|███████▌  | 137/180 [05:21<01:55,  2.68s/it]\u001b[A\n",
            "pearson(r): 0.8152, loss: 0.0301, reg_loss: 0.0000 ||:  77%|███████▋  | 138/180 [05:23<01:44,  2.48s/it]\u001b[A\n",
            "pearson(r): 0.8159, loss: 0.0301, reg_loss: 0.0000 ||:  77%|███████▋  | 139/180 [05:26<01:48,  2.66s/it]\u001b[A\n",
            "pearson(r): 0.8155, loss: 0.0301, reg_loss: 0.0000 ||:  78%|███████▊  | 140/180 [05:28<01:34,  2.37s/it]\u001b[A\n",
            "pearson(r): 0.8152, loss: 0.0302, reg_loss: 0.0000 ||:  78%|███████▊  | 141/180 [05:30<01:29,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.8159, loss: 0.0302, reg_loss: 0.0000 ||:  79%|███████▉  | 142/180 [05:32<01:22,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.8158, loss: 0.0302, reg_loss: 0.0000 ||:  79%|███████▉  | 143/180 [05:34<01:19,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.8157, loss: 0.0302, reg_loss: 0.0000 ||:  80%|████████  | 144/180 [05:36<01:14,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.8163, loss: 0.0302, reg_loss: 0.0000 ||:  81%|████████  | 145/180 [05:37<01:10,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.8161, loss: 0.0302, reg_loss: 0.0000 ||:  81%|████████  | 146/180 [05:40<01:18,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.8166, loss: 0.0301, reg_loss: 0.0000 ||:  82%|████████▏ | 147/180 [05:43<01:16,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.8166, loss: 0.0301, reg_loss: 0.0000 ||:  82%|████████▏ | 148/180 [05:46<01:23,  2.62s/it]\u001b[A\n",
            "pearson(r): 0.8167, loss: 0.0301, reg_loss: 0.0000 ||:  83%|████████▎ | 149/180 [05:48<01:15,  2.44s/it]\u001b[A\n",
            "pearson(r): 0.8166, loss: 0.0301, reg_loss: 0.0000 ||:  83%|████████▎ | 150/180 [05:50<01:11,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.8168, loss: 0.0300, reg_loss: 0.0000 ||:  84%|████████▍ | 151/180 [05:52<01:07,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.8169, loss: 0.0300, reg_loss: 0.0000 ||:  84%|████████▍ | 152/180 [05:55<01:02,  2.24s/it]\u001b[A\n",
            "pearson(r): 0.8162, loss: 0.0300, reg_loss: 0.0000 ||:  85%|████████▌ | 153/180 [05:57<00:59,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.8161, loss: 0.0301, reg_loss: 0.0000 ||:  86%|████████▌ | 154/180 [05:59<00:55,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.8162, loss: 0.0301, reg_loss: 0.0000 ||:  86%|████████▌ | 155/180 [06:01<00:51,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.8160, loss: 0.0301, reg_loss: 0.0000 ||:  87%|████████▋ | 156/180 [06:03<00:49,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.8158, loss: 0.0301, reg_loss: 0.0000 ||:  87%|████████▋ | 157/180 [06:07<01:01,  2.68s/it]\u001b[A\n",
            "pearson(r): 0.8161, loss: 0.0301, reg_loss: 0.0000 ||:  88%|████████▊ | 158/180 [06:09<00:53,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.8158, loss: 0.0301, reg_loss: 0.0000 ||:  88%|████████▊ | 159/180 [06:11<00:49,  2.37s/it]\u001b[A\n",
            "pearson(r): 0.8160, loss: 0.0301, reg_loss: 0.0000 ||:  89%|████████▉ | 160/180 [06:13<00:44,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.8163, loss: 0.0301, reg_loss: 0.0000 ||:  89%|████████▉ | 161/180 [06:17<00:53,  2.83s/it]\u001b[A\n",
            "pearson(r): 0.8169, loss: 0.0301, reg_loss: 0.0000 ||:  90%|█████████ | 162/180 [06:19<00:47,  2.63s/it]\u001b[A\n",
            "pearson(r): 0.8169, loss: 0.0302, reg_loss: 0.0000 ||:  91%|█████████ | 163/180 [06:22<00:47,  2.80s/it]\u001b[A\n",
            "pearson(r): 0.8168, loss: 0.0302, reg_loss: 0.0000 ||:  91%|█████████ | 164/180 [06:25<00:42,  2.67s/it]\u001b[A\n",
            "pearson(r): 0.8164, loss: 0.0302, reg_loss: 0.0000 ||:  92%|█████████▏| 165/180 [06:27<00:37,  2.47s/it]\u001b[A\n",
            "pearson(r): 0.8163, loss: 0.0302, reg_loss: 0.0000 ||:  92%|█████████▏| 166/180 [06:28<00:31,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.8164, loss: 0.0302, reg_loss: 0.0000 ||:  93%|█████████▎| 167/180 [06:30<00:26,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.8167, loss: 0.0301, reg_loss: 0.0000 ||:  93%|█████████▎| 168/180 [06:34<00:31,  2.60s/it]\u001b[A\n",
            "pearson(r): 0.8169, loss: 0.0301, reg_loss: 0.0000 ||:  94%|█████████▍| 169/180 [06:36<00:27,  2.47s/it]\u001b[A\n",
            "pearson(r): 0.8160, loss: 0.0302, reg_loss: 0.0000 ||:  94%|█████████▍| 170/180 [06:40<00:28,  2.83s/it]\u001b[A\n",
            "pearson(r): 0.8157, loss: 0.0302, reg_loss: 0.0000 ||:  95%|█████████▌| 171/180 [06:41<00:22,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.8159, loss: 0.0302, reg_loss: 0.0000 ||:  96%|█████████▌| 172/180 [06:44<00:21,  2.63s/it]\u001b[A\n",
            "pearson(r): 0.8160, loss: 0.0303, reg_loss: 0.0000 ||:  96%|█████████▌| 173/180 [06:46<00:17,  2.44s/it]\u001b[A\n",
            "pearson(r): 0.8159, loss: 0.0302, reg_loss: 0.0000 ||:  97%|█████████▋| 174/180 [06:48<00:13,  2.27s/it]\u001b[A\n",
            "pearson(r): 0.8152, loss: 0.0303, reg_loss: 0.0000 ||:  97%|█████████▋| 175/180 [06:51<00:11,  2.31s/it]\u001b[A\n",
            "pearson(r): 0.8151, loss: 0.0303, reg_loss: 0.0000 ||:  98%|█████████▊| 176/180 [06:53<00:08,  2.24s/it]\u001b[A\n",
            "pearson(r): 0.8149, loss: 0.0304, reg_loss: 0.0000 ||:  98%|█████████▊| 177/180 [06:55<00:06,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.8146, loss: 0.0304, reg_loss: 0.0000 ||:  99%|█████████▉| 178/180 [06:56<00:04,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.8147, loss: 0.0303, reg_loss: 0.0000 ||:  99%|█████████▉| 179/180 [06:59<00:02,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.8142, loss: 0.0304, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [07:00<00:00,  2.34s/it]\n",
            "\n",
            "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.7277, loss: 0.0818, reg_loss: 0.0000 ||:   2%|▏         | 1/47 [00:00<00:12,  3.61it/s]\u001b[A\n",
            "pearson(r): 0.7602, loss: 0.0796, reg_loss: 0.0000 ||:   4%|▍         | 2/47 [00:00<00:12,  3.54it/s]\u001b[A\n",
            "pearson(r): 0.7640, loss: 0.0737, reg_loss: 0.0000 ||:   6%|▋         | 3/47 [00:00<00:13,  3.34it/s]\u001b[A\n",
            "pearson(r): 0.7577, loss: 0.0892, reg_loss: 0.0000 ||:   9%|▊         | 4/47 [00:01<00:13,  3.28it/s]\u001b[A\n",
            "pearson(r): 0.7654, loss: 0.0829, reg_loss: 0.0000 ||:  11%|█         | 5/47 [00:01<00:12,  3.43it/s]\u001b[A\n",
            "pearson(r): 0.7612, loss: 0.0807, reg_loss: 0.0000 ||:  13%|█▎        | 6/47 [00:01<00:12,  3.34it/s]\u001b[A\n",
            "pearson(r): 0.7579, loss: 0.0844, reg_loss: 0.0000 ||:  15%|█▍        | 7/47 [00:02<00:12,  3.31it/s]\u001b[A\n",
            "pearson(r): 0.7448, loss: 0.0916, reg_loss: 0.0000 ||:  17%|█▋        | 8/47 [00:02<00:12,  3.10it/s]\u001b[A\n",
            "pearson(r): 0.7391, loss: 0.0925, reg_loss: 0.0000 ||:  19%|█▉        | 9/47 [00:02<00:13,  2.90it/s]\u001b[A\n",
            "pearson(r): 0.7221, loss: 0.0988, reg_loss: 0.0000 ||:  21%|██▏       | 10/47 [00:03<00:13,  2.80it/s]\u001b[A\n",
            "pearson(r): 0.7242, loss: 0.0974, reg_loss: 0.0000 ||:  23%|██▎       | 11/47 [00:03<00:13,  2.64it/s]\u001b[A\n",
            "pearson(r): 0.7258, loss: 0.0966, reg_loss: 0.0000 ||:  26%|██▌       | 12/47 [00:04<00:13,  2.57it/s]\u001b[A\n",
            "pearson(r): 0.7171, loss: 0.0999, reg_loss: 0.0000 ||:  28%|██▊       | 13/47 [00:04<00:13,  2.49it/s]\u001b[A\n",
            "pearson(r): 0.7144, loss: 0.1006, reg_loss: 0.0000 ||:  30%|██▉       | 14/47 [00:04<00:13,  2.48it/s]\u001b[A\n",
            "pearson(r): 0.6976, loss: 0.1078, reg_loss: 0.0000 ||:  32%|███▏      | 15/47 [00:05<00:13,  2.42it/s]\u001b[A\n",
            "pearson(r): 0.6893, loss: 0.1117, reg_loss: 0.0000 ||:  34%|███▍      | 16/47 [00:05<00:12,  2.40it/s]\u001b[A\n",
            "pearson(r): 0.6907, loss: 0.1103, reg_loss: 0.0000 ||:  36%|███▌      | 17/47 [00:06<00:12,  2.35it/s]\u001b[A\n",
            "pearson(r): 0.6863, loss: 0.1123, reg_loss: 0.0000 ||:  38%|███▊      | 18/47 [00:06<00:12,  2.37it/s]\u001b[A\n",
            "pearson(r): 0.6849, loss: 0.1132, reg_loss: 0.0000 ||:  40%|████      | 19/47 [00:07<00:11,  2.36it/s]\u001b[A\n",
            "pearson(r): 0.6657, loss: 0.1179, reg_loss: 0.0000 ||:  43%|████▎     | 20/47 [00:07<00:12,  2.18it/s]\u001b[A\n",
            "pearson(r): 0.6558, loss: 0.1216, reg_loss: 0.0000 ||:  45%|████▍     | 21/47 [00:08<00:12,  2.03it/s]\u001b[A\n",
            "pearson(r): 0.6376, loss: 0.1270, reg_loss: 0.0000 ||:  47%|████▋     | 22/47 [00:08<00:12,  1.93it/s]\u001b[A\n",
            "pearson(r): 0.6294, loss: 0.1289, reg_loss: 0.0000 ||:  49%|████▉     | 23/47 [00:09<00:13,  1.84it/s]\u001b[A\n",
            "pearson(r): 0.6119, loss: 0.1339, reg_loss: 0.0000 ||:  51%|█████     | 24/47 [00:10<00:13,  1.76it/s]\u001b[A\n",
            "pearson(r): 0.5913, loss: 0.1396, reg_loss: 0.0000 ||:  53%|█████▎    | 25/47 [00:10<00:12,  1.74it/s]\u001b[A\n",
            "pearson(r): 0.5838, loss: 0.1407, reg_loss: 0.0000 ||:  55%|█████▌    | 26/47 [00:11<00:11,  1.78it/s]\u001b[A\n",
            "pearson(r): 0.5674, loss: 0.1441, reg_loss: 0.0000 ||:  57%|█████▋    | 27/47 [00:11<00:11,  1.78it/s]\u001b[A\n",
            "pearson(r): 0.5613, loss: 0.1448, reg_loss: 0.0000 ||:  60%|█████▉    | 28/47 [00:12<00:10,  1.73it/s]\u001b[A\n",
            "pearson(r): 0.5497, loss: 0.1495, reg_loss: 0.0000 ||:  62%|██████▏   | 29/47 [00:12<00:10,  1.77it/s]\u001b[A\n",
            "pearson(r): 0.5406, loss: 0.1522, reg_loss: 0.0000 ||:  64%|██████▍   | 30/47 [00:13<00:09,  1.77it/s]\u001b[A\n",
            "pearson(r): 0.5337, loss: 0.1549, reg_loss: 0.0000 ||:  66%|██████▌   | 31/47 [00:13<00:08,  1.80it/s]\u001b[A\n",
            "pearson(r): 0.5397, loss: 0.1530, reg_loss: 0.0000 ||:  68%|██████▊   | 32/47 [00:14<00:08,  1.69it/s]\u001b[A\n",
            "pearson(r): 0.5493, loss: 0.1503, reg_loss: 0.0000 ||:  70%|███████   | 33/47 [00:15<00:08,  1.63it/s]\u001b[A\n",
            "pearson(r): 0.5561, loss: 0.1473, reg_loss: 0.0000 ||:  72%|███████▏  | 34/47 [00:15<00:08,  1.58it/s]\u001b[A\n",
            "pearson(r): 0.5602, loss: 0.1451, reg_loss: 0.0000 ||:  74%|███████▍  | 35/47 [00:16<00:08,  1.47it/s]\u001b[A\n",
            "pearson(r): 0.5639, loss: 0.1434, reg_loss: 0.0000 ||:  77%|███████▋  | 36/47 [00:17<00:07,  1.47it/s]\u001b[A\n",
            "pearson(r): 0.5668, loss: 0.1418, reg_loss: 0.0000 ||:  79%|███████▊  | 37/47 [00:18<00:06,  1.48it/s]\u001b[A\n",
            "pearson(r): 0.5698, loss: 0.1400, reg_loss: 0.0000 ||:  81%|████████  | 38/47 [00:18<00:06,  1.47it/s]\u001b[A\n",
            "pearson(r): 0.5747, loss: 0.1379, reg_loss: 0.0000 ||:  83%|████████▎ | 39/47 [00:19<00:05,  1.45it/s]\u001b[A\n",
            "pearson(r): 0.5723, loss: 0.1383, reg_loss: 0.0000 ||:  85%|████████▌ | 40/47 [00:19<00:04,  1.64it/s]\u001b[A\n",
            "pearson(r): 0.5728, loss: 0.1373, reg_loss: 0.0000 ||:  87%|████████▋ | 41/47 [00:20<00:03,  1.87it/s]\u001b[A\n",
            "pearson(r): 0.5757, loss: 0.1372, reg_loss: 0.0000 ||:  89%|████████▉ | 42/47 [00:20<00:02,  2.16it/s]\u001b[A\n",
            "pearson(r): 0.5765, loss: 0.1379, reg_loss: 0.0000 ||:  91%|█████████▏| 43/47 [00:20<00:01,  2.35it/s]\u001b[A\n",
            "pearson(r): 0.5757, loss: 0.1375, reg_loss: 0.0000 ||:  94%|█████████▎| 44/47 [00:21<00:01,  2.48it/s]\u001b[A\n",
            "pearson(r): 0.5704, loss: 0.1390, reg_loss: 0.0000 ||:  96%|█████████▌| 45/47 [00:21<00:00,  2.64it/s]\u001b[A\n",
            "pearson(r): 0.5730, loss: 0.1396, reg_loss: 0.0000 ||:  98%|█████████▊| 46/47 [00:21<00:00,  2.66it/s]\u001b[A\n",
            "pearson(r): 0.5681, loss: 0.1405, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:22<00:00,  2.11it/s]\n",
            "\n",
            "  0%|          | 0/180 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.8046, loss: 0.0231, reg_loss: 0.0000 ||:   1%|          | 1/180 [00:02<06:31,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.8174, loss: 0.0241, reg_loss: 0.0000 ||:   1%|          | 2/180 [00:03<06:07,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.8367, loss: 0.0259, reg_loss: 0.0000 ||:   2%|▏         | 3/180 [00:06<06:05,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.8415, loss: 0.0259, reg_loss: 0.0000 ||:   2%|▏         | 4/180 [00:08<06:06,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.8291, loss: 0.0245, reg_loss: 0.0000 ||:   3%|▎         | 5/180 [00:11<06:45,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.8214, loss: 0.0241, reg_loss: 0.0000 ||:   3%|▎         | 6/180 [00:18<11:12,  3.86s/it]\u001b[A\n",
            "pearson(r): 0.8299, loss: 0.0235, reg_loss: 0.0000 ||:   4%|▍         | 7/180 [00:21<10:27,  3.62s/it]\u001b[A\n",
            "pearson(r): 0.8435, loss: 0.0227, reg_loss: 0.0000 ||:   4%|▍         | 8/180 [00:23<09:06,  3.18s/it]\u001b[A\n",
            "pearson(r): 0.8412, loss: 0.0241, reg_loss: 0.0000 ||:   5%|▌         | 9/180 [00:25<08:02,  2.82s/it]\u001b[A\n",
            "pearson(r): 0.8431, loss: 0.0244, reg_loss: 0.0000 ||:   6%|▌         | 10/180 [00:28<07:52,  2.78s/it]\u001b[A\n",
            "pearson(r): 0.8464, loss: 0.0239, reg_loss: 0.0000 ||:   6%|▌         | 11/180 [00:30<07:04,  2.51s/it]\u001b[A\n",
            "pearson(r): 0.8459, loss: 0.0237, reg_loss: 0.0000 ||:   7%|▋         | 12/180 [00:32<06:34,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.8477, loss: 0.0237, reg_loss: 0.0000 ||:   7%|▋         | 13/180 [00:33<06:02,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.8412, loss: 0.0243, reg_loss: 0.0000 ||:   8%|▊         | 14/180 [00:36<05:58,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.8425, loss: 0.0241, reg_loss: 0.0000 ||:   8%|▊         | 15/180 [00:38<05:52,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.8405, loss: 0.0252, reg_loss: 0.0000 ||:   9%|▉         | 16/180 [00:41<06:28,  2.37s/it]\u001b[A\n",
            "pearson(r): 0.8428, loss: 0.0252, reg_loss: 0.0000 ||:   9%|▉         | 17/180 [00:43<06:26,  2.37s/it]\u001b[A\n",
            "pearson(r): 0.8450, loss: 0.0251, reg_loss: 0.0000 ||:  10%|█         | 18/180 [00:45<06:24,  2.37s/it]\u001b[A\n",
            "pearson(r): 0.8430, loss: 0.0252, reg_loss: 0.0000 ||:  11%|█         | 19/180 [00:48<06:15,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.8432, loss: 0.0255, reg_loss: 0.0000 ||:  11%|█         | 20/180 [00:50<05:59,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.8455, loss: 0.0251, reg_loss: 0.0000 ||:  12%|█▏        | 21/180 [00:51<05:34,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.8469, loss: 0.0247, reg_loss: 0.0000 ||:  12%|█▏        | 22/180 [00:54<05:37,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.8379, loss: 0.0259, reg_loss: 0.0000 ||:  13%|█▎        | 23/180 [01:01<09:25,  3.60s/it]\u001b[A\n",
            "pearson(r): 0.8413, loss: 0.0257, reg_loss: 0.0000 ||:  13%|█▎        | 24/180 [01:02<07:57,  3.06s/it]\u001b[A\n",
            "pearson(r): 0.8420, loss: 0.0257, reg_loss: 0.0000 ||:  14%|█▍        | 25/180 [01:04<07:02,  2.72s/it]\u001b[A\n",
            "pearson(r): 0.8404, loss: 0.0261, reg_loss: 0.0000 ||:  14%|█▍        | 26/180 [01:07<06:36,  2.58s/it]\u001b[A\n",
            "pearson(r): 0.8402, loss: 0.0260, reg_loss: 0.0000 ||:  15%|█▌        | 27/180 [01:10<07:22,  2.89s/it]\u001b[A\n",
            "pearson(r): 0.8421, loss: 0.0258, reg_loss: 0.0000 ||:  16%|█▌        | 28/180 [01:12<06:37,  2.61s/it]\u001b[A\n",
            "pearson(r): 0.8428, loss: 0.0257, reg_loss: 0.0000 ||:  16%|█▌        | 29/180 [01:14<06:09,  2.45s/it]\u001b[A\n",
            "pearson(r): 0.8441, loss: 0.0257, reg_loss: 0.0000 ||:  17%|█▋        | 30/180 [01:17<06:19,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.8439, loss: 0.0256, reg_loss: 0.0000 ||:  17%|█▋        | 31/180 [01:19<05:46,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.8461, loss: 0.0255, reg_loss: 0.0000 ||:  18%|█▊        | 32/180 [01:21<05:28,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.8398, loss: 0.0261, reg_loss: 0.0000 ||:  18%|█▊        | 33/180 [01:27<08:38,  3.53s/it]\u001b[A\n",
            "pearson(r): 0.8408, loss: 0.0260, reg_loss: 0.0000 ||:  19%|█▉        | 34/180 [01:30<07:37,  3.13s/it]\u001b[A\n",
            "pearson(r): 0.8407, loss: 0.0259, reg_loss: 0.0000 ||:  19%|█▉        | 35/180 [01:32<06:43,  2.78s/it]\u001b[A\n",
            "pearson(r): 0.8403, loss: 0.0258, reg_loss: 0.0000 ||:  20%|██        | 36/180 [01:33<05:49,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.8419, loss: 0.0256, reg_loss: 0.0000 ||:  21%|██        | 37/180 [01:36<05:53,  2.47s/it]\u001b[A\n",
            "pearson(r): 0.8425, loss: 0.0259, reg_loss: 0.0000 ||:  21%|██        | 38/180 [01:37<05:19,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.8404, loss: 0.0261, reg_loss: 0.0000 ||:  22%|██▏       | 39/180 [01:39<04:58,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.8387, loss: 0.0262, reg_loss: 0.0000 ||:  22%|██▏       | 40/180 [01:41<04:48,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.8376, loss: 0.0261, reg_loss: 0.0000 ||:  23%|██▎       | 41/180 [01:44<05:00,  2.17s/it]\u001b[A\n",
            "pearson(r): 0.8360, loss: 0.0265, reg_loss: 0.0000 ||:  23%|██▎       | 42/180 [01:45<04:46,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.8367, loss: 0.0263, reg_loss: 0.0000 ||:  24%|██▍       | 43/180 [01:47<04:35,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.8378, loss: 0.0262, reg_loss: 0.0000 ||:  24%|██▍       | 44/180 [01:50<04:53,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.8374, loss: 0.0261, reg_loss: 0.0000 ||:  25%|██▌       | 45/180 [01:52<04:45,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.8383, loss: 0.0260, reg_loss: 0.0000 ||:  26%|██▌       | 46/180 [01:54<04:44,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.8372, loss: 0.0260, reg_loss: 0.0000 ||:  26%|██▌       | 47/180 [01:56<04:20,  1.96s/it]\u001b[A\n",
            "pearson(r): 0.8378, loss: 0.0259, reg_loss: 0.0000 ||:  27%|██▋       | 48/180 [01:57<04:15,  1.93s/it]\u001b[A\n",
            "pearson(r): 0.8373, loss: 0.0258, reg_loss: 0.0000 ||:  27%|██▋       | 49/180 [01:59<04:14,  1.94s/it]\u001b[A\n",
            "pearson(r): 0.8369, loss: 0.0260, reg_loss: 0.0000 ||:  28%|██▊       | 50/180 [02:02<04:46,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.8367, loss: 0.0260, reg_loss: 0.0000 ||:  28%|██▊       | 51/180 [02:05<05:07,  2.38s/it]\u001b[A\n",
            "pearson(r): 0.8367, loss: 0.0261, reg_loss: 0.0000 ||:  29%|██▉       | 52/180 [02:07<05:08,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.8368, loss: 0.0264, reg_loss: 0.0000 ||:  29%|██▉       | 53/180 [02:09<04:28,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.8373, loss: 0.0264, reg_loss: 0.0000 ||:  30%|███       | 54/180 [02:11<04:22,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.8371, loss: 0.0264, reg_loss: 0.0000 ||:  31%|███       | 55/180 [02:13<04:12,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.8383, loss: 0.0262, reg_loss: 0.0000 ||:  31%|███       | 56/180 [02:15<04:09,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.8390, loss: 0.0260, reg_loss: 0.0000 ||:  32%|███▏      | 57/180 [02:17<04:13,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.8403, loss: 0.0259, reg_loss: 0.0000 ||:  32%|███▏      | 58/180 [02:19<04:11,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.8409, loss: 0.0258, reg_loss: 0.0000 ||:  33%|███▎      | 59/180 [02:21<04:08,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.8425, loss: 0.0257, reg_loss: 0.0000 ||:  33%|███▎      | 60/180 [02:23<04:11,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.8442, loss: 0.0257, reg_loss: 0.0000 ||:  34%|███▍      | 61/180 [02:25<04:01,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.8450, loss: 0.0256, reg_loss: 0.0000 ||:  34%|███▍      | 62/180 [02:28<04:26,  2.26s/it]\u001b[A\n",
            "pearson(r): 0.8452, loss: 0.0256, reg_loss: 0.0000 ||:  35%|███▌      | 63/180 [02:31<04:43,  2.42s/it]\u001b[A\n",
            "pearson(r): 0.8456, loss: 0.0255, reg_loss: 0.0000 ||:  36%|███▌      | 64/180 [02:34<04:58,  2.58s/it]\u001b[A\n",
            "pearson(r): 0.8454, loss: 0.0255, reg_loss: 0.0000 ||:  36%|███▌      | 65/180 [02:36<04:44,  2.47s/it]\u001b[A\n",
            "pearson(r): 0.8471, loss: 0.0254, reg_loss: 0.0000 ||:  37%|███▋      | 66/180 [02:37<04:11,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.8465, loss: 0.0255, reg_loss: 0.0000 ||:  37%|███▋      | 67/180 [02:40<04:09,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.8453, loss: 0.0255, reg_loss: 0.0000 ||:  38%|███▊      | 68/180 [02:42<04:03,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.8445, loss: 0.0256, reg_loss: 0.0000 ||:  38%|███▊      | 69/180 [02:47<05:46,  3.13s/it]\u001b[A\n",
            "pearson(r): 0.8448, loss: 0.0257, reg_loss: 0.0000 ||:  39%|███▉      | 70/180 [02:50<05:30,  3.00s/it]\u001b[A\n",
            "pearson(r): 0.8421, loss: 0.0261, reg_loss: 0.0000 ||:  39%|███▉      | 71/180 [02:54<05:54,  3.25s/it]\u001b[A\n",
            "pearson(r): 0.8426, loss: 0.0260, reg_loss: 0.0000 ||:  40%|████      | 72/180 [02:55<05:03,  2.81s/it]\u001b[A\n",
            "pearson(r): 0.8407, loss: 0.0263, reg_loss: 0.0000 ||:  41%|████      | 73/180 [03:00<05:44,  3.22s/it]\u001b[A\n",
            "pearson(r): 0.8410, loss: 0.0264, reg_loss: 0.0000 ||:  41%|████      | 74/180 [03:01<04:50,  2.74s/it]\u001b[A\n",
            "pearson(r): 0.8406, loss: 0.0264, reg_loss: 0.0000 ||:  42%|████▏     | 75/180 [03:03<04:21,  2.49s/it]\u001b[A\n",
            "pearson(r): 0.8395, loss: 0.0265, reg_loss: 0.0000 ||:  42%|████▏     | 76/180 [03:05<04:02,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.8392, loss: 0.0265, reg_loss: 0.0000 ||:  43%|████▎     | 77/180 [03:08<04:13,  2.46s/it]\u001b[A\n",
            "pearson(r): 0.8376, loss: 0.0267, reg_loss: 0.0000 ||:  43%|████▎     | 78/180 [03:12<04:47,  2.82s/it]\u001b[A\n",
            "pearson(r): 0.8373, loss: 0.0267, reg_loss: 0.0000 ||:  44%|████▍     | 79/180 [03:13<04:05,  2.43s/it]\u001b[A\n",
            "pearson(r): 0.8374, loss: 0.0267, reg_loss: 0.0000 ||:  44%|████▍     | 80/180 [03:15<03:53,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.8369, loss: 0.0269, reg_loss: 0.0000 ||:  45%|████▌     | 81/180 [03:18<04:16,  2.59s/it]\u001b[A\n",
            "pearson(r): 0.8375, loss: 0.0269, reg_loss: 0.0000 ||:  46%|████▌     | 82/180 [03:20<03:50,  2.35s/it]\u001b[A\n",
            "pearson(r): 0.8372, loss: 0.0270, reg_loss: 0.0000 ||:  46%|████▌     | 83/180 [03:22<03:42,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.8374, loss: 0.0270, reg_loss: 0.0000 ||:  47%|████▋     | 84/180 [03:24<03:29,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.8366, loss: 0.0270, reg_loss: 0.0000 ||:  47%|████▋     | 85/180 [03:28<04:13,  2.66s/it]\u001b[A\n",
            "pearson(r): 0.8360, loss: 0.0270, reg_loss: 0.0000 ||:  48%|████▊     | 86/180 [03:30<03:38,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.8360, loss: 0.0269, reg_loss: 0.0000 ||:  48%|████▊     | 87/180 [03:32<03:53,  2.51s/it]\u001b[A\n",
            "pearson(r): 0.8360, loss: 0.0269, reg_loss: 0.0000 ||:  49%|████▉     | 88/180 [03:35<03:40,  2.40s/it]\u001b[A\n",
            "pearson(r): 0.8361, loss: 0.0268, reg_loss: 0.0000 ||:  49%|████▉     | 89/180 [03:41<05:33,  3.67s/it]\u001b[A\n",
            "pearson(r): 0.8362, loss: 0.0268, reg_loss: 0.0000 ||:  50%|█████     | 90/180 [03:44<04:56,  3.29s/it]\u001b[A\n",
            "pearson(r): 0.8350, loss: 0.0268, reg_loss: 0.0000 ||:  51%|█████     | 91/180 [03:46<04:23,  2.96s/it]\u001b[A\n",
            "pearson(r): 0.8352, loss: 0.0268, reg_loss: 0.0000 ||:  51%|█████     | 92/180 [03:48<03:57,  2.70s/it]\u001b[A\n",
            "pearson(r): 0.8355, loss: 0.0267, reg_loss: 0.0000 ||:  52%|█████▏    | 93/180 [03:50<03:39,  2.52s/it]\u001b[A\n",
            "pearson(r): 0.8361, loss: 0.0267, reg_loss: 0.0000 ||:  52%|█████▏    | 94/180 [03:52<03:25,  2.39s/it]\u001b[A\n",
            "pearson(r): 0.8368, loss: 0.0266, reg_loss: 0.0000 ||:  53%|█████▎    | 95/180 [03:54<03:11,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.8370, loss: 0.0266, reg_loss: 0.0000 ||:  53%|█████▎    | 96/180 [03:56<02:51,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.8371, loss: 0.0265, reg_loss: 0.0000 ||:  54%|█████▍    | 97/180 [03:58<03:00,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.8370, loss: 0.0266, reg_loss: 0.0000 ||:  54%|█████▍    | 98/180 [04:00<02:50,  2.08s/it]\u001b[A\n",
            "pearson(r): 0.8368, loss: 0.0266, reg_loss: 0.0000 ||:  55%|█████▌    | 99/180 [04:02<02:47,  2.07s/it]\u001b[A\n",
            "pearson(r): 0.8357, loss: 0.0266, reg_loss: 0.0000 ||:  56%|█████▌    | 100/180 [04:05<03:06,  2.33s/it]\u001b[A\n",
            "pearson(r): 0.8354, loss: 0.0267, reg_loss: 0.0000 ||:  56%|█████▌    | 101/180 [04:07<03:01,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.8352, loss: 0.0268, reg_loss: 0.0000 ||:  57%|█████▋    | 102/180 [04:09<02:52,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.8352, loss: 0.0267, reg_loss: 0.0000 ||:  57%|█████▋    | 103/180 [04:11<02:50,  2.22s/it]\u001b[A\n",
            "pearson(r): 0.8357, loss: 0.0267, reg_loss: 0.0000 ||:  58%|█████▊    | 104/180 [04:14<02:49,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.8355, loss: 0.0268, reg_loss: 0.0000 ||:  58%|█████▊    | 105/180 [04:16<02:51,  2.28s/it]\u001b[A\n",
            "pearson(r): 0.8354, loss: 0.0268, reg_loss: 0.0000 ||:  59%|█████▉    | 106/180 [04:21<03:40,  2.98s/it]\u001b[A\n",
            "pearson(r): 0.8352, loss: 0.0268, reg_loss: 0.0000 ||:  59%|█████▉    | 107/180 [04:23<03:13,  2.65s/it]\u001b[A\n",
            "pearson(r): 0.8350, loss: 0.0269, reg_loss: 0.0000 ||:  60%|██████    | 108/180 [04:24<02:53,  2.41s/it]\u001b[A\n",
            "pearson(r): 0.8356, loss: 0.0269, reg_loss: 0.0000 ||:  61%|██████    | 109/180 [04:26<02:39,  2.25s/it]\u001b[A\n",
            "pearson(r): 0.8361, loss: 0.0268, reg_loss: 0.0000 ||:  61%|██████    | 110/180 [04:29<02:43,  2.34s/it]\u001b[A\n",
            "pearson(r): 0.8356, loss: 0.0268, reg_loss: 0.0000 ||:  62%|██████▏   | 111/180 [04:31<02:33,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.8358, loss: 0.0268, reg_loss: 0.0000 ||:  62%|██████▏   | 112/180 [04:33<02:25,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.8353, loss: 0.0269, reg_loss: 0.0000 ||:  63%|██████▎   | 113/180 [04:35<02:20,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.8353, loss: 0.0269, reg_loss: 0.0000 ||:  63%|██████▎   | 114/180 [04:37<02:25,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.8353, loss: 0.0270, reg_loss: 0.0000 ||:  64%|██████▍   | 115/180 [04:39<02:22,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.8347, loss: 0.0270, reg_loss: 0.0000 ||:  64%|██████▍   | 116/180 [04:42<02:20,  2.19s/it]\u001b[A\n",
            "pearson(r): 0.8354, loss: 0.0270, reg_loss: 0.0000 ||:  65%|██████▌   | 117/180 [04:44<02:13,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.8352, loss: 0.0271, reg_loss: 0.0000 ||:  66%|██████▌   | 118/180 [04:45<02:07,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.8334, loss: 0.0273, reg_loss: 0.0000 ||:  66%|██████▌   | 119/180 [04:49<02:36,  2.56s/it]\u001b[A\n",
            "pearson(r): 0.8329, loss: 0.0274, reg_loss: 0.0000 ||:  67%|██████▋   | 120/180 [04:51<02:25,  2.42s/it]\u001b[A\n",
            "pearson(r): 0.8323, loss: 0.0275, reg_loss: 0.0000 ||:  67%|██████▋   | 121/180 [04:53<02:09,  2.20s/it]\u001b[A\n",
            "pearson(r): 0.8323, loss: 0.0275, reg_loss: 0.0000 ||:  68%|██████▊   | 122/180 [04:55<02:08,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.8328, loss: 0.0275, reg_loss: 0.0000 ||:  68%|██████▊   | 123/180 [04:57<01:54,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.8330, loss: 0.0275, reg_loss: 0.0000 ||:  69%|██████▉   | 124/180 [04:59<01:54,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.8337, loss: 0.0275, reg_loss: 0.0000 ||:  69%|██████▉   | 125/180 [05:01<01:53,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.8331, loss: 0.0275, reg_loss: 0.0000 ||:  70%|███████   | 126/180 [05:03<01:50,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.8330, loss: 0.0276, reg_loss: 0.0000 ||:  71%|███████   | 127/180 [05:05<01:50,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.8322, loss: 0.0277, reg_loss: 0.0000 ||:  71%|███████   | 128/180 [05:07<01:50,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.8320, loss: 0.0277, reg_loss: 0.0000 ||:  72%|███████▏  | 129/180 [05:10<01:56,  2.29s/it]\u001b[A\n",
            "pearson(r): 0.8321, loss: 0.0276, reg_loss: 0.0000 ||:  72%|███████▏  | 130/180 [05:12<01:47,  2.14s/it]\u001b[A\n",
            "pearson(r): 0.8321, loss: 0.0276, reg_loss: 0.0000 ||:  73%|███████▎  | 131/180 [05:14<01:43,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.8317, loss: 0.0276, reg_loss: 0.0000 ||:  73%|███████▎  | 132/180 [05:16<01:43,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.8318, loss: 0.0277, reg_loss: 0.0000 ||:  74%|███████▍  | 133/180 [05:18<01:36,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.8323, loss: 0.0276, reg_loss: 0.0000 ||:  74%|███████▍  | 134/180 [05:20<01:37,  2.11s/it]\u001b[A\n",
            "pearson(r): 0.8313, loss: 0.0278, reg_loss: 0.0000 ||:  75%|███████▌  | 135/180 [05:22<01:36,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.8314, loss: 0.0277, reg_loss: 0.0000 ||:  76%|███████▌  | 136/180 [05:24<01:27,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.8315, loss: 0.0276, reg_loss: 0.0000 ||:  76%|███████▌  | 137/180 [05:26<01:23,  1.94s/it]\u001b[A\n",
            "pearson(r): 0.8318, loss: 0.0276, reg_loss: 0.0000 ||:  77%|███████▋  | 138/180 [05:28<01:19,  1.90s/it]\u001b[A\n",
            "pearson(r): 0.8320, loss: 0.0276, reg_loss: 0.0000 ||:  77%|███████▋  | 139/180 [05:30<01:23,  2.03s/it]\u001b[A\n",
            "pearson(r): 0.8310, loss: 0.0277, reg_loss: 0.0000 ||:  78%|███████▊  | 140/180 [05:32<01:20,  2.01s/it]\u001b[A\n",
            "pearson(r): 0.8304, loss: 0.0278, reg_loss: 0.0000 ||:  78%|███████▊  | 141/180 [05:36<01:43,  2.64s/it]\u001b[A\n",
            "pearson(r): 0.8303, loss: 0.0278, reg_loss: 0.0000 ||:  79%|███████▉  | 142/180 [05:38<01:33,  2.47s/it]\u001b[A\n",
            "pearson(r): 0.8298, loss: 0.0278, reg_loss: 0.0000 ||:  79%|███████▉  | 143/180 [05:41<01:30,  2.45s/it]\u001b[A\n",
            "pearson(r): 0.8298, loss: 0.0278, reg_loss: 0.0000 ||:  80%|████████  | 144/180 [05:43<01:29,  2.49s/it]\u001b[A\n",
            "pearson(r): 0.8296, loss: 0.0278, reg_loss: 0.0000 ||:  81%|████████  | 145/180 [05:45<01:21,  2.32s/it]\u001b[A\n",
            "pearson(r): 0.8298, loss: 0.0279, reg_loss: 0.0000 ||:  81%|████████  | 146/180 [05:47<01:20,  2.36s/it]\u001b[A\n",
            "pearson(r): 0.8298, loss: 0.0280, reg_loss: 0.0000 ||:  82%|████████▏ | 147/180 [05:49<01:12,  2.18s/it]\u001b[A\n",
            "pearson(r): 0.8301, loss: 0.0280, reg_loss: 0.0000 ||:  82%|████████▏ | 148/180 [05:51<01:08,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.8297, loss: 0.0280, reg_loss: 0.0000 ||:  83%|████████▎ | 149/180 [05:53<01:05,  2.10s/it]\u001b[A\n",
            "pearson(r): 0.8294, loss: 0.0281, reg_loss: 0.0000 ||:  83%|████████▎ | 150/180 [05:55<00:59,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.8287, loss: 0.0281, reg_loss: 0.0000 ||:  84%|████████▍ | 151/180 [05:57<00:56,  1.93s/it]\u001b[A\n",
            "pearson(r): 0.8284, loss: 0.0281, reg_loss: 0.0000 ||:  84%|████████▍ | 152/180 [05:58<00:51,  1.83s/it]\u001b[A\n",
            "pearson(r): 0.8283, loss: 0.0281, reg_loss: 0.0000 ||:  85%|████████▌ | 153/180 [06:00<00:51,  1.90s/it]\u001b[A\n",
            "pearson(r): 0.8283, loss: 0.0282, reg_loss: 0.0000 ||:  86%|████████▌ | 154/180 [06:03<00:50,  1.95s/it]\u001b[A\n",
            "pearson(r): 0.8285, loss: 0.0282, reg_loss: 0.0000 ||:  86%|████████▌ | 155/180 [06:05<00:50,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.8284, loss: 0.0282, reg_loss: 0.0000 ||:  87%|████████▋ | 156/180 [06:07<00:49,  2.04s/it]\u001b[A\n",
            "pearson(r): 0.8270, loss: 0.0284, reg_loss: 0.0000 ||:  87%|████████▋ | 157/180 [06:10<00:58,  2.53s/it]\u001b[A\n",
            "pearson(r): 0.8269, loss: 0.0284, reg_loss: 0.0000 ||:  88%|████████▊ | 158/180 [06:13<00:52,  2.40s/it]\u001b[A\n",
            "pearson(r): 0.8264, loss: 0.0285, reg_loss: 0.0000 ||:  88%|████████▊ | 159/180 [06:14<00:47,  2.24s/it]\u001b[A\n",
            "pearson(r): 0.8263, loss: 0.0285, reg_loss: 0.0000 ||:  89%|████████▉ | 160/180 [06:16<00:42,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.8263, loss: 0.0285, reg_loss: 0.0000 ||:  89%|████████▉ | 161/180 [06:18<00:40,  2.13s/it]\u001b[A\n",
            "pearson(r): 0.8261, loss: 0.0285, reg_loss: 0.0000 ||:  90%|█████████ | 162/180 [06:20<00:35,  1.99s/it]\u001b[A\n",
            "pearson(r): 0.8262, loss: 0.0285, reg_loss: 0.0000 ||:  91%|█████████ | 163/180 [06:22<00:32,  1.91s/it]\u001b[A\n",
            "pearson(r): 0.8264, loss: 0.0285, reg_loss: 0.0000 ||:  91%|█████████ | 164/180 [06:24<00:33,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.8261, loss: 0.0285, reg_loss: 0.0000 ||:  92%|█████████▏| 165/180 [06:26<00:30,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.8257, loss: 0.0285, reg_loss: 0.0000 ||:  92%|█████████▏| 166/180 [06:28<00:28,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.8258, loss: 0.0286, reg_loss: 0.0000 ||:  93%|█████████▎| 167/180 [06:30<00:26,  2.05s/it]\u001b[A\n",
            "pearson(r): 0.8261, loss: 0.0286, reg_loss: 0.0000 ||:  93%|█████████▎| 168/180 [06:32<00:23,  1.95s/it]\u001b[A\n",
            "pearson(r): 0.8262, loss: 0.0285, reg_loss: 0.0000 ||:  94%|█████████▍| 169/180 [06:34<00:21,  1.97s/it]\u001b[A\n",
            "pearson(r): 0.8256, loss: 0.0286, reg_loss: 0.0000 ||:  94%|█████████▍| 170/180 [06:36<00:19,  1.93s/it]\u001b[A\n",
            "pearson(r): 0.8260, loss: 0.0285, reg_loss: 0.0000 ||:  95%|█████████▌| 171/180 [06:38<00:17,  1.98s/it]\u001b[A\n",
            "pearson(r): 0.8260, loss: 0.0285, reg_loss: 0.0000 ||:  96%|█████████▌| 172/180 [06:40<00:16,  2.06s/it]\u001b[A\n",
            "pearson(r): 0.8260, loss: 0.0286, reg_loss: 0.0000 ||:  96%|█████████▌| 173/180 [06:43<00:15,  2.23s/it]\u001b[A\n",
            "pearson(r): 0.8254, loss: 0.0286, reg_loss: 0.0000 ||:  97%|█████████▋| 174/180 [06:45<00:12,  2.16s/it]\u001b[A\n",
            "pearson(r): 0.8253, loss: 0.0286, reg_loss: 0.0000 ||:  97%|█████████▋| 175/180 [06:47<00:11,  2.21s/it]\u001b[A\n",
            "pearson(r): 0.8249, loss: 0.0287, reg_loss: 0.0000 ||:  98%|█████████▊| 176/180 [06:49<00:08,  2.15s/it]\u001b[A\n",
            "pearson(r): 0.8247, loss: 0.0287, reg_loss: 0.0000 ||:  98%|█████████▊| 177/180 [06:51<00:06,  2.12s/it]\u001b[A\n",
            "pearson(r): 0.8251, loss: 0.0287, reg_loss: 0.0000 ||:  99%|█████████▉| 178/180 [06:53<00:04,  2.02s/it]\u001b[A\n",
            "pearson(r): 0.8252, loss: 0.0286, reg_loss: 0.0000 ||:  99%|█████████▉| 179/180 [06:55<00:02,  2.09s/it]\u001b[A\n",
            "pearson(r): 0.8252, loss: 0.0287, reg_loss: 0.0000 ||: 100%|██████████| 180/180 [06:57<00:00,  2.32s/it]\n",
            "\n",
            "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A\n",
            "pearson(r): 0.7036, loss: 0.0847, reg_loss: 0.0000 ||:   2%|▏         | 1/47 [00:00<00:12,  3.62it/s]\u001b[A\n",
            "pearson(r): 0.7503, loss: 0.0803, reg_loss: 0.0000 ||:   4%|▍         | 2/47 [00:00<00:12,  3.54it/s]\u001b[A\n",
            "pearson(r): 0.7267, loss: 0.0787, reg_loss: 0.0000 ||:   6%|▋         | 3/47 [00:00<00:13,  3.36it/s]\u001b[A\n",
            "pearson(r): 0.7225, loss: 0.0933, reg_loss: 0.0000 ||:   9%|▊         | 4/47 [00:01<00:12,  3.31it/s]\u001b[A\n",
            "pearson(r): 0.7265, loss: 0.0896, reg_loss: 0.0000 ||:  11%|█         | 5/47 [00:01<00:12,  3.45it/s]\u001b[A\n",
            "pearson(r): 0.7245, loss: 0.0864, reg_loss: 0.0000 ||:  13%|█▎        | 6/47 [00:01<00:12,  3.33it/s]\u001b[A\n",
            "pearson(r): 0.7237, loss: 0.0884, reg_loss: 0.0000 ||:  15%|█▍        | 7/47 [00:02<00:12,  3.30it/s]\u001b[A\n",
            "pearson(r): 0.7139, loss: 0.0944, reg_loss: 0.0000 ||:  17%|█▋        | 8/47 [00:02<00:12,  3.09it/s]\u001b[A\n",
            "pearson(r): 0.7087, loss: 0.0949, reg_loss: 0.0000 ||:  19%|█▉        | 9/47 [00:02<00:13,  2.88it/s]\u001b[A\n",
            "pearson(r): 0.7017, loss: 0.0972, reg_loss: 0.0000 ||:  21%|██▏       | 10/47 [00:03<00:13,  2.78it/s]\u001b[A\n",
            "pearson(r): 0.7099, loss: 0.0942, reg_loss: 0.0000 ||:  23%|██▎       | 11/47 [00:03<00:13,  2.61it/s]\u001b[A\n",
            "pearson(r): 0.7109, loss: 0.0923, reg_loss: 0.0000 ||:  26%|██▌       | 12/47 [00:04<00:13,  2.55it/s]\u001b[A\n",
            "pearson(r): 0.7033, loss: 0.0956, reg_loss: 0.0000 ||:  28%|██▊       | 13/47 [00:04<00:13,  2.50it/s]\u001b[A\n",
            "pearson(r): 0.7057, loss: 0.0948, reg_loss: 0.0000 ||:  30%|██▉       | 14/47 [00:04<00:13,  2.50it/s]\u001b[A\n",
            "pearson(r): 0.6993, loss: 0.0979, reg_loss: 0.0000 ||:  32%|███▏      | 15/47 [00:05<00:13,  2.45it/s]\u001b[A\n",
            "pearson(r): 0.6883, loss: 0.1020, reg_loss: 0.0000 ||:  34%|███▍      | 16/47 [00:05<00:12,  2.41it/s]\u001b[A\n",
            "pearson(r): 0.6906, loss: 0.1005, reg_loss: 0.0000 ||:  36%|███▌      | 17/47 [00:06<00:12,  2.37it/s]\u001b[A\n",
            "pearson(r): 0.6867, loss: 0.1020, reg_loss: 0.0000 ||:  38%|███▊      | 18/47 [00:06<00:12,  2.39it/s]\u001b[A\n",
            "pearson(r): 0.6870, loss: 0.1026, reg_loss: 0.0000 ||:  40%|████      | 19/47 [00:07<00:11,  2.38it/s]\u001b[A\n",
            "pearson(r): 0.6729, loss: 0.1061, reg_loss: 0.0000 ||:  43%|████▎     | 20/47 [00:07<00:12,  2.20it/s]\u001b[A\n",
            "pearson(r): 0.6626, loss: 0.1093, reg_loss: 0.0000 ||:  45%|████▍     | 21/47 [00:08<00:12,  2.06it/s]\u001b[A\n",
            "pearson(r): 0.6494, loss: 0.1128, reg_loss: 0.0000 ||:  47%|████▋     | 22/47 [00:08<00:12,  1.94it/s]\u001b[A\n",
            "pearson(r): 0.6417, loss: 0.1139, reg_loss: 0.0000 ||:  49%|████▉     | 23/47 [00:09<00:12,  1.85it/s]\u001b[A\n",
            "pearson(r): 0.6242, loss: 0.1181, reg_loss: 0.0000 ||:  51%|█████     | 24/47 [00:09<00:12,  1.78it/s]\u001b[A\n",
            "pearson(r): 0.6060, loss: 0.1231, reg_loss: 0.0000 ||:  53%|█████▎    | 25/47 [00:10<00:12,  1.75it/s]\u001b[A\n",
            "pearson(r): 0.5995, loss: 0.1232, reg_loss: 0.0000 ||:  55%|█████▌    | 26/47 [00:11<00:11,  1.79it/s]\u001b[A\n",
            "pearson(r): 0.5850, loss: 0.1261, reg_loss: 0.0000 ||:  57%|█████▋    | 27/47 [00:11<00:11,  1.78it/s]\u001b[A\n",
            "pearson(r): 0.5742, loss: 0.1271, reg_loss: 0.0000 ||:  60%|█████▉    | 28/47 [00:12<00:10,  1.74it/s]\u001b[A\n",
            "pearson(r): 0.5653, loss: 0.1309, reg_loss: 0.0000 ||:  62%|██████▏   | 29/47 [00:12<00:10,  1.76it/s]\u001b[A\n",
            "pearson(r): 0.5561, loss: 0.1334, reg_loss: 0.0000 ||:  64%|██████▍   | 30/47 [00:13<00:09,  1.76it/s]\u001b[A\n",
            "pearson(r): 0.5494, loss: 0.1356, reg_loss: 0.0000 ||:  66%|██████▌   | 31/47 [00:13<00:08,  1.80it/s]\u001b[A\n",
            "pearson(r): 0.5555, loss: 0.1338, reg_loss: 0.0000 ||:  68%|██████▊   | 32/47 [00:14<00:08,  1.69it/s]\u001b[A\n",
            "pearson(r): 0.5644, loss: 0.1315, reg_loss: 0.0000 ||:  70%|███████   | 33/47 [00:15<00:08,  1.65it/s]\u001b[A\n",
            "pearson(r): 0.5710, loss: 0.1287, reg_loss: 0.0000 ||:  72%|███████▏  | 34/47 [00:15<00:08,  1.58it/s]\u001b[A\n",
            "pearson(r): 0.5744, loss: 0.1270, reg_loss: 0.0000 ||:  74%|███████▍  | 35/47 [00:16<00:08,  1.47it/s]\u001b[A\n",
            "pearson(r): 0.5757, loss: 0.1253, reg_loss: 0.0000 ||:  77%|███████▋  | 36/47 [00:17<00:07,  1.47it/s]\u001b[A\n",
            "pearson(r): 0.5765, loss: 0.1241, reg_loss: 0.0000 ||:  79%|███████▊  | 37/47 [00:18<00:06,  1.49it/s]\u001b[A\n",
            "pearson(r): 0.5790, loss: 0.1227, reg_loss: 0.0000 ||:  81%|████████  | 38/47 [00:18<00:06,  1.48it/s]\u001b[A\n",
            "pearson(r): 0.5832, loss: 0.1210, reg_loss: 0.0000 ||:  83%|████████▎ | 39/47 [00:19<00:05,  1.45it/s]\u001b[A\n",
            "pearson(r): 0.5815, loss: 0.1211, reg_loss: 0.0000 ||:  85%|████████▌ | 40/47 [00:19<00:04,  1.64it/s]\u001b[A\n",
            "pearson(r): 0.5795, loss: 0.1205, reg_loss: 0.0000 ||:  87%|████████▋ | 41/47 [00:20<00:03,  1.88it/s]\u001b[A\n",
            "pearson(r): 0.5828, loss: 0.1203, reg_loss: 0.0000 ||:  89%|████████▉ | 42/47 [00:20<00:02,  2.16it/s]\u001b[A\n",
            "pearson(r): 0.5815, loss: 0.1212, reg_loss: 0.0000 ||:  91%|█████████▏| 43/47 [00:20<00:01,  2.35it/s]\u001b[A\n",
            "pearson(r): 0.5816, loss: 0.1211, reg_loss: 0.0000 ||:  94%|█████████▎| 44/47 [00:21<00:01,  2.49it/s]\u001b[A\n",
            "pearson(r): 0.5770, loss: 0.1223, reg_loss: 0.0000 ||:  96%|█████████▌| 45/47 [00:21<00:00,  2.66it/s]\u001b[A\n",
            "pearson(r): 0.5787, loss: 0.1229, reg_loss: 0.0000 ||:  98%|█████████▊| 46/47 [00:21<00:00,  2.68it/s]\u001b[A\n",
            "pearson(r): 0.5727, loss: 0.1245, reg_loss: 0.0000 ||: 100%|██████████| 47/47 [00:22<00:00,  2.12it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Finished training\n",
            "CPU times: user 56min 9s, sys: 17min 23s, total: 1h 13min 32s\n",
            "Wall time: 1h 15min 50s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-H3F0v6bOtv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "64c260ad-18ca-49f2-bdef-0114d9482e97"
      },
      "source": [
        "train"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_epoch': 1,\n",
              " 'best_validation_loss': 0.11999055442023784,\n",
              " 'best_validation_pearson(r)': 0.5646551037058789,\n",
              " 'best_validation_reg_loss': 0.0,\n",
              " 'epoch': 9,\n",
              " 'peak_gpu_0_memory_MB': 7893,\n",
              " 'peak_worker_0_memory_MB': 5307.072,\n",
              " 'training_duration': '1:15:20.332530',\n",
              " 'training_epochs': 9,\n",
              " 'training_gpu_0_memory_MB': 7893,\n",
              " 'training_loss': 0.028669148279974858,\n",
              " 'training_pearson(r)': 0.8251509821119101,\n",
              " 'training_reg_loss': 0.0,\n",
              " 'training_start_epoch': 0,\n",
              " 'training_worker_0_memory_MB': 5307.072,\n",
              " 'validation_loss': 0.12447338464095238,\n",
              " 'validation_pearson(r)': 0.5726557982562258,\n",
              " 'validation_reg_loss': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvnFo18E_QHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdkIbWvLZ4bW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "2e4b32ff-7139-4f88-b05f-dd6adfb8af09"
      },
      "source": [
        "train"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best_epoch': 9,\n",
              " 'best_validation_loss': 0.11864947654465412,\n",
              " 'best_validation_pearson(r)': 0.5726986627893124,\n",
              " 'best_validation_reg_loss': 0.0,\n",
              " 'epoch': 9,\n",
              " 'peak_gpu_0_memory_MB': 13213,\n",
              " 'peak_worker_0_memory_MB': 5379.952,\n",
              " 'training_duration': '0:36:11.368891',\n",
              " 'training_epochs': 9,\n",
              " 'training_gpu_0_memory_MB': 13213,\n",
              " 'training_loss': 0.02483441670321756,\n",
              " 'training_pearson(r)': 0.8537758812915612,\n",
              " 'training_reg_loss': 0.0,\n",
              " 'training_start_epoch': 0,\n",
              " 'training_worker_0_memory_MB': 5379.952,\n",
              " 'validation_loss': 0.11864947654465412,\n",
              " 'validation_pearson(r)': 0.5726986627893124,\n",
              " 'validation_reg_loss': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFKr8tEjz9Sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#log_histograms\n",
        "#tbw.log_histograms(emodel)\n",
        "\n",
        "#log_metrics\n",
        "'''tbw.log_metrics(\n",
        "                train_metrics= \n",
        "                val_metrics=\n",
        "                epoch= 10\n",
        "                )'''\n",
        "\n",
        "\n",
        "                       "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBBUajfVY4zY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNphSsrbz9o7",
        "colab_type": "text"
      },
      "source": [
        "#Evalutate on Test Data\n",
        "We will use allennlp 'evaluate' api to evaluate our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p07gohfh0AFf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "fb409e58-f53b-4e0b-c91d-8c0605396019"
      },
      "source": [
        "#evaluate on test data\n",
        "test_evaluate = evaluate(emodel, test_data_loader)\n",
        "test_evaluate\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "pearson(r): 0.60, loss: 0.09 ||: : 1it [00:00,  2.67it/s]\u001b[A\n",
            "pearson(r): 0.57, loss: 0.12 ||: : 2it [00:00,  2.84it/s]\u001b[A\n",
            "pearson(r): 0.60, loss: 0.12 ||: : 3it [00:00,  2.93it/s]\u001b[A\n",
            "pearson(r): 0.61, loss: 0.11 ||: : 4it [00:01,  2.93it/s]\u001b[A\n",
            "pearson(r): 0.63, loss: 0.11 ||: : 5it [00:01,  3.01it/s]\u001b[A\n",
            "pearson(r): 0.64, loss: 0.11 ||: : 6it [00:01,  3.13it/s]\u001b[A\n",
            "pearson(r): 0.63, loss: 0.11 ||: : 7it [00:02,  3.22it/s]\u001b[A\n",
            "pearson(r): 0.63, loss: 0.11 ||: : 8it [00:02,  3.09it/s]\u001b[A\n",
            "pearson(r): 0.64, loss: 0.11 ||: : 9it [00:02,  2.95it/s]\u001b[A\n",
            "pearson(r): 0.65, loss: 0.11 ||: : 10it [00:03,  2.79it/s]\u001b[A\n",
            "pearson(r): 0.65, loss: 0.10 ||: : 11it [00:03,  2.76it/s]\u001b[A\n",
            "pearson(r): 0.65, loss: 0.10 ||: : 12it [00:04,  2.70it/s]\u001b[A\n",
            "pearson(r): 0.64, loss: 0.11 ||: : 13it [00:04,  2.58it/s]\u001b[A\n",
            "pearson(r): 0.65, loss: 0.11 ||: : 14it [00:04,  2.49it/s]\u001b[A\n",
            "pearson(r): 0.65, loss: 0.11 ||: : 15it [00:05,  2.45it/s]\u001b[A\n",
            "pearson(r): 0.65, loss: 0.11 ||: : 16it [00:05,  2.43it/s]\u001b[A\n",
            "pearson(r): 0.64, loss: 0.11 ||: : 17it [00:06,  2.40it/s]\u001b[A\n",
            "pearson(r): 0.63, loss: 0.11 ||: : 18it [00:06,  2.58it/s]\u001b[A\n",
            "pearson(r): 0.63, loss: 0.11 ||: : 19it [00:06,  2.54it/s]\u001b[A\n",
            "pearson(r): 0.62, loss: 0.11 ||: : 20it [00:07,  2.43it/s]\u001b[A\n",
            "pearson(r): 0.61, loss: 0.11 ||: : 21it [00:07,  2.35it/s]\u001b[A\n",
            "pearson(r): 0.59, loss: 0.12 ||: : 22it [00:08,  2.33it/s]\u001b[A\n",
            "pearson(r): 0.57, loss: 0.12 ||: : 23it [00:08,  2.33it/s]\u001b[A\n",
            "pearson(r): 0.56, loss: 0.12 ||: : 24it [00:09,  2.35it/s]\u001b[A\n",
            "pearson(r): 0.55, loss: 0.12 ||: : 25it [00:09,  2.32it/s]\u001b[A\n",
            "pearson(r): 0.53, loss: 0.13 ||: : 26it [00:10,  2.31it/s]\u001b[A\n",
            "pearson(r): 0.52, loss: 0.13 ||: : 27it [00:10,  2.32it/s]\u001b[A\n",
            "pearson(r): 0.52, loss: 0.13 ||: : 28it [00:11,  1.96it/s]\u001b[A\n",
            "pearson(r): 0.52, loss: 0.12 ||: : 29it [00:11,  1.79it/s]\u001b[A\n",
            "pearson(r): 0.52, loss: 0.12 ||: : 30it [00:12,  1.69it/s]\u001b[A\n",
            "pearson(r): 0.53, loss: 0.12 ||: : 31it [00:13,  1.61it/s]\u001b[A\n",
            "pearson(r): 0.53, loss: 0.12 ||: : 32it [00:13,  1.61it/s]\u001b[A\n",
            "pearson(r): 0.53, loss: 0.12 ||: : 33it [00:14,  1.56it/s]\u001b[A\n",
            "pearson(r): 0.53, loss: 0.12 ||: : 34it [00:15,  1.53it/s]\u001b[A\n",
            "pearson(r): 0.53, loss: 0.11 ||: : 35it [00:15,  1.51it/s]\u001b[A\n",
            "pearson(r): 0.52, loss: 0.12 ||: : 36it [00:16,  1.55it/s]\u001b[A\n",
            "pearson(r): 0.52, loss: 0.12 ||: : 37it [00:16,  1.81it/s]\u001b[A\n",
            "pearson(r): 0.52, loss: 0.12 ||: : 38it [00:17,  2.01it/s]\u001b[A\n",
            "pearson(r): 0.52, loss: 0.12 ||: : 39it [00:17,  2.33it/s]\u001b[A\n",
            "pearson(r): 0.52, loss: 0.12 ||: : 40it [00:17,  2.57it/s]\u001b[A\n",
            "pearson(r): 0.52, loss: 0.12 ||: : 41it [00:18,  2.38it/s]\u001b[A\n",
            "pearson(r): 0.52, loss: 0.12 ||: : 42it [00:18,  2.56it/s]\u001b[A\n",
            "pearson(r): 0.52, loss: 0.12 ||: : 43it [00:18,  2.73it/s]\u001b[A\n",
            "pearson(r): 0.52, loss: 0.12 ||: : 44it [00:19,  2.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 0.12267272191291506, 'pearson(r)': 0.5204117698519292}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrqCFjDlbVQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBi-W3T6U0xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Qz5Tl8gw9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(12)\n",
        "torch.cuda.manual_seed(12)\n",
        "np.random.seed(12)\n"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j8oUKAkra2x",
        "colab_type": "text"
      },
      "source": [
        "#Predict new sentence pair\n",
        "We will make a class for prediction that inheritated from allenlp 'Predictor'. The code is taken from [allennlp](https://guide.allennlp.org/training-and-prediction#4) and is modified as per our problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TIXthUPfpme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prediction class\n",
        "class SentencePairPredictor(Predictor):\n",
        "    def predict(self, sent_1: str, sent_2: str) -> JsonDict:\n",
        "        # This method is implemented in the base class.\n",
        "        return self.predict_json({\"sent_1\": sent_1, \"sent_2\": sent_2})\n",
        "\n",
        "    def _json_to_instance(self, json_dict: JsonDict) -> Instance:\n",
        "        sent_1, sent_2  = json_dict[\"sent_1\"], json_dict[\"sent_2\"]\n",
        "        return self._dataset_reader.text_to_instance(sent_1, sent_2)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk8621wOfpe9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "60d864c4-bcdd-495f-f15d-916910f0d35d"
      },
      "source": [
        "#predict a pari of sentences\n",
        "predictor = SentencePairPredictor(emodel, dataset_reader)\n",
        "a= df_test.loc[:,'sentence_1'].values.tolist()[0]\n",
        "b= df_test.loc[:,'sentence_1'].values.tolist()[0]\n",
        "print(a,b)\n",
        "predictor.predict(a, b)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A girl is styling her hair. A girl is styling her hair.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cos_sim': 0.9637460708618164}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ynw6M-m0Z8LH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8eb48dc-a714-4bdc-9bd9-d8356321b9c7"
      },
      "source": [
        "#parameteres \n",
        "for name,param in emodel.named_parameters():\n",
        "        print(name)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "elmo_embedding._elmo_lstm._token_embedder._char_embedding_weights\n",
            "elmo_embedding._elmo_lstm._token_embedder.char_conv_0.weight\n",
            "elmo_embedding._elmo_lstm._token_embedder.char_conv_0.bias\n",
            "elmo_embedding._elmo_lstm._token_embedder.char_conv_1.weight\n",
            "elmo_embedding._elmo_lstm._token_embedder.char_conv_1.bias\n",
            "elmo_embedding._elmo_lstm._token_embedder.char_conv_2.weight\n",
            "elmo_embedding._elmo_lstm._token_embedder.char_conv_2.bias\n",
            "elmo_embedding._elmo_lstm._token_embedder.char_conv_3.weight\n",
            "elmo_embedding._elmo_lstm._token_embedder.char_conv_3.bias\n",
            "elmo_embedding._elmo_lstm._token_embedder.char_conv_4.weight\n",
            "elmo_embedding._elmo_lstm._token_embedder.char_conv_4.bias\n",
            "elmo_embedding._elmo_lstm._token_embedder.char_conv_5.weight\n",
            "elmo_embedding._elmo_lstm._token_embedder.char_conv_5.bias\n",
            "elmo_embedding._elmo_lstm._token_embedder.char_conv_6.weight\n",
            "elmo_embedding._elmo_lstm._token_embedder.char_conv_6.bias\n",
            "elmo_embedding._elmo_lstm._token_embedder._highways._layers.0.weight\n",
            "elmo_embedding._elmo_lstm._token_embedder._highways._layers.0.bias\n",
            "elmo_embedding._elmo_lstm._token_embedder._highways._layers.1.weight\n",
            "elmo_embedding._elmo_lstm._token_embedder._highways._layers.1.bias\n",
            "elmo_embedding._elmo_lstm._token_embedder._projection.weight\n",
            "elmo_embedding._elmo_lstm._token_embedder._projection.bias\n",
            "elmo_embedding._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight\n",
            "elmo_embedding._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight\n",
            "elmo_embedding._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias\n",
            "elmo_embedding._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight\n",
            "elmo_embedding._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight\n",
            "elmo_embedding._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight\n",
            "elmo_embedding._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias\n",
            "elmo_embedding._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight\n",
            "elmo_embedding._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight\n",
            "elmo_embedding._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight\n",
            "elmo_embedding._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias\n",
            "elmo_embedding._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight\n",
            "elmo_embedding._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight\n",
            "elmo_embedding._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight\n",
            "elmo_embedding._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias\n",
            "elmo_embedding._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight\n",
            "elmo_embedding.scalar_mix_0.gamma\n",
            "elmo_embedding.scalar_mix_0.scalar_parameters.0\n",
            "elmo_embedding.scalar_mix_0.scalar_parameters.1\n",
            "elmo_embedding.scalar_mix_0.scalar_parameters.2\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder._char_embedding_weights\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder.char_conv_0.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder.char_conv_0.bias\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder.char_conv_1.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder.char_conv_1.bias\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder.char_conv_2.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder.char_conv_2.bias\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder.char_conv_3.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder.char_conv_3.bias\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder.char_conv_4.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder.char_conv_4.bias\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder.char_conv_5.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder.char_conv_5.bias\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder.char_conv_6.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder.char_conv_6.bias\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder._highways._layers.0.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder._highways._layers.0.bias\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder._highways._layers.1.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder._highways._layers.1.bias\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder._projection.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._token_embedder._projection.bias\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias\n",
            "word_embedding.token_embedder_elmo_tokens._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight\n",
            "word_embedding.token_embedder_elmo_tokens._elmo.scalar_mix_0.gamma\n",
            "word_embedding.token_embedder_elmo_tokens._elmo.scalar_mix_0.scalar_parameters.0\n",
            "word_embedding.token_embedder_elmo_tokens._elmo.scalar_mix_0.scalar_parameters.1\n",
            "word_embedding.token_embedder_elmo_tokens._elmo.scalar_mix_0.scalar_parameters.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJUxJwW270di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load model\n",
        "model2 = ElmoSentenceSimilarityModel(seq2vec, vocab)\n",
        "with open(serialization_dir +\"/best.th\", 'rb') as f:\n",
        "    model2.load_state_dict(torch.load(f))\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh3Hp9Np8DU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHqIHQj380H1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Biw9b5Ag91_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}